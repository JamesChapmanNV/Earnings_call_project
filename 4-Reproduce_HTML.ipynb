{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earnings Call Project: Data Cleaning\n",
    "<br>\n",
    "CIS 831 Deep Learning â€“ Term Project<br>\n",
    "Kansas State University\n",
    "<br><br>\n",
    "James Chapman<br>\n",
    "John Woods<br>\n",
    "Nathan Diehl<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the transformer architecture from the [HTML paper](https://www.researchgate.net/publication/340385140_HTML_Hierarchical_Transformer-based_Multi-task_Learning_for_Volatility_Prediction). \n",
    "\n",
    "From the previous notebooks, we have features for both audio and text, of each sentence, of each meeting.<br>\n",
    "- audio \n",
    "    - PRAAT (27 features)\n",
    "- text\n",
    "    - GLOVE (300 features)\n",
    "    - ROBERTA (1024 features)\n",
    "    - ROBERTA with averaging (1024 features)\n",
    "    - FinLang investopedia (768 features) from huggingface sentencetransformers\n",
    "    - BGE financial (1024 features) from huggingface sentencetransformers\n",
    "\n",
    "This notebook performs 3 nested loops. Each audio/text pair, and for each N_DAYS, we train models with 17 different alpha values. The alpha value the lowest MSE, based on the validation set, is been used to train a model with Both training and validation sets. This model is finally tested on the test set.\n",
    "\n",
    "These notebooks also give us a playground to work with the data, and test the models. Now we can insert sentiment detection, segmentation of the text, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "torch.cuda.manual_seed_all(777)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "#fresh start\n",
    "\n",
    "directory_path = r\"C:\\Users\\James\\OneDrive\\Documents\\GitHub\\Earnings_call_project\\runs\"\n",
    "if os.path.exists(directory_path):\n",
    "    shutil.rmtree(directory_path)\n",
    "    \n",
    "path = \"C:/Users/James/AppData/Local/Temp/.tensorboard-info/\"\n",
    "for filename in os.listdir(path):\n",
    "    filepath = os.path.join(path, filename)\n",
    "    print(filepath)\n",
    "    os.remove(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['Roberta/', 'Roberta2/', 'investopedia/', 'bge/', 'glove/']#, 'bge_base/'\n",
    "all_n_days = ['3', '7', '15', '30']\n",
    "alphas = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85]\n",
    "\n",
    "# static hyper-parameters from paper\n",
    "max_norm = 1.0\n",
    "num_epochs = 10\n",
    "warmup_steps = 1000\n",
    "batch_size=4\n",
    "dropout=0.5\n",
    "heads=2\n",
    "depth=2\n",
    "\n",
    "lr=0.000002 # 1/10 learning rate of paper\n",
    "is_using_scaler = True # whether or not to use standardscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the hierarchical transformer from the HTML paper.\n",
    "\n",
    "## This is taken directly from the GitHub account for HTML paper.\n",
    "- a few adaptions are highlighted with ##############################################\n",
    "\n",
    "\n",
    "- [GitHub HTML - util.py](https://github.com/YangLinyi/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/blob/master/Model/Sentence-Level-Transformer/transformers/util/util.py)\n",
    "- [GitHub HTML - transformers_gpu.py](https://github.com/YangLinyi/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/blob/master/Model/Sentence-Level-Transformer/transformers/transformers_gpu.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://github.com/YangLinyi/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/blob/master/Model/Sentence-Level-Transformer/transformers/transformers_gpu.py\n",
    "def mask_(matrices, maskval=0.0, mask_diagonal=True):\n",
    "    \"\"\"\n",
    "    Masks out all values in the given batch of matrices where i <= j holds,\n",
    "    i < j if mask_diagonal is false\n",
    "\n",
    "    In place operation\n",
    "\n",
    "    :param tns:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    b, h, w = matrices.size()\n",
    "\n",
    "    indices = torch.triu_indices(h, w, offset=0 if mask_diagonal else 1)\n",
    "    matrices[:, indices, indices[1]] = maskval\n",
    "\n",
    "def contains_nan(tensor):\n",
    "    return bool((tensor != tensor).sum() > 0)\n",
    "\n",
    "# https://github.com/YangLinyi/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/blob/master/Model/Sentence-Level-Transformer/transformers/transformers_gpu.py\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, emb, heads=8, mask=False):\n",
    "        \"\"\"\n",
    "        :param emb:\n",
    "        :param heads:\n",
    "        :param mask:\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = emb\n",
    "        self.heads = heads\n",
    "        self.mask = mask\n",
    "\n",
    "        self.tokeys = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.toqueries = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.tovalues = nn.Linear(emb, emb * heads, bias=False)\n",
    "\n",
    "        self.unifyheads = nn.Linear(heads * emb, emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        b, t, e = x.size()\n",
    "        h = self.heads\n",
    "        assert e == self.emb\n",
    "\n",
    "        keys    = self.tokeys(x)   .view(b, t, h, e)\n",
    "        queries = self.toqueries(x).view(b, t, h, e)\n",
    "        values  = self.tovalues(x) .view(b, t, h, e)\n",
    "\n",
    "        # compute scaled dot-product self-attention\n",
    "\n",
    "        # - fold heads into the batch dimension\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "\n",
    "        queries = queries / (e ** (1/4))\n",
    "        keys    = keys / (e ** (1/4))\n",
    "        # - Instead of dividing the dot products by sqrt(e), we scale the keys and values.\n",
    "        #   This should be more memory efficient\n",
    "\n",
    "        # - get dot product of queries and keys, and scale\n",
    "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "\n",
    "        assert dot.size() == (b*h, t, t)\n",
    "\n",
    "        if self.mask: # mask out the lower half of the dot matrix,including the diagonal\n",
    "            mask_(dot, maskval=float('-inf'), mask_diagonal=False)\n",
    "\n",
    "        dot = F.softmax(dot, dim=2) # dot now has row-wise self-attention probabilities\n",
    "\n",
    "        ##############################################\n",
    "        ##############################################\n",
    "        # assert not util.contains_nan(dot[:, 1:, :]) # only the forst row may contain nan\n",
    "        assert not contains_nan(dot[:, 1:, :]) # only the forst row may contain nan \n",
    "        ##############################################\n",
    "        ##############################################\n",
    "        \n",
    "        if self.mask == 'first':\n",
    "            dot = dot.clone()\n",
    "            dot[:, :1, :] = 0.0\n",
    "            # - The first row of the first attention matrix is entirely masked out, so the softmax operation results\n",
    "            #   in a division by zero. We set this row to zero by hand to get rid of the NaNs\n",
    "\n",
    "        # apply the self attention to the values\n",
    "        out = torch.bmm(dot, values).view(b, h, t, e)\n",
    "\n",
    "        # swap h, t back, unify heads\n",
    "        out = out.transpose(1, 2).contiguous().view(b, t, h * e)\n",
    "\n",
    "        return self.unifyheads(out)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb, heads, mask, seq_length, ff_hidden_mult=4, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = SelfAttention(emb, heads=heads, mask=mask)\n",
    "        self.mask = mask\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(emb)\n",
    "        self.norm2 = nn.LayerNorm(emb)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(emb, ff_hidden_mult * emb),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_mult * emb, emb)\n",
    "        )\n",
    "\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        attended = self.attention(x)\n",
    "\n",
    "        x = self.norm1(attended + x)\n",
    "\n",
    "        x = self.do(x)\n",
    "\n",
    "        fedforward = self.ff(x)\n",
    "\n",
    "        x = self.norm2(fedforward + x)\n",
    "\n",
    "        x = self.do(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class RTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer for sequences Regression    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emb, heads, depth, seq_length, num_tokens, num_classes, max_pool=True, dropout=0.0):\n",
    "        \"\"\"\n",
    "        emb: Embedding dimension\n",
    "        heads: nr. of attention heads\n",
    "        depth: Number of transformer blocks\n",
    "        seq_length: Expected maximum sequence length\n",
    "        num_tokens: Number of tokens (usually words) in the vocabulary\n",
    "        num_classes: Number of classes.\n",
    "        max_pool: If true, use global max pooling in the last layer. If false, use global\n",
    "                         average pooling.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_tokens, self.max_pool = num_tokens, max_pool\n",
    "\n",
    "        #self.token_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=num_tokens)\n",
    "        self.pos_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=seq_length)\n",
    "\n",
    "        tblocks = []\n",
    "        for i in range(depth):\n",
    "            tblocks.append(\n",
    "                TransformerBlock(emb=emb, heads=heads, seq_length=seq_length, mask=False, dropout=dropout))\n",
    "\n",
    "        self.tblocks = nn.Sequential(*tblocks)\n",
    "\n",
    "        self.toprobs = nn.Linear(emb, num_classes)\n",
    "        self.toprobs_b = nn.Linear(emb, num_classes)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: A batch by sequence length integer tensor of token indices.\n",
    "        :return: predicted log-probability vectors for each token based on the preceding tokens.\n",
    "        \"\"\"\n",
    "        sentences_emb = x\n",
    "        b, t, e = x.size()\n",
    "\n",
    "        ##############################################\n",
    "        ##############################################\n",
    "        # swap d() for device\n",
    "        # positions = self.pos_embedding(torch.arange(t, device=d()))[None, :, :].expand(b, t, e)\n",
    "        positions = self.pos_embedding(torch.arange(t, device=device))[None, :, :].expand(b, t, e)\n",
    "        ##############################################\n",
    "        ##############################################\n",
    "        #positions = self.pos_embedding(torch.arange(t))[None, :, :].expand(b, t, e)\n",
    "        #positions = torch.tensor(positions, dtype=torch.float32)\n",
    "        x = sentences_emb.cuda() + positions\n",
    "        x = self.do(x)\n",
    "\n",
    "        x = self.tblocks(x)\n",
    "\n",
    "        x = x.max(dim=1)[0] if self.max_pool else x.mean(dim=1) # pool over the time dimension\n",
    "        \n",
    "        \n",
    "        x_a = self.toprobs(x)\n",
    "        x_b = self.toprobs_b(x)\n",
    "        x_a = torch.squeeze(x_a)\n",
    "        x_b = torch.squeeze(x_b)\n",
    "        #print('x shape: ',x.shape)\n",
    "        return x_a, x_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset builder and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, embeddings, labels, labels_b):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "        self.labels_b = labels_b\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb = self.embeddings[idx]\n",
    "        label = self.labels[idx]\n",
    "        label_b = self.labels_b[idx]\n",
    "        return emb, label, label_b \n",
    "\n",
    "def get_data(data_directory, n_days, no_validation_set, is_using_scaler, batch_size):\n",
    "    # features\n",
    "    train_features = np.load('data/{}/train_features.npy'.format(data_directory))\n",
    "    val_features = np.load('data/{}/val_features.npy'.format(data_directory))\n",
    "    test_features = np.load('data/{}/test_features.npy'.format(data_directory))\n",
    "    # targets (n_days volatility)\n",
    "    train_targets = np.load('data/{}/train_targets_{}.npy'.format(data_directory, n_days))\n",
    "    val_targets = np.load('data/{}/val_targets_{}.npy'.format(data_directory, n_days))\n",
    "    test_targets = np.load('data/{}/test_targets_{}.npy'.format(data_directory, n_days))\n",
    "    # secondary targets (log percent change of day n)\n",
    "    train_secondary_targets = np.load('data/{}/train_secondary_targets_{}.npy'.format(data_directory, n_days))\n",
    "    val_secondary_targets = np.load('data/{}/val_secondary_targets_{}.npy'.format(data_directory, n_days))\n",
    "    test_secondary_targets = np.load('data/{}/test_secondary_targets_{}.npy'.format(data_directory, n_days))\n",
    "\n",
    "    # after hyperparameters are tuned on the validation set\n",
    "    # add validation set to training set\n",
    "    if no_validation_set:\n",
    "        train_features = np.concatenate((train_features, val_features), axis=0)\n",
    "        train_targets = np.concatenate((train_targets, val_targets), axis=0)\n",
    "        train_secondary_targets = np.concatenate((train_secondary_targets, val_secondary_targets), axis=0)\n",
    "\n",
    "    if is_using_scaler:\n",
    "        # Scaling features\n",
    "        feature_scaler = StandardScaler()\n",
    "        train_features = feature_scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "        val_features = feature_scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "        test_features = feature_scaler.transform(test_features.reshape(-1, test_features.shape[-1])).reshape(test_features.shape)\n",
    "        # Scaling primary targets\n",
    "        target_scaler = StandardScaler()\n",
    "        train_targets = target_scaler.fit_transform(train_targets.reshape(-1, 1)).reshape(train_targets.shape)\n",
    "        val_targets = target_scaler.transform(val_targets.reshape(-1, 1)).reshape(val_targets.shape)\n",
    "        test_targets = target_scaler.transform(test_targets.reshape(-1, 1)).reshape(test_targets.shape)\n",
    "        # Scaling secondary targets\n",
    "        secondary_target_scaler = StandardScaler()\n",
    "        train_secondary_targets = secondary_target_scaler.fit_transform(train_secondary_targets.reshape(-1, 1)).reshape(train_secondary_targets.shape)\n",
    "        val_secondary_targets = secondary_target_scaler.transform(val_secondary_targets.reshape(-1, 1)).reshape(val_secondary_targets.shape)\n",
    "        test_secondary_targets = secondary_target_scaler.transform(test_secondary_targets.reshape(-1, 1)).reshape(test_secondary_targets.shape)\n",
    "    # Dataset & DataLoader\n",
    "    training_set = Dataset(train_features, train_targets, train_secondary_targets) \n",
    "    val_set = Dataset(val_features, val_targets, val_secondary_targets)\n",
    "    test_set = Dataset(test_features, test_targets, test_secondary_targets)\n",
    "    trainloader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    valloader = torch.utils.data.DataLoader(val_set, batch_size=len(val_set), shuffle=False, num_workers=0)\n",
    "    testloader = torch.utils.data.DataLoader(test_set, batch_size=len(test_set), shuffle=False, num_workers=0)\n",
    "\n",
    "    print(train_features.shape, train_targets.shape, train_secondary_targets.shape) \n",
    "    print(val_features.shape, val_targets.shape, val_secondary_targets.shape) \n",
    "    print(test_features.shape, test_targets.shape, test_secondary_targets.shape) \n",
    "\n",
    "    # train_features.shape[2] is the number of features, need to instantiate the model\n",
    "    # need target scaler to inverse transform\n",
    "    return trainloader, valloader, testloader, train_features.shape[2], target_scaler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this training loop is actually reused for training, validation, and testing\n",
    "def  training_loop(trainloader, loader, emb_dimensions, heads, depth,dropout, warmup_steps, \n",
    "                   batch_size, num_epochs, alphas, max_norm, lr, run_name, target_scaler):\n",
    "    alphas_results = []\n",
    "    for alpha in alphas:\n",
    "        model = RTransformer(emb=emb_dimensions, heads=heads, depth=depth, seq_length=523, \n",
    "                            num_tokens=4000, num_classes=1, max_pool=False, dropout=dropout).to(device)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        # Linear LR warmup for the first #warmup_steps training examples\n",
    "        scheduler = LambdaLR(opt, lr_lambda=lambda step: min(1.0, step / (warmup_steps/batch_size)))\n",
    "\n",
    "        seen = 0\n",
    "        min_loss = float('inf')\n",
    "        val_loss_a_history =  []\n",
    "        writer = SummaryWriter(log_dir= f'runs/{run_name}_{alpha}')\n",
    "        progress_bar = tqdm(range(num_epochs), desc=\"Training Progress\", unit=\"epoch\")\n",
    "        for epoch in progress_bar:\n",
    "            model.train()\n",
    "            epoch_seen = 0 # 1st 1000 meetings trained, increase the learning rate\n",
    "            train_loss_total = 0\n",
    "            for i, (inputs, labels, labels_b) in enumerate(trainloader): #training data\n",
    "                seen += inputs.size(0)\n",
    "                epoch_seen += inputs.size(0)\n",
    "                inputs = inputs.to(device, dtype=torch.float32)\n",
    "                labels = labels.to(device, dtype=torch.float32)\n",
    "                labels_b = labels_b.to(device, dtype=torch.float32)\n",
    "                out_a, out_b = model(inputs)\n",
    "\n",
    "                # Compute the combined loss (multitask)\n",
    "                loss_a = F.mse_loss(out_a, labels)\n",
    "                loss_b = F.mse_loss(out_b, labels_b)\n",
    "                loss = alpha * loss_a + (1 - alpha) * loss_b # Alpha parameter\n",
    "            \n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "                opt.step()\n",
    "                if seen < warmup_steps:\n",
    "                    scheduler.step()\n",
    "\n",
    "                # we only care about the primary target\n",
    "                # although we training with the scaled loss, reporting the volatility must be unscaled\n",
    "                out_a_unscaled = target_scaler.inverse_transform(out_a.detach().cpu().numpy().reshape(-1, 1)).reshape(out_a.shape)\n",
    "                labels_unscaled = target_scaler.inverse_transform(labels.detach().cpu().numpy().reshape(-1, 1)).reshape(labels.shape)\n",
    "                loss_a_unscaled = F.mse_loss(torch.tensor(out_a_unscaled, device=out_a.device), torch.tensor(labels_unscaled, device=labels.device))\n",
    "                train_loss_total += loss_a_unscaled.item() * inputs.size(0) # MSE of volatility training\n",
    "\n",
    "            # Epoch average of unscaled training loss\n",
    "            train_loss_avg = train_loss_total / epoch_seen\n",
    "            \n",
    "            # Epoch Evaluation\n",
    "            model.eval()\n",
    "            val_loss_a_total = 0.0\n",
    "            val_loss_b_total = 0.0\n",
    "            epoch_seen = 0\n",
    "            with torch.no_grad():\n",
    "                for i, (inputs, labels, labels_b) in enumerate(loader): #validation ortesting\n",
    "                    epoch_seen += inputs.size(0)\n",
    "                    inputs = inputs.to(device, dtype=torch.float32)\n",
    "                    labels = labels.to(device, dtype=torch.float32)\n",
    "                    labels_b = labels_b.to(device, dtype=torch.float32)\n",
    "\n",
    "                    out_a, out_b = model(inputs)\n",
    "                    #loss_a = F.mse_loss(out_a, labels)\n",
    "                    loss_b = F.mse_loss(out_b, labels_b)\n",
    "                    \n",
    "                    out_a_unscaled = target_scaler.inverse_transform(out_a.detach().cpu().numpy().reshape(-1, 1)).reshape(out_a.shape)\n",
    "                    labels_unscaled = target_scaler.inverse_transform(labels.detach().cpu().numpy().reshape(-1, 1)).reshape(labels.shape)\n",
    "                    loss_a_unscaled = F.mse_loss(torch.tensor(out_a_unscaled, device=out_a.device), torch.tensor(labels_unscaled, device=labels.device))\n",
    "                    val_loss_a_total += loss_a_unscaled.item() * inputs.size(0) # MSE of volatility\n",
    "\n",
    "                    val_loss_b_total += loss_b.item() * inputs.size(0) \n",
    "                ##############################################\n",
    "                val_loss_a_avg = val_loss_a_total / epoch_seen # MSE of volatility of Val/test!!\n",
    "                val_loss_b_avg = val_loss_b_total / epoch_seen\n",
    "            # Epoch finished\n",
    "            writer.add_scalar('Train Loss/train', train_loss_avg, epoch)\n",
    "            writer.add_scalar('Loss A/val', val_loss_a_avg, epoch)\n",
    "            writer.add_scalar('Loss B/val', val_loss_b_avg, epoch)\n",
    "            # Update progress bar description and postfix\n",
    "            progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            progress_bar.set_postfix({\n",
    "                \"Train Loss\": f\"{train_loss_avg:.4f}\",\n",
    "                \"Test Loss A\": f\"{val_loss_a_avg:.4f}\",\n",
    "                \"Test Loss B\": f\"{val_loss_b_avg:.4f}\"\n",
    "            })\n",
    "            # for alpha optimization, collect each Epoch's average loss\n",
    "            val_loss_a_history.append(val_loss_a_avg)\n",
    "        # all Epochs finished for this alpha value\n",
    "        # if testing, there will only be one Alpha\n",
    "        # I made a sliding window of 2, so we pick the alpha with the lowest average 2 consecutive Epoeh losses\n",
    "        # min_loss = min(\n",
    "        #     (val_loss_a_history[i] + val_loss_a_history[i + 1]) / 2 # average 2 consecutive Epoeh losses\n",
    "        #     for i in range(len(val_loss_a_history) - 1)\n",
    "        # )\n",
    "        # or just the Alpha with the lowest minimum loss\n",
    "        min_loss = round(min(val_loss_a_history), 3)\n",
    "        alphas_results.append((alpha, min_loss))\n",
    "        print(alpha, min_loss)\n",
    "        writer.close()\n",
    "    best_alpha, lowest_val_loss = min(alphas_results, key=lambda x: x[1])\n",
    "    return best_alpha, lowest_val_loss # if testING, this is the MSE  of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_test(data_directory, n_days):\n",
    "    run_name = data_directory + '_'  + n_days\n",
    "    # using training set and validation set, determine optimum hyper-parameters (just alpha)\n",
    "    no_validation_set = False\n",
    "    trainloader,valloader,testloader,emb_dimensions, target_scaler = get_data(data_directory, n_days, no_validation_set, is_using_scaler, batch_size)\n",
    "    best_alpha, _ = training_loop(trainloader, valloader, emb_dimensions, heads, depth,dropout, warmup_steps, \n",
    "                            batch_size, num_epochs, alphas, max_norm, lr, run_name, target_scaler)\n",
    "    # using optimum alpha, retrain with all training/validation sets and test on testset\n",
    "    test_run_name = run_name + '_test'\n",
    "    no_validation_set = True\n",
    "    trainloader,valloader,testloader,emb_dimensions, target_scaler = get_data(data_directory, n_days, no_validation_set, is_using_scaler, batch_size)\n",
    "    _, MSE_testset = training_loop(trainloader, testloader, emb_dimensions, heads, depth, dropout, warmup_steps, \n",
    "                        batch_size, num_epochs, [best_alpha], max_norm, lr, test_run_name, target_scaler)\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    print(f'run_name-----------{run_name}')\n",
    "    print(f'best_alpha---------{best_alpha}')\n",
    "    print(f'MSE_testset--------{MSE_testset}')\n",
    "    print('----------------------------------------')\n",
    "    return best_alpha, MSE_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.7474, Test Loss A=0.5626, Test Loss B=5.1637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.7351, Test Loss A=0.6318, Test Loss B=5.0527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.7449, Test Loss A=0.6438, Test Loss B=5.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.7456, Test Loss A=0.6742, Test Loss B=5.1316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.7359, Test Loss A=0.7346, Test Loss B=5.0295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:26<00:00,  2.66s/epoch, Train Loss=0.7332, Test Loss A=0.7000, Test Loss B=5.0452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.58s/epoch, Train Loss=0.7375, Test Loss A=0.8301, Test Loss B=4.9928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:26<00:00,  2.69s/epoch, Train Loss=0.7376, Test Loss A=0.8129, Test Loss B=5.1011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:26<00:00,  2.63s/epoch, Train Loss=0.7348, Test Loss A=0.7924, Test Loss B=4.9932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.7256, Test Loss A=0.8033, Test Loss B=4.9804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/epoch, Train Loss=0.7308, Test Loss A=0.8125, Test Loss B=4.9856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.7272, Test Loss A=0.8812, Test Loss B=5.1153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.7333, Test Loss A=0.8623, Test Loss B=4.9983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.7317, Test Loss A=0.8978, Test Loss B=5.0169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7282, Test Loss A=0.8183, Test Loss B=4.9829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7385, Test Loss A=0.8381, Test Loss B=4.9130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.7341, Test Loss A=0.8933, Test Loss B=4.8391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.617\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.95s/epoch, Train Loss=0.7301, Test Loss A=0.7247, Test Loss B=0.2895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.725\n",
      "----------------------------------------\n",
      "run_name-----------\n",
      "best_alpha---------0.05\n",
      "MSE_testset--------0.725\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.4303, Test Loss A=0.2686, Test Loss B=2.3269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.4312, Test Loss A=0.2685, Test Loss B=2.4284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.4304, Test Loss A=0.2864, Test Loss B=2.3316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.4333, Test Loss A=0.2835, Test Loss B=2.3538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.4270, Test Loss A=0.2793, Test Loss B=2.3428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.4270, Test Loss A=0.2970, Test Loss B=2.3734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.4327, Test Loss A=0.2867, Test Loss B=2.3679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.4305, Test Loss A=0.2958, Test Loss B=2.3795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.4298, Test Loss A=0.2920, Test Loss B=2.3768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.4311, Test Loss A=0.2894, Test Loss B=2.3341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.4298, Test Loss A=0.3113, Test Loss B=2.3186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.42s/epoch, Train Loss=0.4308, Test Loss A=0.2915, Test Loss B=2.3738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.4325, Test Loss A=0.3109, Test Loss B=2.2925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.4350, Test Loss A=0.2911, Test Loss B=2.4522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.41s/epoch, Train Loss=0.4319, Test Loss A=0.2948, Test Loss B=2.3194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.40s/epoch, Train Loss=0.4315, Test Loss A=0.3037, Test Loss B=2.3720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.38s/epoch, Train Loss=0.4315, Test Loss A=0.2968, Test Loss B=2.3111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.27\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.89s/epoch, Train Loss=0.4092, Test Loss A=0.3622, Test Loss B=1.9909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.362\n",
      "----------------------------------------\n",
      "run_name-----------_7\n",
      "best_alpha---------0.25\n",
      "MSE_testset--------0.362\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.2636, Test Loss A=0.1810, Test Loss B=1.2284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.41s/epoch, Train Loss=0.2590, Test Loss A=0.1896, Test Loss B=1.2347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.42s/epoch, Train Loss=0.2590, Test Loss A=0.1871, Test Loss B=1.2705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.50s/epoch, Train Loss=0.2587, Test Loss A=0.1958, Test Loss B=1.2610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.50s/epoch, Train Loss=0.2586, Test Loss A=0.1952, Test Loss B=1.3040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.2621, Test Loss A=0.2022, Test Loss B=1.2948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.2601, Test Loss A=0.2125, Test Loss B=1.2167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.2596, Test Loss A=0.2115, Test Loss B=1.2515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.2584, Test Loss A=0.2227, Test Loss B=1.4535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.2580, Test Loss A=0.2270, Test Loss B=1.2616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.2575, Test Loss A=0.2254, Test Loss B=1.2825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.2557, Test Loss A=0.2159, Test Loss B=1.2773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.2577, Test Loss A=0.2143, Test Loss B=1.1963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.2556, Test Loss A=0.2132, Test Loss B=1.1492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.50s/epoch, Train Loss=0.2580, Test Loss A=0.2164, Test Loss B=1.1481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.2549, Test Loss A=0.2379, Test Loss B=1.1334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.2574, Test Loss A=0.2324, Test Loss B=1.1310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.186\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.96s/epoch, Train Loss=0.2518, Test Loss A=0.2930, Test Loss B=0.6435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.28\n",
      "----------------------------------------\n",
      "run_name-----------_15\n",
      "best_alpha---------0.05\n",
      "MSE_testset--------0.28\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.1912, Test Loss A=0.1211, Test Loss B=0.2907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.1929, Test Loss A=0.1216, Test Loss B=0.2957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.1901, Test Loss A=0.1407, Test Loss B=0.3058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.1907, Test Loss A=0.1246, Test Loss B=0.2976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.1902, Test Loss A=0.1350, Test Loss B=0.2883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.1889, Test Loss A=0.1201, Test Loss B=0.2833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.1884, Test Loss A=0.1281, Test Loss B=0.2920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.72s/epoch, Train Loss=0.1890, Test Loss A=0.1287, Test Loss B=0.2846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:26<00:00,  2.66s/epoch, Train Loss=0.1885, Test Loss A=0.1249, Test Loss B=0.2795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.57s/epoch, Train Loss=0.1900, Test Loss A=0.1277, Test Loss B=0.2919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.1917, Test Loss A=0.1287, Test Loss B=0.2838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.1892, Test Loss A=0.1335, Test Loss B=0.2806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.57s/epoch, Train Loss=0.1920, Test Loss A=0.1347, Test Loss B=0.2800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.1920, Test Loss A=0.1261, Test Loss B=0.2772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.1910, Test Loss A=0.1314, Test Loss B=0.2793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.50s/epoch, Train Loss=0.1910, Test Loss A=0.1350, Test Loss B=0.2896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.1903, Test Loss A=0.1322, Test Loss B=0.2928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.116\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.96s/epoch, Train Loss=0.1795, Test Loss A=0.1913, Test Loss B=0.4571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.19\n",
      "----------------------------------------\n",
      "run_name-----------_30\n",
      "best_alpha---------0.45\n",
      "MSE_testset--------0.19\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.7496, Test Loss A=0.5640, Test Loss B=4.9113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.7371, Test Loss A=0.6106, Test Loss B=5.0016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.7375, Test Loss A=0.5780, Test Loss B=4.9170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.7260, Test Loss A=0.6118, Test Loss B=5.1356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.50s/epoch, Train Loss=0.7276, Test Loss A=0.6408, Test Loss B=5.0350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.7193, Test Loss A=0.7292, Test Loss B=5.0662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.7217, Test Loss A=0.6560, Test Loss B=5.1278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7164, Test Loss A=0.7113, Test Loss B=5.0302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.7118, Test Loss A=0.7561, Test Loss B=5.0359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.7222, Test Loss A=0.6475, Test Loss B=4.9642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.7166, Test Loss A=0.6558, Test Loss B=5.0661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.42s/epoch, Train Loss=0.7058, Test Loss A=0.7232, Test Loss B=5.1137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.40s/epoch, Train Loss=0.7195, Test Loss A=0.6422, Test Loss B=5.0764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.7242, Test Loss A=0.7140, Test Loss B=4.9009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.7205, Test Loss A=0.6374, Test Loss B=4.8919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.41s/epoch, Train Loss=0.7104, Test Loss A=0.7521, Test Loss B=4.9063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7147, Test Loss A=0.7598, Test Loss B=5.0931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.589\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.98s/epoch, Train Loss=0.7266, Test Loss A=0.7480, Test Loss B=0.2477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.734\n",
      "----------------------------------------\n",
      "run_name-----------Roberta2/\n",
      "best_alpha---------0.05\n",
      "MSE_testset--------0.734\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.4296, Test Loss A=0.2592, Test Loss B=2.4339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.4304, Test Loss A=0.2561, Test Loss B=2.3692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.4247, Test Loss A=0.2647, Test Loss B=2.4141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.4236, Test Loss A=0.2579, Test Loss B=2.3633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.4243, Test Loss A=0.2640, Test Loss B=2.3769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.4239, Test Loss A=0.2618, Test Loss B=2.3796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.4234, Test Loss A=0.2683, Test Loss B=2.3749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.4216, Test Loss A=0.2530, Test Loss B=2.3207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.4182, Test Loss A=0.2542, Test Loss B=2.3695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.4178, Test Loss A=0.2889, Test Loss B=2.3438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.4191, Test Loss A=0.2590, Test Loss B=2.3282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.4171, Test Loss A=0.2538, Test Loss B=2.3180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.4156, Test Loss A=0.2821, Test Loss B=2.3408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.56s/epoch, Train Loss=0.4168, Test Loss A=0.2601, Test Loss B=2.3093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.50s/epoch, Train Loss=0.4145, Test Loss A=0.2787, Test Loss B=2.2630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.4168, Test Loss A=0.2597, Test Loss B=2.2878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.4169, Test Loss A=0.2834, Test Loss B=2.3371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.252\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.96s/epoch, Train Loss=0.4002, Test Loss A=0.3431, Test Loss B=2.0490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.343\n",
      "----------------------------------------\n",
      "run_name-----------Roberta2/_7\n",
      "best_alpha---------0.4\n",
      "MSE_testset--------0.343\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.2607, Test Loss A=0.1803, Test Loss B=1.1937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.2615, Test Loss A=0.1785, Test Loss B=1.2105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.2577, Test Loss A=0.1780, Test Loss B=1.2273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.2583, Test Loss A=0.1826, Test Loss B=1.2301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.2582, Test Loss A=0.1810, Test Loss B=1.1778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/epoch, Train Loss=0.2568, Test Loss A=0.1787, Test Loss B=1.2163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.50s/epoch, Train Loss=0.2548, Test Loss A=0.1778, Test Loss B=1.2228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.56s/epoch, Train Loss=0.2544, Test Loss A=0.1776, Test Loss B=1.2428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:26<00:00,  2.60s/epoch, Train Loss=0.2515, Test Loss A=0.1772, Test Loss B=1.2583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.2512, Test Loss A=0.1751, Test Loss B=1.1554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.2520, Test Loss A=0.1794, Test Loss B=1.2273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.2492, Test Loss A=0.1889, Test Loss B=1.1657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.59s/epoch, Train Loss=0.2455, Test Loss A=0.1790, Test Loss B=1.0903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.58s/epoch, Train Loss=0.2462, Test Loss A=0.1762, Test Loss B=1.0877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.2469, Test Loss A=0.1744, Test Loss B=1.1488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.2451, Test Loss A=0.1847, Test Loss B=1.0149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.2428, Test Loss A=0.1888, Test Loss B=0.9151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.18\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:31<00:00,  3.14s/epoch, Train Loss=0.2323, Test Loss A=0.3181, Test Loss B=0.4995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.276\n",
      "----------------------------------------\n",
      "run_name-----------Roberta2/_15\n",
      "best_alpha---------0.75\n",
      "MSE_testset--------0.276\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.1933, Test Loss A=0.1076, Test Loss B=0.3016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.57s/epoch, Train Loss=0.1927, Test Loss A=0.1090, Test Loss B=0.2996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.1909, Test Loss A=0.1071, Test Loss B=0.2861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.1899, Test Loss A=0.1069, Test Loss B=0.2816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/epoch, Train Loss=0.1891, Test Loss A=0.1009, Test Loss B=0.2972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.1886, Test Loss A=0.1003, Test Loss B=0.2942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.1889, Test Loss A=0.1013, Test Loss B=0.2830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.1865, Test Loss A=0.0967, Test Loss B=0.3112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/epoch, Train Loss=0.1871, Test Loss A=0.1015, Test Loss B=0.2924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.59s/epoch, Train Loss=0.1869, Test Loss A=0.1055, Test Loss B=0.2740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.59s/epoch, Train Loss=0.1864, Test Loss A=0.1065, Test Loss B=0.3327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.1854, Test Loss A=0.1005, Test Loss B=0.2708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.50s/epoch, Train Loss=0.1849, Test Loss A=0.1049, Test Loss B=0.2733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.1842, Test Loss A=0.1116, Test Loss B=0.2657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.1869, Test Loss A=0.1079, Test Loss B=0.2676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/epoch, Train Loss=0.1839, Test Loss A=0.1095, Test Loss B=0.2718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.58s/epoch, Train Loss=0.1824, Test Loss A=0.1094, Test Loss B=0.2688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.107\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.05s/epoch, Train Loss=0.1724, Test Loss A=0.1867, Test Loss B=0.4995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.182\n",
      "----------------------------------------\n",
      "run_name-----------Roberta2/_30\n",
      "best_alpha---------0.4\n",
      "MSE_testset--------0.182\n",
      "----------------------------------------\n",
      "(392, 523, 795) (392,) (392,)\n",
      "(56, 523, 795) (56,) (56,)\n",
      "(117, 523, 795) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.88s/epoch, Train Loss=0.7467, Test Loss A=0.5589, Test Loss B=4.9114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.85s/epoch, Train Loss=0.7411, Test Loss A=0.5791, Test Loss B=4.8575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.82s/epoch, Train Loss=0.7342, Test Loss A=0.5915, Test Loss B=4.9856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.82s/epoch, Train Loss=0.7389, Test Loss A=0.5675, Test Loss B=4.9401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.78s/epoch, Train Loss=0.7305, Test Loss A=0.6137, Test Loss B=4.9873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.75s/epoch, Train Loss=0.7318, Test Loss A=0.6271, Test Loss B=4.9193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.75s/epoch, Train Loss=0.7304, Test Loss A=0.6366, Test Loss B=4.8413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.85s/epoch, Train Loss=0.7293, Test Loss A=0.6351, Test Loss B=4.8983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.94s/epoch, Train Loss=0.7242, Test Loss A=0.6431, Test Loss B=4.8356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.87s/epoch, Train Loss=0.7210, Test Loss A=0.6734, Test Loss B=4.9430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.86s/epoch, Train Loss=0.7224, Test Loss A=0.6813, Test Loss B=4.9527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.84s/epoch, Train Loss=0.7231, Test Loss A=0.6526, Test Loss B=4.8893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.79s/epoch, Train Loss=0.7230, Test Loss A=0.6575, Test Loss B=4.8786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.88s/epoch, Train Loss=0.7193, Test Loss A=0.6702, Test Loss B=4.9247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.85s/epoch, Train Loss=0.7251, Test Loss A=0.6584, Test Loss B=5.0489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.86s/epoch, Train Loss=0.7215, Test Loss A=0.7051, Test Loss B=4.9726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.85s/epoch, Train Loss=0.7232, Test Loss A=0.6444, Test Loss B=4.9871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.554\n",
      "(448, 523, 795) (448,) (448,)\n",
      "(56, 523, 795) (56,) (56,)\n",
      "(117, 523, 795) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.21s/epoch, Train Loss=0.7030, Test Loss A=0.7012, Test Loss B=0.2769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.698\n",
      "----------------------------------------\n",
      "run_name-----------investopedia/\n",
      "best_alpha---------0.85\n",
      "MSE_testset--------0.698\n",
      "----------------------------------------\n",
      "(392, 523, 795) (392,) (392,)\n",
      "(56, 523, 795) (56,) (56,)\n",
      "(117, 523, 795) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.82s/epoch, Train Loss=0.4272, Test Loss A=0.2696, Test Loss B=2.3352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.82s/epoch, Train Loss=0.4268, Test Loss A=0.2666, Test Loss B=2.2682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.85s/epoch, Train Loss=0.4276, Test Loss A=0.2646, Test Loss B=2.2854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.83s/epoch, Train Loss=0.4276, Test Loss A=0.2850, Test Loss B=2.2884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.79s/epoch, Train Loss=0.4242, Test Loss A=0.2595, Test Loss B=2.3360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.4209, Test Loss A=0.2657, Test Loss B=2.3276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.70s/epoch, Train Loss=0.4240, Test Loss A=0.2626, Test Loss B=2.3495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.4238, Test Loss A=0.2690, Test Loss B=2.3060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.62s/epoch, Train Loss=0.4216, Test Loss A=0.2641, Test Loss B=2.3629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.4175, Test Loss A=0.2596, Test Loss B=2.3285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.4212, Test Loss A=0.2703, Test Loss B=2.3360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.4219, Test Loss A=0.2627, Test Loss B=2.3334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.70s/epoch, Train Loss=0.4195, Test Loss A=0.2660, Test Loss B=2.2880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.62s/epoch, Train Loss=0.4183, Test Loss A=0.2581, Test Loss B=2.3040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.69s/epoch, Train Loss=0.4192, Test Loss A=0.2462, Test Loss B=2.3152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.68s/epoch, Train Loss=0.4192, Test Loss A=0.2535, Test Loss B=2.3129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.72s/epoch, Train Loss=0.4160, Test Loss A=0.2559, Test Loss B=2.2770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.256\n",
      "(448, 523, 795) (448,) (448,)\n",
      "(56, 523, 795) (56,) (56,)\n",
      "(117, 523, 795) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.97s/epoch, Train Loss=0.3970, Test Loss A=0.3235, Test Loss B=2.0326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.324\n",
      "----------------------------------------\n",
      "run_name-----------investopedia/_7\n",
      "best_alpha---------0.75\n",
      "MSE_testset--------0.324\n",
      "----------------------------------------\n",
      "(392, 523, 795) (392,) (392,)\n",
      "(56, 523, 795) (56,) (56,)\n",
      "(117, 523, 795) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.72s/epoch, Train Loss=0.2628, Test Loss A=0.1838, Test Loss B=1.1653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.2608, Test Loss A=0.1846, Test Loss B=1.1952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.71s/epoch, Train Loss=0.2605, Test Loss A=0.1824, Test Loss B=1.1249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.69s/epoch, Train Loss=0.2580, Test Loss A=0.1774, Test Loss B=1.1282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.69s/epoch, Train Loss=0.2589, Test Loss A=0.1750, Test Loss B=1.1292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.2559, Test Loss A=0.1838, Test Loss B=1.1956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.2560, Test Loss A=0.1755, Test Loss B=1.1254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.71s/epoch, Train Loss=0.2540, Test Loss A=0.1733, Test Loss B=1.1022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.71s/epoch, Train Loss=0.2532, Test Loss A=0.1764, Test Loss B=1.1810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.70s/epoch, Train Loss=0.2550, Test Loss A=0.1743, Test Loss B=1.1616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.69s/epoch, Train Loss=0.2512, Test Loss A=0.1757, Test Loss B=1.1563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.63s/epoch, Train Loss=0.2515, Test Loss A=0.1802, Test Loss B=1.1024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.2497, Test Loss A=0.1729, Test Loss B=1.0516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.2519, Test Loss A=0.1756, Test Loss B=1.0242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.2485, Test Loss A=0.1695, Test Loss B=1.0026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.2494, Test Loss A=0.1723, Test Loss B=1.0977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.2508, Test Loss A=0.1771, Test Loss B=1.0087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.177\n",
      "(448, 523, 795) (448,) (448,)\n",
      "(56, 523, 795) (56,) (56,)\n",
      "(117, 523, 795) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:20<00:00,  2.00s/epoch, Train Loss=0.2401, Test Loss A=0.2633, Test Loss B=0.5573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.263\n",
      "----------------------------------------\n",
      "run_name-----------investopedia/_15\n",
      "best_alpha---------0.75\n",
      "MSE_testset--------0.263\n",
      "----------------------------------------\n",
      "(392, 523, 795) (392,) (392,)\n",
      "(56, 523, 795) (56,) (56,)\n",
      "(117, 523, 795) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.70s/epoch, Train Loss=0.1918, Test Loss A=0.1128, Test Loss B=0.2909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.70s/epoch, Train Loss=0.1917, Test Loss A=0.1129, Test Loss B=0.2766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.1902, Test Loss A=0.1070, Test Loss B=0.2963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.1915, Test Loss A=0.1108, Test Loss B=0.2794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.76s/epoch, Train Loss=0.1884, Test Loss A=0.1048, Test Loss B=0.2865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.74s/epoch, Train Loss=0.1912, Test Loss A=0.1060, Test Loss B=0.2847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.68s/epoch, Train Loss=0.1884, Test Loss A=0.1021, Test Loss B=0.3051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.1880, Test Loss A=0.1040, Test Loss B=0.2851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.1880, Test Loss A=0.1056, Test Loss B=0.2869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.1892, Test Loss A=0.1002, Test Loss B=0.2798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.69s/epoch, Train Loss=0.1867, Test Loss A=0.1001, Test Loss B=0.2782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.1869, Test Loss A=0.1032, Test Loss B=0.2815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.1859, Test Loss A=0.1033, Test Loss B=0.2730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.71s/epoch, Train Loss=0.1863, Test Loss A=0.1024, Test Loss B=0.2860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.70s/epoch, Train Loss=0.1888, Test Loss A=0.1057, Test Loss B=0.2947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.70s/epoch, Train Loss=0.1880, Test Loss A=0.1085, Test Loss B=0.2816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.63s/epoch, Train Loss=0.1851, Test Loss A=0.1085, Test Loss B=0.2866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.108\n",
      "(448, 523, 795) (448,) (448,)\n",
      "(56, 523, 795) (56,) (56,)\n",
      "(117, 523, 795) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  2.00s/epoch, Train Loss=0.1768, Test Loss A=0.1883, Test Loss B=0.4765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.187\n",
      "----------------------------------------\n",
      "run_name-----------investopedia/_30\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.187\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.7451, Test Loss A=0.5822, Test Loss B=4.8407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/epoch, Train Loss=0.7441, Test Loss A=0.5770, Test Loss B=4.9290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.38s/epoch, Train Loss=0.7333, Test Loss A=0.5933, Test Loss B=4.9167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.7353, Test Loss A=0.6200, Test Loss B=5.0370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.7296, Test Loss A=0.6264, Test Loss B=4.8640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7305, Test Loss A=0.6174, Test Loss B=4.8668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7203, Test Loss A=0.6215, Test Loss B=4.9204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.7212, Test Loss A=0.6583, Test Loss B=4.9506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7224, Test Loss A=0.6730, Test Loss B=4.8957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.42s/epoch, Train Loss=0.7174, Test Loss A=0.6848, Test Loss B=4.9041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.42s/epoch, Train Loss=0.7185, Test Loss A=0.7097, Test Loss B=4.8998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7199, Test Loss A=0.6664, Test Loss B=5.0604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.7210, Test Loss A=0.7046, Test Loss B=4.9638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7196, Test Loss A=0.6928, Test Loss B=4.9840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.7172, Test Loss A=0.7057, Test Loss B=4.8502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.42s/epoch, Train Loss=0.7226, Test Loss A=0.6428, Test Loss B=4.9434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.7210, Test Loss A=0.6865, Test Loss B=4.9416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.587\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.94s/epoch, Train Loss=0.6982, Test Loss A=0.6932, Test Loss B=0.2565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.693\n",
      "----------------------------------------\n",
      "run_name-----------bge/\n",
      "best_alpha---------0.6\n",
      "MSE_testset--------0.693\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.4301, Test Loss A=0.2633, Test Loss B=2.4041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.4313, Test Loss A=0.2824, Test Loss B=2.3856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.4277, Test Loss A=0.2777, Test Loss B=2.3667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.4243, Test Loss A=0.2653, Test Loss B=2.2893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.4239, Test Loss A=0.2815, Test Loss B=2.3589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.4245, Test Loss A=0.2708, Test Loss B=2.3234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.4199, Test Loss A=0.2787, Test Loss B=2.3289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.4288, Test Loss A=0.2770, Test Loss B=2.3707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.4239, Test Loss A=0.2701, Test Loss B=2.4045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.4194, Test Loss A=0.2767, Test Loss B=2.3439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.4179, Test Loss A=0.2688, Test Loss B=2.2902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.4160, Test Loss A=0.2705, Test Loss B=2.3460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.4198, Test Loss A=0.2620, Test Loss B=2.3139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.4206, Test Loss A=0.2533, Test Loss B=2.3412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.4182, Test Loss A=0.2734, Test Loss B=2.3362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.4151, Test Loss A=0.2578, Test Loss B=2.3069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.58s/epoch, Train Loss=0.4139, Test Loss A=0.2724, Test Loss B=2.2968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.268\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.02s/epoch, Train Loss=0.3943, Test Loss A=0.3242, Test Loss B=2.0494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.324\n",
      "----------------------------------------\n",
      "run_name-----------bge/_7\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.324\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.2602, Test Loss A=0.1806, Test Loss B=1.2837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.2621, Test Loss A=0.1822, Test Loss B=1.2283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.50s/epoch, Train Loss=0.2591, Test Loss A=0.1755, Test Loss B=1.2143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.2578, Test Loss A=0.1800, Test Loss B=1.2010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.2557, Test Loss A=0.1741, Test Loss B=1.2007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.2585, Test Loss A=0.1817, Test Loss B=1.2760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.56s/epoch, Train Loss=0.2541, Test Loss A=0.1759, Test Loss B=1.2241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:26<00:00,  2.65s/epoch, Train Loss=0.2539, Test Loss A=0.1779, Test Loss B=1.2536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/epoch, Train Loss=0.2516, Test Loss A=0.1788, Test Loss B=1.1738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.2536, Test Loss A=0.1759, Test Loss B=1.2146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.2507, Test Loss A=0.1753, Test Loss B=1.1805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.56s/epoch, Train Loss=0.2521, Test Loss A=0.1760, Test Loss B=1.2313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.2509, Test Loss A=0.1785, Test Loss B=1.1111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.58s/epoch, Train Loss=0.2514, Test Loss A=0.1817, Test Loss B=1.1504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.2488, Test Loss A=0.1721, Test Loss B=1.1244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.2503, Test Loss A=0.1910, Test Loss B=1.0346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/epoch, Train Loss=0.2497, Test Loss A=0.1804, Test Loss B=0.9973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.178\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.06s/epoch, Train Loss=0.2357, Test Loss A=0.2651, Test Loss B=0.5462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.265\n",
      "----------------------------------------\n",
      "run_name-----------bge/_15\n",
      "best_alpha---------0.75\n",
      "MSE_testset--------0.265\n",
      "----------------------------------------\n",
      "(392, 523, 1051) (392,) (392,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.1942, Test Loss A=0.1127, Test Loss B=0.3076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.1910, Test Loss A=0.1062, Test Loss B=0.3011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.1913, Test Loss A=0.1059, Test Loss B=0.2906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/epoch, Train Loss=0.1890, Test Loss A=0.1067, Test Loss B=0.3071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/epoch, Train Loss=0.1900, Test Loss A=0.1024, Test Loss B=0.2923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.1879, Test Loss A=0.1062, Test Loss B=0.2859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.1888, Test Loss A=0.1072, Test Loss B=0.2800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.1887, Test Loss A=0.1057, Test Loss B=0.2886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.57s/epoch, Train Loss=0.1870, Test Loss A=0.1056, Test Loss B=0.2809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/epoch, Train Loss=0.1855, Test Loss A=0.1041, Test Loss B=0.2761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.1850, Test Loss A=0.1078, Test Loss B=0.2649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.51s/epoch, Train Loss=0.1865, Test Loss A=0.1068, Test Loss B=0.2738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.1865, Test Loss A=0.1089, Test Loss B=0.2760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/epoch, Train Loss=0.1877, Test Loss A=0.1085, Test Loss B=0.2805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.50s/epoch, Train Loss=0.1859, Test Loss A=0.1099, Test Loss B=0.2788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.49s/epoch, Train Loss=0.1877, Test Loss A=0.1094, Test Loss B=0.2710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.54s/epoch, Train Loss=0.1878, Test Loss A=0.1079, Test Loss B=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.108\n",
      "(448, 523, 1051) (448,) (448,)\n",
      "(56, 523, 1051) (56,) (56,)\n",
      "(117, 523, 1051) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.98s/epoch, Train Loss=0.1784, Test Loss A=0.1787, Test Loss B=0.4899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.179\n",
      "----------------------------------------\n",
      "run_name-----------bge/_30\n",
      "best_alpha---------0.25\n",
      "MSE_testset--------0.179\n",
      "----------------------------------------\n",
      "(392, 523, 327) (392,) (392,)\n",
      "(56, 523, 327) (56,) (56,)\n",
      "(117, 523, 327) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.42epoch/s, Train Loss=0.7512, Test Loss A=0.5535, Test Loss B=5.1305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.40epoch/s, Train Loss=0.7593, Test Loss A=0.5713, Test Loss B=5.0591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.45epoch/s, Train Loss=0.7508, Test Loss A=0.5763, Test Loss B=4.9367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.38epoch/s, Train Loss=0.7517, Test Loss A=0.5797, Test Loss B=4.9815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.51epoch/s, Train Loss=0.7558, Test Loss A=0.5705, Test Loss B=5.0130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.47epoch/s, Train Loss=0.7434, Test Loss A=0.5691, Test Loss B=5.0320]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.51epoch/s, Train Loss=0.7559, Test Loss A=0.6273, Test Loss B=4.9976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.51epoch/s, Train Loss=0.7509, Test Loss A=0.5834, Test Loss B=5.0051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.44epoch/s, Train Loss=0.7440, Test Loss A=0.5899, Test Loss B=4.9374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.44epoch/s, Train Loss=0.7447, Test Loss A=0.5713, Test Loss B=4.9331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.48epoch/s, Train Loss=0.7478, Test Loss A=0.6112, Test Loss B=5.0277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.39epoch/s, Train Loss=0.7473, Test Loss A=0.5740, Test Loss B=5.0009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.46epoch/s, Train Loss=0.7466, Test Loss A=0.5981, Test Loss B=5.0970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.50epoch/s, Train Loss=0.7466, Test Loss A=0.5632, Test Loss B=5.0112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.51epoch/s, Train Loss=0.7418, Test Loss A=0.5561, Test Loss B=5.0844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.52epoch/s, Train Loss=0.7439, Test Loss A=0.5681, Test Loss B=5.0542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.44epoch/s, Train Loss=0.7473, Test Loss A=0.6212, Test Loss B=5.1214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.621\n",
      "(448, 523, 327) (448,) (448,)\n",
      "(56, 523, 327) (56,) (56,)\n",
      "(117, 523, 327) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29epoch/s, Train Loss=0.7322, Test Loss A=0.7625, Test Loss B=0.2902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.743\n",
      "----------------------------------------\n",
      "run_name-----------glove/\n",
      "best_alpha---------0.05\n",
      "MSE_testset--------0.743\n",
      "----------------------------------------\n",
      "(392, 523, 327) (392,) (392,)\n",
      "(56, 523, 327) (56,) (56,)\n",
      "(117, 523, 327) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.41epoch/s, Train Loss=0.4295, Test Loss A=0.2654, Test Loss B=2.3270]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.41epoch/s, Train Loss=0.4343, Test Loss A=0.2988, Test Loss B=2.3691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.40epoch/s, Train Loss=0.4296, Test Loss A=0.2767, Test Loss B=2.4124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.34epoch/s, Train Loss=0.4325, Test Loss A=0.2832, Test Loss B=2.3403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.46epoch/s, Train Loss=0.4310, Test Loss A=0.2610, Test Loss B=2.3742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.51epoch/s, Train Loss=0.4307, Test Loss A=0.2825, Test Loss B=2.3706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.54epoch/s, Train Loss=0.4297, Test Loss A=0.2904, Test Loss B=2.3321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.47epoch/s, Train Loss=0.4324, Test Loss A=0.2747, Test Loss B=2.3912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.47epoch/s, Train Loss=0.4341, Test Loss A=0.2873, Test Loss B=2.3268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.48epoch/s, Train Loss=0.4315, Test Loss A=0.2898, Test Loss B=2.3626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.46epoch/s, Train Loss=0.4317, Test Loss A=0.2906, Test Loss B=2.3193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.53epoch/s, Train Loss=0.4308, Test Loss A=0.2884, Test Loss B=2.3233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.50epoch/s, Train Loss=0.4312, Test Loss A=0.2634, Test Loss B=2.3139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.51epoch/s, Train Loss=0.4320, Test Loss A=0.2612, Test Loss B=2.3238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.52epoch/s, Train Loss=0.4291, Test Loss A=0.2952, Test Loss B=2.3653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.54epoch/s, Train Loss=0.4326, Test Loss A=0.2784, Test Loss B=2.3326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.42epoch/s, Train Loss=0.4346, Test Loss A=0.2846, Test Loss B=2.3129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.277\n",
      "(448, 523, 327) (448,) (448,)\n",
      "(56, 523, 327) (56,) (56,)\n",
      "(117, 523, 327) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.18epoch/s, Train Loss=0.4093, Test Loss A=0.3729, Test Loss B=2.0087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.372\n",
      "----------------------------------------\n",
      "run_name-----------glove/_7\n",
      "best_alpha---------0.25\n",
      "MSE_testset--------0.372\n",
      "----------------------------------------\n",
      "(392, 523, 327) (392,) (392,)\n",
      "(56, 523, 327) (56,) (56,)\n",
      "(117, 523, 327) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.41epoch/s, Train Loss=0.2626, Test Loss A=0.1947, Test Loss B=1.0505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.41epoch/s, Train Loss=0.2623, Test Loss A=0.1837, Test Loss B=1.0084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.37epoch/s, Train Loss=0.2612, Test Loss A=0.1836, Test Loss B=1.0175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.39epoch/s, Train Loss=0.2603, Test Loss A=0.1846, Test Loss B=0.9358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30epoch/s, Train Loss=0.2614, Test Loss A=0.1827, Test Loss B=1.0586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27epoch/s, Train Loss=0.2603, Test Loss A=0.1839, Test Loss B=0.9390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.32epoch/s, Train Loss=0.2599, Test Loss A=0.1823, Test Loss B=0.9719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.37epoch/s, Train Loss=0.2620, Test Loss A=0.1863, Test Loss B=1.0456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.44epoch/s, Train Loss=0.2618, Test Loss A=0.1841, Test Loss B=0.9654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.38epoch/s, Train Loss=0.2585, Test Loss A=0.1836, Test Loss B=0.9775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30epoch/s, Train Loss=0.2609, Test Loss A=0.1886, Test Loss B=0.9657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.49epoch/s, Train Loss=0.2607, Test Loss A=0.1809, Test Loss B=0.9543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.40epoch/s, Train Loss=0.2611, Test Loss A=0.1841, Test Loss B=0.9725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.50epoch/s, Train Loss=0.2592, Test Loss A=0.1819, Test Loss B=0.9409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.48epoch/s, Train Loss=0.2617, Test Loss A=0.1991, Test Loss B=0.8994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.41epoch/s, Train Loss=0.2590, Test Loss A=0.1826, Test Loss B=0.9732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.40epoch/s, Train Loss=0.2594, Test Loss A=0.1857, Test Loss B=0.9235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.186\n",
      "(448, 523, 327) (448,) (448,)\n",
      "(56, 523, 327) (56,) (56,)\n",
      "(117, 523, 327) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.25epoch/s, Train Loss=0.2502, Test Loss A=0.2837, Test Loss B=0.5124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.284\n",
      "----------------------------------------\n",
      "run_name-----------glove/_15\n",
      "best_alpha---------0.6\n",
      "MSE_testset--------0.284\n",
      "----------------------------------------\n",
      "(392, 523, 327) (392,) (392,)\n",
      "(56, 523, 327) (56,) (56,)\n",
      "(117, 523, 327) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.35epoch/s, Train Loss=0.1916, Test Loss A=0.1180, Test Loss B=0.2953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.16epoch/s, Train Loss=0.1916, Test Loss A=0.1183, Test Loss B=0.2733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.23epoch/s, Train Loss=0.1926, Test Loss A=0.1153, Test Loss B=0.3131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.35epoch/s, Train Loss=0.1940, Test Loss A=0.1199, Test Loss B=0.2767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.41epoch/s, Train Loss=0.1920, Test Loss A=0.1189, Test Loss B=0.2809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.41epoch/s, Train Loss=0.1943, Test Loss A=0.1234, Test Loss B=0.2786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.37epoch/s, Train Loss=0.1921, Test Loss A=0.1180, Test Loss B=0.2782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.36epoch/s, Train Loss=0.1924, Test Loss A=0.1166, Test Loss B=0.2768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30epoch/s, Train Loss=0.1916, Test Loss A=0.1206, Test Loss B=0.2836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.33epoch/s, Train Loss=0.1930, Test Loss A=0.1148, Test Loss B=0.2825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.38epoch/s, Train Loss=0.1926, Test Loss A=0.1163, Test Loss B=0.2864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.47epoch/s, Train Loss=0.1927, Test Loss A=0.1183, Test Loss B=0.3108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.51epoch/s, Train Loss=0.1928, Test Loss A=0.1164, Test Loss B=0.2773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.52epoch/s, Train Loss=0.1937, Test Loss A=0.1181, Test Loss B=0.2710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.51epoch/s, Train Loss=0.1941, Test Loss A=0.1159, Test Loss B=0.2825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.41epoch/s, Train Loss=0.1933, Test Loss A=0.1170, Test Loss B=0.2790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.34epoch/s, Train Loss=0.1917, Test Loss A=0.1257, Test Loss B=0.2758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 0.126\n",
      "(448, 523, 327) (448,) (448,)\n",
      "(56, 523, 327) (56,) (56,)\n",
      "(117, 523, 327) (117,) (117,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.16epoch/s, Train Loss=0.1843, Test Loss A=0.2264, Test Loss B=0.4581]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.226\n",
      "----------------------------------------\n",
      "run_name-----------glove/_30\n",
      "best_alpha---------0.15\n",
      "MSE_testset--------0.226\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_results = []\n",
    "for data_directory in directories: # different feature engineering features\n",
    "    for n_days in all_n_days: \n",
    "        best_alpha, MSE_testset = train_val_test(data_directory, n_days)\n",
    "        final_results.append([data_directory, n_days, best_alpha, MSE_testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_30</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roberta2/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Roberta2/_7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Roberta2/_15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Roberta2/_30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>investopedia/</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>investopedia/_7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>investopedia/_15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>investopedia/_30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bge/</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bge/_7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bge/_15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bge/_30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>glove/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>glove/_7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>glove/_15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>glove/_30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0     1      2\n",
       "0                     0.05  0.725\n",
       "1                 _7  0.25  0.362\n",
       "2                _15  0.05  0.280\n",
       "3                _30  0.45  0.190\n",
       "4          Roberta2/  0.05  0.734\n",
       "5        Roberta2/_7  0.40  0.343\n",
       "6       Roberta2/_15  0.75  0.276\n",
       "7       Roberta2/_30  0.40  0.182\n",
       "8      investopedia/  0.85  0.698\n",
       "9    investopedia/_7  0.75  0.324\n",
       "10  investopedia/_15  0.75  0.263\n",
       "11  investopedia/_30  0.50  0.187\n",
       "12              bge/  0.60  0.693\n",
       "13            bge/_7  0.70  0.324\n",
       "14           bge/_15  0.75  0.265\n",
       "15           bge/_30  0.25  0.179\n",
       "16            glove/  0.05  0.743\n",
       "17          glove/_7  0.25  0.372\n",
       "18         glove/_15  0.60  0.284\n",
       "19         glove/_30  0.15  0.226"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.DataFrame(final_results, columns=['data_directory', 'n_days', 'best_alpha', 'MSE_testset'])\n",
    "final_results.to_csv('data/final_results.csv', index=False)\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha3</th>\n",
       "      <th>alpha_15</th>\n",
       "      <th>alpha_30</th>\n",
       "      <th>alpha_7</th>\n",
       "      <th>MSE3</th>\n",
       "      <th>MSE_15</th>\n",
       "      <th>MSE_30</th>\n",
       "      <th>MSE_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberta2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_15</th>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_30</th>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_7</th>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bge</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glove</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investopedia</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              alpha3  alpha_15  alpha_30  alpha_7   MSE3  MSE_15  MSE_30  \\\n",
       "model                                                                      \n",
       "NaN             0.05       NaN       NaN      NaN  0.725     NaN     NaN   \n",
       "Roberta2        0.05      0.75      0.40     0.40  0.734   0.276   0.182   \n",
       "_15             0.05       NaN       NaN      NaN  0.280     NaN     NaN   \n",
       "_30             0.45       NaN       NaN      NaN  0.190     NaN     NaN   \n",
       "_7              0.25       NaN       NaN      NaN  0.362     NaN     NaN   \n",
       "bge             0.60      0.75      0.25     0.70  0.693   0.265   0.179   \n",
       "glove           0.05      0.60      0.15     0.25  0.743   0.284   0.226   \n",
       "investopedia    0.85      0.75      0.50     0.75  0.698   0.263   0.187   \n",
       "\n",
       "              MSE_7  \n",
       "model                \n",
       "NaN             NaN  \n",
       "Roberta2      0.343  \n",
       "_15             NaN  \n",
       "_30             NaN  \n",
       "_7              NaN  \n",
       "bge           0.324  \n",
       "glove         0.372  \n",
       "investopedia  0.324  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "final_results_pivoted = final_results.pivot(index='data_directory', columns='n_days', values=['best_alpha', 'MSE_testset'])\n",
    "final_results_pivoted.columns = [f\"{n_days}_{metric}\" for metric, n_days in final_results_pivoted.columns]\n",
    "final_results_pivoted.reset_index(inplace=True)\n",
    "final_results_pivoted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>alpha</th>\n",
       "      <th>MSE</th>\n",
       "      <th>model</th>\n",
       "      <th>n_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.362</td>\n",
       "      <td>_7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.280</td>\n",
       "      <td>_15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_30</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.190</td>\n",
       "      <td>_30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roberta2/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.734</td>\n",
       "      <td>Roberta2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Roberta2/_7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.343</td>\n",
       "      <td>Roberta2</td>\n",
       "      <td>_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Roberta2/_15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.276</td>\n",
       "      <td>Roberta2</td>\n",
       "      <td>_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Roberta2/_30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.182</td>\n",
       "      <td>Roberta2</td>\n",
       "      <td>_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>investopedia/</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.698</td>\n",
       "      <td>investopedia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>investopedia/_7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.324</td>\n",
       "      <td>investopedia</td>\n",
       "      <td>_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>investopedia/_15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.263</td>\n",
       "      <td>investopedia</td>\n",
       "      <td>_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>investopedia/_30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.187</td>\n",
       "      <td>investopedia</td>\n",
       "      <td>_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bge/</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.693</td>\n",
       "      <td>bge</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bge/_7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.324</td>\n",
       "      <td>bge</td>\n",
       "      <td>_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bge/_15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.265</td>\n",
       "      <td>bge</td>\n",
       "      <td>_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bge/_30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.179</td>\n",
       "      <td>bge</td>\n",
       "      <td>_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>glove/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.743</td>\n",
       "      <td>glove</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>glove/_7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.372</td>\n",
       "      <td>glove</td>\n",
       "      <td>_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>glove/_15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.284</td>\n",
       "      <td>glove</td>\n",
       "      <td>_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>glove/_30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.226</td>\n",
       "      <td>glove</td>\n",
       "      <td>_30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            run_name  alpha    MSE         model n_days\n",
       "0                      0.05  0.725           NaN      3\n",
       "1                 _7   0.25  0.362            _7      3\n",
       "2                _15   0.05  0.280           _15      3\n",
       "3                _30   0.45  0.190           _30      3\n",
       "4          Roberta2/   0.05  0.734      Roberta2      3\n",
       "5        Roberta2/_7   0.40  0.343      Roberta2     _7\n",
       "6       Roberta2/_15   0.75  0.276      Roberta2    _15\n",
       "7       Roberta2/_30   0.40  0.182      Roberta2    _30\n",
       "8      investopedia/   0.85  0.698  investopedia      3\n",
       "9    investopedia/_7   0.75  0.324  investopedia     _7\n",
       "10  investopedia/_15   0.75  0.263  investopedia    _15\n",
       "11  investopedia/_30   0.50  0.187  investopedia    _30\n",
       "12              bge/   0.60  0.693           bge      3\n",
       "13            bge/_7   0.70  0.324           bge     _7\n",
       "14           bge/_15   0.75  0.265           bge    _15\n",
       "15           bge/_30   0.25  0.179           bge    _30\n",
       "16            glove/   0.05  0.743         glove      3\n",
       "17          glove/_7   0.25  0.372         glove     _7\n",
       "18         glove/_15   0.60  0.284         glove    _15\n",
       "19         glove/_30   0.15  0.226         glove    _30"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-17ac5b5f63da0e9c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-17ac5b5f63da0e9c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (1896645534.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[100], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    :)\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    ":)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
