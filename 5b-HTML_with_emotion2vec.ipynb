{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earnings Call Project: Data Cleaning\n",
    "<br>\n",
    "CIS 831 Deep Learning â€“ Term Project<br>\n",
    "Kansas State University\n",
    "<br><br>\n",
    "James Chapman<br>\n",
    "John Woods<br>\n",
    "Nathan Diehl<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the transformer architecture from the [HTML paper](https://www.researchgate.net/publication/340385140_HTML_Hierarchical_Transformer-based_Multi-task_Learning_for_Volatility_Prediction). \n",
    "\n",
    "From the previous notebooks, we have features for both audio and text, of each sentence, of each meeting.<br>\n",
    "- audio \n",
    "    - PRAAT (27 features)\n",
    "- text\n",
    "    - GLOVE (300 features)\n",
    "    - ROBERTA (1024 features)\n",
    "    - ROBERTA with averaging (1024 features)\n",
    "    - FinLang investopedia (768 features) from huggingface sentencetransformers\n",
    "    - BGE financial (1024 features) from huggingface sentencetransformers\n",
    "\n",
    "This notebook performs 3 nested loops. Each audio/text pair, and for each N_DAYS, we train models with 17 different alpha values. The alpha value the lowest MSE, based on the validation set, is been used to train a model with Both training and validation sets. This model is finally tested on the test set.\n",
    "\n",
    "These notebooks also give us a playground to work with the data, and test the models. Now we can insert sentiment detection, segmentation of the text, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "torch.cuda.manual_seed_all(777)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static hyper-parameters from paper\n",
    "max_norm = 1.0\n",
    "num_epochs = 10\n",
    "warmup_steps = 1000\n",
    "batch_size=4\n",
    "dropout=0.5\n",
    "heads=2\n",
    "depth=2\n",
    "\n",
    "lr=0.000002 # 1/10 learning rate of paper\n",
    "\n",
    "all_n_days = ['3', '7', '15', '30']\n",
    "alphas = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "is_using_scaler = True # whether or not to use standardscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the hierarchical transformer from the HTML paper.\n",
    "\n",
    "## This is taken directly from the GitHub account for HTML paper.\n",
    "- a few adaptions are highlighted with ##############################################\n",
    "\n",
    "\n",
    "- [GitHub HTML - util.py](https://github.com/YangLinyi/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/blob/master/Model/Sentence-Level-Transformer/transformers/util/util.py)\n",
    "- [GitHub HTML - transformers_gpu.py](https://github.com/YangLinyi/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/blob/master/Model/Sentence-Level-Transformer/transformers/transformers_gpu.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://github.com/YangLinyi/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/blob/master/Model/Sentence-Level-Transformer/transformers/transformers_gpu.py\n",
    "def mask_(matrices, maskval=0.0, mask_diagonal=True):\n",
    "    \"\"\"\n",
    "    Masks out all values in the given batch of matrices where i <= j holds,\n",
    "    i < j if mask_diagonal is false\n",
    "\n",
    "    In place operation\n",
    "\n",
    "    :param tns:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    b, h, w = matrices.size()\n",
    "\n",
    "    indices = torch.triu_indices(h, w, offset=0 if mask_diagonal else 1)\n",
    "    matrices[:, indices, indices[1]] = maskval\n",
    "\n",
    "def contains_nan(tensor):\n",
    "    return bool((tensor != tensor).sum() > 0)\n",
    "\n",
    "# https://github.com/YangLinyi/HTML-Hierarchical-Transformer-based-Multi-task-Learning-for-Volatility-Prediction/blob/master/Model/Sentence-Level-Transformer/transformers/transformers_gpu.py\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, emb, heads=8, mask=False):\n",
    "        \"\"\"\n",
    "        :param emb:\n",
    "        :param heads:\n",
    "        :param mask:\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = emb\n",
    "        self.heads = heads\n",
    "        self.mask = mask\n",
    "\n",
    "        self.tokeys = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.toqueries = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.tovalues = nn.Linear(emb, emb * heads, bias=False)\n",
    "\n",
    "        self.unifyheads = nn.Linear(heads * emb, emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        b, t, e = x.size()\n",
    "        h = self.heads\n",
    "        assert e == self.emb\n",
    "\n",
    "        keys    = self.tokeys(x)   .view(b, t, h, e)\n",
    "        queries = self.toqueries(x).view(b, t, h, e)\n",
    "        values  = self.tovalues(x) .view(b, t, h, e)\n",
    "\n",
    "        # compute scaled dot-product self-attention\n",
    "\n",
    "        # - fold heads into the batch dimension\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "\n",
    "        queries = queries / (e ** (1/4))\n",
    "        keys    = keys / (e ** (1/4))\n",
    "        # - Instead of dividing the dot products by sqrt(e), we scale the keys and values.\n",
    "        #   This should be more memory efficient\n",
    "\n",
    "        # - get dot product of queries and keys, and scale\n",
    "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "\n",
    "        assert dot.size() == (b*h, t, t)\n",
    "\n",
    "        if self.mask: # mask out the lower half of the dot matrix,including the diagonal\n",
    "            mask_(dot, maskval=float('-inf'), mask_diagonal=False)\n",
    "\n",
    "        dot = F.softmax(dot, dim=2) # dot now has row-wise self-attention probabilities\n",
    "\n",
    "        ##############################################\n",
    "        ##############################################\n",
    "        # assert not util.contains_nan(dot[:, 1:, :]) # only the forst row may contain nan\n",
    "        assert not contains_nan(dot[:, 1:, :]) # only the forst row may contain nan \n",
    "        ##############################################\n",
    "        ##############################################\n",
    "        \n",
    "        if self.mask == 'first':\n",
    "            dot = dot.clone()\n",
    "            dot[:, :1, :] = 0.0\n",
    "            # - The first row of the first attention matrix is entirely masked out, so the softmax operation results\n",
    "            #   in a division by zero. We set this row to zero by hand to get rid of the NaNs\n",
    "\n",
    "        # apply the self attention to the values\n",
    "        out = torch.bmm(dot, values).view(b, h, t, e)\n",
    "\n",
    "        # swap h, t back, unify heads\n",
    "        out = out.transpose(1, 2).contiguous().view(b, t, h * e)\n",
    "\n",
    "        return self.unifyheads(out)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb, heads, mask, seq_length, ff_hidden_mult=4, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = SelfAttention(emb, heads=heads, mask=mask)\n",
    "        self.mask = mask\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(emb)\n",
    "        self.norm2 = nn.LayerNorm(emb)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(emb, ff_hidden_mult * emb),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_mult * emb, emb)\n",
    "        )\n",
    "\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        attended = self.attention(x)\n",
    "\n",
    "        x = self.norm1(attended + x)\n",
    "\n",
    "        x = self.do(x)\n",
    "\n",
    "        fedforward = self.ff(x)\n",
    "\n",
    "        x = self.norm2(fedforward + x)\n",
    "\n",
    "        x = self.do(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class RTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer for sequences Regression    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emb, heads, depth, seq_length, num_tokens, num_classes, max_pool=True, dropout=0.0):\n",
    "        \"\"\"\n",
    "        emb: Embedding dimension\n",
    "        heads: nr. of attention heads\n",
    "        depth: Number of transformer blocks\n",
    "        seq_length: Expected maximum sequence length\n",
    "        num_tokens: Number of tokens (usually words) in the vocabulary\n",
    "        num_classes: Number of classes.\n",
    "        max_pool: If true, use global max pooling in the last layer. If false, use global\n",
    "                         average pooling.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_tokens, self.max_pool = num_tokens, max_pool\n",
    "\n",
    "        #self.token_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=num_tokens)\n",
    "        self.pos_embedding = nn.Embedding(embedding_dim=emb, num_embeddings=seq_length)\n",
    "\n",
    "        tblocks = []\n",
    "        for i in range(depth):\n",
    "            tblocks.append(\n",
    "                TransformerBlock(emb=emb, heads=heads, seq_length=seq_length, mask=False, dropout=dropout))\n",
    "\n",
    "        self.tblocks = nn.Sequential(*tblocks)\n",
    "\n",
    "        self.toprobs = nn.Linear(emb, num_classes)\n",
    "        self.toprobs_b = nn.Linear(emb, num_classes)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: A batch by sequence length integer tensor of token indices.\n",
    "        :return: predicted log-probability vectors for each token based on the preceding tokens.\n",
    "        \"\"\"\n",
    "        sentences_emb = x\n",
    "        b, t, e = x.size()\n",
    "\n",
    "        ##############################################\n",
    "        ##############################################\n",
    "        # swap d() for device\n",
    "        # positions = self.pos_embedding(torch.arange(t, device=d()))[None, :, :].expand(b, t, e)\n",
    "        positions = self.pos_embedding(torch.arange(t, device=device))[None, :, :].expand(b, t, e)\n",
    "        ##############################################\n",
    "        ##############################################\n",
    "        #positions = self.pos_embedding(torch.arange(t))[None, :, :].expand(b, t, e)\n",
    "        #positions = torch.tensor(positions, dtype=torch.float32)\n",
    "        x = sentences_emb.cuda() + positions\n",
    "        x = self.do(x)\n",
    "\n",
    "        x = self.tblocks(x)\n",
    "\n",
    "        x = x.max(dim=1)[0] if self.max_pool else x.mean(dim=1) # pool over the time dimension\n",
    "        \n",
    "        \n",
    "        x_a = self.toprobs(x)\n",
    "        x_b = self.toprobs_b(x)\n",
    "        x_a = torch.squeeze(x_a)\n",
    "        x_b = torch.squeeze(x_b)\n",
    "        #print('x shape: ',x.shape)\n",
    "        return x_a, x_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset builder and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, embeddings, labels, labels_b):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "        self.labels_b = labels_b\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb = self.embeddings[idx]\n",
    "        label = self.labels[idx]\n",
    "        label_b = self.labels_b[idx]\n",
    "        return emb, label, label_b \n",
    "\n",
    "def get_data(data_directory, n_days, year, no_validation_set, is_using_scaler, batch_size):\n",
    "    # features\n",
    "    train_features = np.load('data/{}/train_features{}.npy'.format(data_directory, year))\n",
    "    val_features = np.load('data/{}/val_features{}.npy'.format(data_directory, year))\n",
    "    test_features = np.load('data/{}/test_features{}.npy'.format(data_directory, year))\n",
    "    # targets (n_days volatility)\n",
    "    train_targets = np.load('data/{}/train_targets{}_{}.npy'.format(data_directory, year, n_days))\n",
    "    val_targets = np.load('data/{}/val_targets{}_{}.npy'.format(data_directory, year, n_days))\n",
    "    test_targets = np.load('data/{}/test_targets{}_{}.npy'.format(data_directory, year, n_days))\n",
    "    # secondary targets (log percent change of day n)\n",
    "    train_secondary_targets = np.load('data/{}/train_secondary_targets{}_{}.npy'.format(data_directory, year, n_days))\n",
    "    val_secondary_targets = np.load('data/{}/val_secondary_targets{}_{}.npy'.format(data_directory, year, n_days))\n",
    "    test_secondary_targets = np.load('data/{}/test_secondary_targets{}_{}.npy'.format(data_directory, year, n_days))\n",
    "\n",
    "    train_secondary_targets[np.isneginf(train_secondary_targets)] = 0\n",
    "    val_secondary_targets[np.isneginf(val_secondary_targets)] = 0\n",
    "    test_secondary_targets[np.isneginf(test_secondary_targets)] = 0\n",
    "\n",
    "    # after hyperparameters are tuned on the validation set\n",
    "    # add validation set to training set\n",
    "    if no_validation_set:\n",
    "        train_features = np.concatenate((train_features, val_features), axis=0)\n",
    "        train_targets = np.concatenate((train_targets, val_targets), axis=0)\n",
    "        train_secondary_targets = np.concatenate((train_secondary_targets, val_secondary_targets), axis=0)\n",
    "\n",
    "    if is_using_scaler:\n",
    "        # Scaling features\n",
    "        feature_scaler = StandardScaler()\n",
    "        train_features = feature_scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "        val_features = feature_scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "        test_features = feature_scaler.transform(test_features.reshape(-1, test_features.shape[-1])).reshape(test_features.shape)\n",
    "        # Scaling primary targets\n",
    "        target_scaler = StandardScaler()\n",
    "        train_targets = target_scaler.fit_transform(train_targets.reshape(-1, 1)).reshape(train_targets.shape)\n",
    "        val_targets = target_scaler.transform(val_targets.reshape(-1, 1)).reshape(val_targets.shape)\n",
    "        test_targets = target_scaler.transform(test_targets.reshape(-1, 1)).reshape(test_targets.shape)\n",
    "        # Scaling secondary targets\n",
    "        secondary_target_scaler = StandardScaler()\n",
    "        train_secondary_targets = secondary_target_scaler.fit_transform(train_secondary_targets.reshape(-1, 1)).reshape(train_secondary_targets.shape)\n",
    "        val_secondary_targets = secondary_target_scaler.transform(val_secondary_targets.reshape(-1, 1)).reshape(val_secondary_targets.shape)\n",
    "        test_secondary_targets = secondary_target_scaler.transform(test_secondary_targets.reshape(-1, 1)).reshape(test_secondary_targets.shape)\n",
    "\n",
    "    # Dataset & DataLoader\n",
    "    training_set = Dataset(train_features, train_targets, train_secondary_targets) \n",
    "    val_set = Dataset(val_features, val_targets, val_secondary_targets)\n",
    "    test_set = Dataset(test_features, test_targets, test_secondary_targets)\n",
    "    trainloader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    valloader = torch.utils.data.DataLoader(val_set, batch_size=len(val_set), shuffle=False, num_workers=0)\n",
    "    testloader = torch.utils.data.DataLoader(test_set, batch_size=len(test_set), shuffle=False, num_workers=0)\n",
    "\n",
    "    print(train_features.shape, train_targets.shape, train_secondary_targets.shape) \n",
    "    print(val_features.shape, val_targets.shape, val_secondary_targets.shape) \n",
    "    print(test_features.shape, test_targets.shape, test_secondary_targets.shape) \n",
    "\n",
    "    # train_features.shape[2] is the number of features, need to instantiate the model\n",
    "    # need target scaler to inverse transform\n",
    "    return trainloader, valloader, testloader, train_features.shape[2], target_scaler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this training loop is actually reused for training, validation, and testing\n",
    "def  training_loop(trainloader, loader, emb_dimensions, heads, depth,dropout, warmup_steps, \n",
    "                   batch_size, num_epochs, alphas, max_norm, lr, run_name, target_scaler):\n",
    "    alphas_results = []\n",
    "    for alpha in alphas:\n",
    "        model = RTransformer(emb=emb_dimensions, heads=heads, depth=depth, seq_length=523, \n",
    "                            num_tokens=4000, num_classes=1, max_pool=False, dropout=dropout).to(device)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        # Linear LR warmup for the first #warmup_steps training examples\n",
    "        scheduler = LambdaLR(opt, lr_lambda=lambda step: min(1.0, step / (warmup_steps/batch_size)))\n",
    "\n",
    "        seen = 0\n",
    "        val_loss_a_history =  [] # keep track of the loss for the current Alpha value\n",
    "        writer = SummaryWriter(log_dir= f'KeFVP_runs/{run_name}_{alpha}')\n",
    "        progress_bar = tqdm(range(num_epochs), desc=\"Training Progress\", unit=\"epoch\")\n",
    "        for epoch in progress_bar:\n",
    "            model.train()\n",
    "            train_loss_total = 0\n",
    "            for i, (inputs, labels, labels_b) in enumerate(trainloader): #training data\n",
    "                seen += inputs.size(0)\n",
    "                inputs = inputs.to(device, dtype=torch.float32)\n",
    "                labels = labels.to(device, dtype=torch.float32)\n",
    "                labels_b = labels_b.to(device, dtype=torch.float32)\n",
    "                out_a, out_b = model(inputs)\n",
    "                out_a = out_a.view(-1)\n",
    "                out_b = out_b.view(-1)\n",
    "\n",
    "                # Compute the combined loss (multitask)\n",
    "                loss_a = F.mse_loss(out_a, labels)\n",
    "                loss_b = F.mse_loss(out_b, labels_b)\n",
    "                loss = alpha * loss_a + (1 - alpha) * loss_b # Alpha parameter\n",
    "            \n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "                opt.step()\n",
    "                if seen < warmup_steps:\n",
    "                    scheduler.step()\n",
    "\n",
    "                # we only care about the primary target\n",
    "                # although we are training with the scaled loss, reporting the volatility must be unscaled\n",
    "                out_a_unscaled = target_scaler.inverse_transform(out_a.detach().cpu().numpy().reshape(-1, 1)).reshape(out_a.shape)\n",
    "                labels_unscaled = target_scaler.inverse_transform(labels.detach().cpu().numpy().reshape(-1, 1)).reshape(labels.shape)\n",
    "                loss_a_unscaled = F.mse_loss(torch.tensor(out_a_unscaled, device=device), torch.tensor(labels_unscaled, device=device))\n",
    "                train_loss_total += loss_a_unscaled.item() * inputs.size(0) # MSE of volatility training (multiplied by current batch size)\n",
    "\n",
    "            # Epoch average of unscaled training loss\n",
    "            train_loss_avg = train_loss_total / len(trainloader.dataset)\n",
    "            \n",
    "            # Epoch Evaluation\n",
    "            model.eval()\n",
    "            val_loss_a_total = 0.0\n",
    "            with torch.no_grad():\n",
    "                for i, (inputs, labels, labels_b) in enumerate(loader): #validation or testing\n",
    "                    inputs = inputs.to(device, dtype=torch.float32)\n",
    "                    labels = labels.to(device, dtype=torch.float32)\n",
    "                    labels_b = labels_b.to(device, dtype=torch.float32)\n",
    "\n",
    "                    out_a, out_b = model(inputs)\n",
    "                    out_a = out_a.view(-1)\n",
    "                    \n",
    "                    out_a_unscaled = target_scaler.inverse_transform(out_a.detach().cpu().numpy().reshape(-1, 1)).reshape(out_a.shape)\n",
    "                    labels_unscaled = target_scaler.inverse_transform(labels.detach().cpu().numpy().reshape(-1, 1)).reshape(labels.shape)\n",
    "                    loss_a_unscaled = F.mse_loss(torch.tensor(out_a_unscaled, device=device), torch.tensor(labels_unscaled, device=device))\n",
    "                    val_loss_a_total += loss_a_unscaled.item() * inputs.size(0) # MSE of volatility\n",
    "\n",
    "                val_loss_a_avg = val_loss_a_total / len(loader.dataset) # MSE of volatility of Val/test!!\n",
    "            # Epoch finished\n",
    "            writer.add_scalar('Train Loss/train', train_loss_avg, epoch)\n",
    "            writer.add_scalar('Loss A/val', val_loss_a_avg, epoch)\n",
    "            # Update progress bar description and postfix\n",
    "            progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            progress_bar.set_postfix({\n",
    "                \"Train Loss\": f\"{train_loss_avg:.3f}\",\n",
    "                \"Test Loss A\": f\"{val_loss_a_avg:.3f}\"\n",
    "            })\n",
    "            # for alpha optimization, collect each Epoch's average loss\n",
    "            val_loss_a_history.append(val_loss_a_avg)\n",
    "        # all Epochs finished for this alpha value\n",
    "        min_loss = round(min(val_loss_a_history), 3)\n",
    "        alphas_results.append((alpha, min_loss))\n",
    "        writer.close()\n",
    "    print(alphas_results)\n",
    "    best_alpha, lowest_val_loss = min(alphas_results, key=lambda x: x[1])\n",
    "    return best_alpha, lowest_val_loss # if testING, this is the MSE  of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_test(data_directory, n_days, year):\n",
    "    run_name = data_directory + year + '_' + n_days \n",
    "    # using training set and validation set, determine optimum hyper-parameters (just alpha)\n",
    "    no_validation_set = False\n",
    "    trainloader,valloader,testloader,emb_dimensions, target_scaler = get_data(data_directory, n_days, year, no_validation_set, is_using_scaler, batch_size)\n",
    "    best_alpha, _ = training_loop(trainloader, valloader, emb_dimensions, heads, depth,dropout, warmup_steps, \n",
    "                            batch_size, num_epochs, alphas, max_norm, lr, run_name, target_scaler)\n",
    "    # using optimum alpha, retrain with all training/validation sets and test on testset\n",
    "    test_run_name = run_name + '_test'\n",
    "    no_validation_set = True\n",
    "    trainloader,valloader,testloader,emb_dimensions, target_scaler = get_data(data_directory, n_days, year, no_validation_set, is_using_scaler, batch_size)\n",
    "    _, MSE_testset = training_loop(trainloader, testloader, emb_dimensions, heads, depth, dropout, warmup_steps, \n",
    "                        batch_size, num_epochs, [best_alpha], max_norm, lr, test_run_name, target_scaler)\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    print(f'run_name-----------{run_name}')\n",
    "    print(f'best_alpha---------{best_alpha}')\n",
    "    print(f'MSE_testset--------{MSE_testset}')\n",
    "    print('----------------------------------------')\n",
    "    return best_alpha, MSE_testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.48s/epoch, Train Loss=0.680, Test Loss A=0.585]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.674, Test Loss A=0.707]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.670, Test Loss A=0.629]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.666, Test Loss A=0.622]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.665, Test Loss A=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.557), (0.3, 0.549), (0.5, 0.566), (0.7, 0.547), (0.9, 0.54)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.93s/epoch, Train Loss=0.659, Test Loss A=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.697)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_Roberta_3\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.697\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.376, Test Loss A=0.268]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.370, Test Loss A=0.282]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.373, Test Loss A=0.267]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.373, Test Loss A=0.269]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.373, Test Loss A=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.267), (0.3, 0.274), (0.5, 0.257), (0.7, 0.256), (0.9, 0.266)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.89s/epoch, Train Loss=0.357, Test Loss A=0.340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.34)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_Roberta_7\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.34\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.246, Test Loss A=0.200]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.246, Test Loss A=0.197]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.245, Test Loss A=0.195]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.245, Test Loss A=0.188]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.241, Test Loss A=0.210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.195), (0.3, 0.189), (0.5, 0.191), (0.7, 0.187), (0.9, 0.192)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.92s/epoch, Train Loss=0.236, Test Loss A=0.241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.224)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_Roberta_15\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.224\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.182, Test Loss A=0.137]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.183, Test Loss A=0.129]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.182, Test Loss A=0.132]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.182, Test Loss A=0.132]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.177, Test Loss A=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.132), (0.3, 0.129), (0.5, 0.124), (0.7, 0.132), (0.9, 0.125)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.90s/epoch, Train Loss=0.170, Test Loss A=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.168)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_Roberta_30\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.168\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.679, Test Loss A=0.556]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.672, Test Loss A=0.594]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.659, Test Loss A=0.565]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.643, Test Loss A=0.583]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.642, Test Loss A=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.546), (0.3, 0.565), (0.5, 0.549), (0.7, 0.502), (0.9, 0.522)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.90s/epoch, Train Loss=0.625, Test Loss A=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.723)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_Roberta2_3\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.723\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.372, Test Loss A=0.302]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.364, Test Loss A=0.269]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.354, Test Loss A=0.267]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.352, Test Loss A=0.256]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.349, Test Loss A=0.283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.272), (0.3, 0.26), (0.5, 0.253), (0.7, 0.252), (0.9, 0.247)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.91s/epoch, Train Loss=0.336, Test Loss A=0.400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.329)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_Roberta2_7\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.329\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.246, Test Loss A=0.190]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.239, Test Loss A=0.186]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.239, Test Loss A=0.188]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.230, Test Loss A=0.211]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.231, Test Loss A=0.240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.19), (0.3, 0.182), (0.5, 0.182), (0.7, 0.184), (0.9, 0.179)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.89s/epoch, Train Loss=0.210, Test Loss A=0.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.245)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_Roberta2_15\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.245\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.182, Test Loss A=0.135]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.179, Test Loss A=0.131]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.175, Test Loss A=0.155]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.175, Test Loss A=0.177]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.175, Test Loss A=0.160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.124), (0.3, 0.121), (0.5, 0.136), (0.7, 0.137), (0.9, 0.124)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.92s/epoch, Train Loss=0.172, Test Loss A=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.176)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_Roberta2_30\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.176\n",
      "----------------------------------------\n",
      "(391, 523, 804) (391,) (391,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.685, Test Loss A=0.547]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.669, Test Loss A=0.549]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.664, Test Loss A=0.565]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.654, Test Loss A=0.563]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.649, Test Loss A=0.598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.546), (0.3, 0.548), (0.5, 0.539), (0.7, 0.541), (0.9, 0.566)]\n",
      "(447, 523, 804) (447,) (447,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.97s/epoch, Train Loss=0.648, Test Loss A=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.675)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_investopedia_3\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.675\n",
      "----------------------------------------\n",
      "(391, 523, 804) (391,) (391,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.373, Test Loss A=0.274]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.369, Test Loss A=0.250]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.369, Test Loss A=0.261]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.361, Test Loss A=0.264]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.357, Test Loss A=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.271), (0.3, 0.25), (0.5, 0.261), (0.7, 0.26), (0.9, 0.246)]\n",
      "(447, 523, 804) (447,) (447,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.97s/epoch, Train Loss=0.347, Test Loss A=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.335)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_investopedia_7\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.335\n",
      "----------------------------------------\n",
      "(391, 523, 804) (391,) (391,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.247, Test Loss A=0.194]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.245, Test Loss A=0.184]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.64s/epoch, Train Loss=0.241, Test Loss A=0.185]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.238, Test Loss A=0.172]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.237, Test Loss A=0.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.193), (0.3, 0.181), (0.5, 0.181), (0.7, 0.172), (0.9, 0.174)]\n",
      "(447, 523, 804) (447,) (447,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.97s/epoch, Train Loss=0.232, Test Loss A=0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.234)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_investopedia_15\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.234\n",
      "----------------------------------------\n",
      "(391, 523, 804) (391,) (391,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.183, Test Loss A=0.133]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.181, Test Loss A=0.126]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.178, Test Loss A=0.119]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.175, Test Loss A=0.118]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.178, Test Loss A=0.113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.127), (0.3, 0.126), (0.5, 0.115), (0.7, 0.118), (0.9, 0.113)]\n",
      "(447, 523, 804) (447,) (447,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.97s/epoch, Train Loss=0.171, Test Loss A=0.199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.192)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_investopedia_30\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.192\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.42s/epoch, Train Loss=0.683, Test Loss A=0.539]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.665, Test Loss A=0.518]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.657, Test Loss A=0.606]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.662, Test Loss A=0.577]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.650, Test Loss A=0.613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.539), (0.3, 0.518), (0.5, 0.557), (0.7, 0.553), (0.9, 0.56)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.83s/epoch, Train Loss=0.658, Test Loss A=0.678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.678)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_bge_3\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.678\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.40s/epoch, Train Loss=0.372, Test Loss A=0.277]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.367, Test Loss A=0.284]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.362, Test Loss A=0.252]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.361, Test Loss A=0.261]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/epoch, Train Loss=0.361, Test Loss A=0.299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.273), (0.3, 0.269), (0.5, 0.252), (0.7, 0.257), (0.9, 0.251)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.87s/epoch, Train Loss=0.347, Test Loss A=0.409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.346)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_bge_7\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.346\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.246, Test Loss A=0.188]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.240, Test Loss A=0.209]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.239, Test Loss A=0.188]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.44s/epoch, Train Loss=0.239, Test Loss A=0.181]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.43s/epoch, Train Loss=0.238, Test Loss A=0.193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.188), (0.3, 0.186), (0.5, 0.183), (0.7, 0.177), (0.9, 0.18)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.91s/epoch, Train Loss=0.224, Test Loss A=0.289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.221)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_bge_15\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.221\n",
      "----------------------------------------\n",
      "(391, 523, 1060) (391,) (391,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/epoch, Train Loss=0.184, Test Loss A=0.136]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.178, Test Loss A=0.116]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.176, Test Loss A=0.178]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.176, Test Loss A=0.113]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/epoch, Train Loss=0.175, Test Loss A=0.121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.127), (0.3, 0.116), (0.5, 0.129), (0.7, 0.113), (0.9, 0.121)]\n",
      "(447, 523, 1060) (447,) (447,)\n",
      "(56, 523, 1060) (56,) (56,)\n",
      "(111, 523, 1060) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.93s/epoch, Train Loss=0.165, Test Loss A=0.181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.179)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_bge_30\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.179\n",
      "----------------------------------------\n",
      "(391, 523, 804) (391,) (391,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.70s/epoch, Train Loss=0.683, Test Loss A=0.538]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.668, Test Loss A=0.555]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.656, Test Loss A=0.557]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.648, Test Loss A=0.581]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.651, Test Loss A=0.623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.534), (0.3, 0.548), (0.5, 0.551), (0.7, 0.555), (0.9, 0.56)]\n",
      "(447, 523, 804) (447,) (447,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.97s/epoch, Train Loss=0.667, Test Loss A=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.711)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_bge_base_3\n",
      "best_alpha---------0.1\n",
      "MSE_testset--------0.711\n",
      "----------------------------------------\n",
      "(391, 523, 804) (391,) (391,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.68s/epoch, Train Loss=0.372, Test Loss A=0.269]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.369, Test Loss A=0.275]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.358, Test Loss A=0.263]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.353, Test Loss A=0.258]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.352, Test Loss A=0.236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.269), (0.3, 0.27), (0.5, 0.256), (0.7, 0.24), (0.9, 0.236)]\n",
      "(447, 523, 804) (447,) (447,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.96s/epoch, Train Loss=0.341, Test Loss A=0.369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.329)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_bge_base_7\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.329\n",
      "----------------------------------------\n",
      "(391, 523, 804) (391,) (391,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.246, Test Loss A=0.197]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.242, Test Loss A=0.181]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.239, Test Loss A=0.184]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.238, Test Loss A=0.171]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.235, Test Loss A=0.166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.197), (0.3, 0.18), (0.5, 0.184), (0.7, 0.171), (0.9, 0.166)]\n",
      "(447, 523, 804) (447,) (447,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.96s/epoch, Train Loss=0.229, Test Loss A=0.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.233)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_bge_base_15\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.233\n",
      "----------------------------------------\n",
      "(391, 523, 804) (391,) (391,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.67s/epoch, Train Loss=0.181, Test Loss A=0.129]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.179, Test Loss A=0.121]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.179, Test Loss A=0.115]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.174, Test Loss A=0.116]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.175, Test Loss A=0.136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.124), (0.3, 0.121), (0.5, 0.115), (0.7, 0.116), (0.9, 0.121)]\n",
      "(447, 523, 804) (447,) (447,)\n",
      "(56, 523, 804) (56,) (56,)\n",
      "(111, 523, 804) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.96s/epoch, Train Loss=0.168, Test Loss A=0.218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.191)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_bge_base_30\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.191\n",
      "----------------------------------------\n",
      "(391, 523, 336) (391,) (391,)\n",
      "(56, 523, 336) (56,) (56,)\n",
      "(111, 523, 336) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.60epoch/s, Train Loss=0.693, Test Loss A=0.623]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68epoch/s, Train Loss=0.688, Test Loss A=0.556]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66epoch/s, Train Loss=0.691, Test Loss A=0.531]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.58epoch/s, Train Loss=0.683, Test Loss A=0.527]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.57epoch/s, Train Loss=0.691, Test Loss A=0.546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.623), (0.3, 0.556), (0.5, 0.53), (0.7, 0.527), (0.9, 0.546)]\n",
      "(447, 523, 336) (447,) (447,)\n",
      "(56, 523, 336) (56,) (56,)\n",
      "(111, 523, 336) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.34epoch/s, Train Loss=0.670, Test Loss A=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.717)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_glove_3\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.717\n",
      "----------------------------------------\n",
      "(391, 523, 336) (391,) (391,)\n",
      "(56, 523, 336) (56,) (56,)\n",
      "(111, 523, 336) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.49epoch/s, Train Loss=0.377, Test Loss A=0.297]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.62epoch/s, Train Loss=0.376, Test Loss A=0.279]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.59epoch/s, Train Loss=0.373, Test Loss A=0.272]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.58epoch/s, Train Loss=0.376, Test Loss A=0.267]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.64epoch/s, Train Loss=0.380, Test Loss A=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.291), (0.3, 0.277), (0.5, 0.272), (0.7, 0.267), (0.9, 0.284)]\n",
      "(447, 523, 336) (447,) (447,)\n",
      "(56, 523, 336) (56,) (56,)\n",
      "(111, 523, 336) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.39epoch/s, Train Loss=0.362, Test Loss A=0.372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.372)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_glove_7\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.372\n",
      "----------------------------------------\n",
      "(391, 523, 336) (391,) (391,)\n",
      "(56, 523, 336) (56,) (56,)\n",
      "(111, 523, 336) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.50epoch/s, Train Loss=0.251, Test Loss A=0.215]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.47epoch/s, Train Loss=0.249, Test Loss A=0.188]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.47epoch/s, Train Loss=0.246, Test Loss A=0.196]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.62epoch/s, Train Loss=0.248, Test Loss A=0.190]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.63epoch/s, Train Loss=0.248, Test Loss A=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.212), (0.3, 0.188), (0.5, 0.196), (0.7, 0.189), (0.9, 0.186)]\n",
      "(447, 523, 336) (447,) (447,)\n",
      "(56, 523, 336) (56,) (56,)\n",
      "(111, 523, 336) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.36epoch/s, Train Loss=0.241, Test Loss A=0.272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.255)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_glove_15\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.255\n",
      "----------------------------------------\n",
      "(391, 523, 336) (391,) (391,)\n",
      "(56, 523, 336) (56,) (56,)\n",
      "(111, 523, 336) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.53epoch/s, Train Loss=0.183, Test Loss A=0.129]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.53epoch/s, Train Loss=0.183, Test Loss A=0.137]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72epoch/s, Train Loss=0.184, Test Loss A=0.136]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.60epoch/s, Train Loss=0.184, Test Loss A=0.140]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.58epoch/s, Train Loss=0.183, Test Loss A=0.136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.129), (0.3, 0.133), (0.5, 0.128), (0.7, 0.138), (0.9, 0.129)]\n",
      "(447, 523, 336) (447,) (447,)\n",
      "(56, 523, 336) (56,) (56,)\n",
      "(111, 523, 336) (111,) (111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.38epoch/s, Train Loss=0.176, Test Loss A=0.214]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.208)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_glove_30\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.208\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "directories = ['KeFVP_emotion2vec_Roberta', 'KeFVP_emotion2vec_Roberta2', 'KeFVP_emotion2vec_investopedia', 'KeFVP_emotion2vec_bge', 'KeFVP_emotion2vec_bge_base', 'KeFVP_emotion2vec_glove']#\n",
    "\n",
    "final_results = []\n",
    "for data_directory in directories: # different feature engineering features\n",
    "    for n_days in all_n_days: \n",
    "        year = '' # for the original data we don't separate by years (this is for Maec)\n",
    "        best_alpha, MSE_testset = train_val_test(data_directory, n_days, year)\n",
    "        final_results.append([data_directory, n_days, best_alpha, MSE_testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding Variant</th>\n",
       "      <th>n_days</th>\n",
       "      <th>best_alpha</th>\n",
       "      <th>MSE_testset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KeFVP_emotion2vec_Roberta</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeFVP_emotion2vec_Roberta</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KeFVP_emotion2vec_Roberta</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KeFVP_emotion2vec_Roberta</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KeFVP_emotion2vec_Roberta2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KeFVP_emotion2vec_Roberta2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KeFVP_emotion2vec_Roberta2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KeFVP_emotion2vec_Roberta2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KeFVP_emotion2vec_investopedia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KeFVP_emotion2vec_investopedia</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KeFVP_emotion2vec_investopedia</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KeFVP_emotion2vec_investopedia</td>\n",
       "      <td>30</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KeFVP_emotion2vec_bge</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KeFVP_emotion2vec_bge</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KeFVP_emotion2vec_bge</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KeFVP_emotion2vec_bge</td>\n",
       "      <td>30</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KeFVP_emotion2vec_bge_base</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KeFVP_emotion2vec_bge_base</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KeFVP_emotion2vec_bge_base</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KeFVP_emotion2vec_bge_base</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KeFVP_emotion2vec_glove</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KeFVP_emotion2vec_glove</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KeFVP_emotion2vec_glove</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KeFVP_emotion2vec_glove</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Embedding Variant n_days  best_alpha  MSE_testset\n",
       "0        KeFVP_emotion2vec_Roberta      3         0.9        0.697\n",
       "1        KeFVP_emotion2vec_Roberta      7         0.7        0.340\n",
       "2        KeFVP_emotion2vec_Roberta     15         0.7        0.224\n",
       "3        KeFVP_emotion2vec_Roberta     30         0.5        0.168\n",
       "4       KeFVP_emotion2vec_Roberta2      3         0.7        0.723\n",
       "5       KeFVP_emotion2vec_Roberta2      7         0.9        0.329\n",
       "6       KeFVP_emotion2vec_Roberta2     15         0.9        0.245\n",
       "7       KeFVP_emotion2vec_Roberta2     30         0.3        0.176\n",
       "8   KeFVP_emotion2vec_investopedia      3         0.5        0.675\n",
       "9   KeFVP_emotion2vec_investopedia      7         0.9        0.335\n",
       "10  KeFVP_emotion2vec_investopedia     15         0.7        0.234\n",
       "11  KeFVP_emotion2vec_investopedia     30         0.9        0.192\n",
       "12           KeFVP_emotion2vec_bge      3         0.3        0.678\n",
       "13           KeFVP_emotion2vec_bge      7         0.9        0.346\n",
       "14           KeFVP_emotion2vec_bge     15         0.7        0.221\n",
       "15           KeFVP_emotion2vec_bge     30         0.7        0.179\n",
       "16      KeFVP_emotion2vec_bge_base      3         0.1        0.711\n",
       "17      KeFVP_emotion2vec_bge_base      7         0.9        0.329\n",
       "18      KeFVP_emotion2vec_bge_base     15         0.9        0.233\n",
       "19      KeFVP_emotion2vec_bge_base     30         0.5        0.191\n",
       "20         KeFVP_emotion2vec_glove      3         0.7        0.717\n",
       "21         KeFVP_emotion2vec_glove      7         0.7        0.372\n",
       "22         KeFVP_emotion2vec_glove     15         0.9        0.255\n",
       "23         KeFVP_emotion2vec_glove     30         0.5        0.208"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.DataFrame(final_results, columns=['Embedding Variant', 'n_days', 'best_alpha', 'MSE_testset'])\n",
    "final_results.to_csv('data/KeFVP_emotion2vec_final_results.csv', index=False)\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n_days</th>\n",
       "      <th>15</th>\n",
       "      <th>3</th>\n",
       "      <th>30</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding Variant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_Roberta</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_Roberta2</th>\n",
       "      <td>0.245</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_bge</th>\n",
       "      <td>0.221</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_bge_base</th>\n",
       "      <td>0.233</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_glove</th>\n",
       "      <td>0.255</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_investopedia</th>\n",
       "      <td>0.234</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "n_days                             15      3     30      7\n",
       "Embedding Variant                                         \n",
       "KeFVP_emotion2vec_Roberta       0.224  0.697  0.168  0.340\n",
       "KeFVP_emotion2vec_Roberta2      0.245  0.723  0.176  0.329\n",
       "KeFVP_emotion2vec_bge           0.221  0.678  0.179  0.346\n",
       "KeFVP_emotion2vec_bge_base      0.233  0.711  0.191  0.329\n",
       "KeFVP_emotion2vec_glove         0.255  0.717  0.208  0.372\n",
       "KeFVP_emotion2vec_investopedia  0.234  0.675  0.192  0.335"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = final_results.drop(columns=['best_alpha'])\n",
    "final_results = final_results.pivot(index='Embedding Variant', columns='n_days', values='MSE_testset')\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test MAEC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.39s/epoch, Train Loss=0.472, Test Loss A=0.544]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.470, Test Loss A=0.511]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.35s/epoch, Train Loss=0.465, Test Loss A=0.552]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.470, Test Loss A=0.555]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.462, Test Loss A=0.947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.544), (0.3, 0.511), (0.5, 0.515), (0.7, 0.548), (0.9, 0.509)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.26s/epoch, Train Loss=0.485, Test Loss A=1.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.509)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_Roberta_3\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.509\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.40s/epoch, Train Loss=0.228, Test Loss A=0.328]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.226, Test Loss A=0.398]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.224, Test Loss A=0.326]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.224, Test Loss A=0.391]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.223, Test Loss A=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.288), (0.3, 0.275), (0.5, 0.291), (0.7, 0.305), (0.9, 0.286)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.26s/epoch, Train Loss=0.241, Test Loss A=0.301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.281)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_Roberta_7\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.281\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.191, Test Loss A=0.269]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.35s/epoch, Train Loss=0.193, Test Loss A=0.210]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.191, Test Loss A=0.224]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.35s/epoch, Train Loss=0.192, Test Loss A=0.221]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.35s/epoch, Train Loss=0.188, Test Loss A=0.362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.226), (0.3, 0.205), (0.5, 0.187), (0.7, 0.199), (0.9, 0.206)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.25s/epoch, Train Loss=0.194, Test Loss A=0.283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.186)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_Roberta_15\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.186\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.153, Test Loss A=0.239]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.34s/epoch, Train Loss=0.151, Test Loss A=0.178]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.34s/epoch, Train Loss=0.155, Test Loss A=0.221]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.34s/epoch, Train Loss=0.155, Test Loss A=0.186]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.34s/epoch, Train Loss=0.151, Test Loss A=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.168), (0.3, 0.165), (0.5, 0.163), (0.7, 0.168), (0.9, 0.172)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.24s/epoch, Train Loss=0.157, Test Loss A=0.182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.154)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_Roberta_30\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.154\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.39s/epoch, Train Loss=0.468, Test Loss A=0.550]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.37s/epoch, Train Loss=0.464, Test Loss A=0.545]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.462, Test Loss A=0.569]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.37s/epoch, Train Loss=0.460, Test Loss A=0.527]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.466, Test Loss A=0.567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.532), (0.3, 0.514), (0.5, 0.531), (0.7, 0.505), (0.9, 0.509)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.22s/epoch, Train Loss=0.472, Test Loss A=0.560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.514)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_Roberta2_3\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.514\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.35s/epoch, Train Loss=0.222, Test Loss A=0.353]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.34s/epoch, Train Loss=0.220, Test Loss A=0.358]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.33s/epoch, Train Loss=0.219, Test Loss A=0.360]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.217, Test Loss A=0.339]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.212, Test Loss A=0.466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.301), (0.3, 0.268), (0.5, 0.282), (0.7, 0.273), (0.9, 0.281)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.25s/epoch, Train Loss=0.232, Test Loss A=0.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.272)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_Roberta2_7\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.272\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.40s/epoch, Train Loss=0.189, Test Loss A=0.213]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.185, Test Loss A=0.219]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.185, Test Loss A=0.250]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.180, Test Loss A=0.342]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.39s/epoch, Train Loss=0.179, Test Loss A=0.377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.206), (0.3, 0.196), (0.5, 0.211), (0.7, 0.196), (0.9, 0.198)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.27s/epoch, Train Loss=0.186, Test Loss A=0.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.183)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_Roberta2_15\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.183\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.36s/epoch, Train Loss=0.152, Test Loss A=0.163]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.35s/epoch, Train Loss=0.150, Test Loss A=0.204]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.35s/epoch, Train Loss=0.148, Test Loss A=0.233]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.35s/epoch, Train Loss=0.148, Test Loss A=0.215]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.34s/epoch, Train Loss=0.148, Test Loss A=0.170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.162), (0.3, 0.163), (0.5, 0.158), (0.7, 0.161), (0.9, 0.166)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.25s/epoch, Train Loss=0.152, Test Loss A=0.185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.153)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_Roberta2_30\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.153\n",
      "----------------------------------------\n",
      "(535, 500, 804) (535,) (535,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.19s/epoch, Train Loss=0.468, Test Loss A=0.541]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.469, Test Loss A=0.555]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.459, Test Loss A=0.511]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.464, Test Loss A=0.507]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.17s/epoch, Train Loss=0.457, Test Loss A=0.521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.539), (0.3, 0.514), (0.5, 0.511), (0.7, 0.505), (0.9, 0.51)]\n",
      "(689, 500, 804) (689,) (689,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.77s/epoch, Train Loss=0.479, Test Loss A=0.518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.508)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_investopedia_3\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.508\n",
      "----------------------------------------\n",
      "(535, 500, 804) (535,) (535,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.19s/epoch, Train Loss=0.223, Test Loss A=0.312]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.221, Test Loss A=0.331]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.221, Test Loss A=0.326]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.220, Test Loss A=0.282]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.17s/epoch, Train Loss=0.217, Test Loss A=0.322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.301), (0.3, 0.293), (0.5, 0.286), (0.7, 0.269), (0.9, 0.265)]\n",
      "(689, 500, 804) (689,) (689,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.76s/epoch, Train Loss=0.229, Test Loss A=0.285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.267)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_investopedia_7\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.267\n",
      "----------------------------------------\n",
      "(535, 500, 804) (535,) (535,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.19s/epoch, Train Loss=0.190, Test Loss A=0.226]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.187, Test Loss A=0.231]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.184, Test Loss A=0.270]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.184, Test Loss A=0.224]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.183, Test Loss A=0.227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.207), (0.3, 0.215), (0.5, 0.223), (0.7, 0.203), (0.9, 0.187)]\n",
      "(689, 500, 804) (689,) (689,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.75s/epoch, Train Loss=0.185, Test Loss A=0.199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.184)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_investopedia_15\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.184\n",
      "----------------------------------------\n",
      "(535, 500, 804) (535,) (535,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.152, Test Loss A=0.185]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.152, Test Loss A=0.185]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.150, Test Loss A=0.186]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.150, Test Loss A=0.158]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.150, Test Loss A=0.178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.171), (0.3, 0.18), (0.5, 0.161), (0.7, 0.158), (0.9, 0.159)]\n",
      "(689, 500, 804) (689,) (689,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.79s/epoch, Train Loss=0.152, Test Loss A=0.167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.153)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_investopedia_30\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.153\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.30s/epoch, Train Loss=0.468, Test Loss A=0.530]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.28s/epoch, Train Loss=0.472, Test Loss A=0.530]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.29s/epoch, Train Loss=0.467, Test Loss A=0.555]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.29s/epoch, Train Loss=0.465, Test Loss A=0.599]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.28s/epoch, Train Loss=0.478, Test Loss A=0.524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.523), (0.3, 0.508), (0.5, 0.51), (0.7, 0.501), (0.9, 0.507)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:41<00:00,  4.18s/epoch, Train Loss=0.480, Test Loss A=0.581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.497)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_bge_3\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.497\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.30s/epoch, Train Loss=0.226, Test Loss A=0.284]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.27s/epoch, Train Loss=0.220, Test Loss A=0.291]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.27s/epoch, Train Loss=0.218, Test Loss A=0.292]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.27s/epoch, Train Loss=0.219, Test Loss A=0.289]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.27s/epoch, Train Loss=0.218, Test Loss A=0.313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.271), (0.3, 0.283), (0.5, 0.274), (0.7, 0.276), (0.9, 0.26)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:41<00:00,  4.18s/epoch, Train Loss=0.229, Test Loss A=0.286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.263)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_bge_7\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.263\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.30s/epoch, Train Loss=0.189, Test Loss A=0.224]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.27s/epoch, Train Loss=0.186, Test Loss A=0.258]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.27s/epoch, Train Loss=0.183, Test Loss A=0.219]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.34s/epoch, Train Loss=0.183, Test Loss A=0.208]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.37s/epoch, Train Loss=0.180, Test Loss A=0.194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.213), (0.3, 0.196), (0.5, 0.199), (0.7, 0.18), (0.9, 0.194)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.25s/epoch, Train Loss=0.185, Test Loss A=0.196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.179)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_bge_15\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.179\n",
      "----------------------------------------\n",
      "(535, 500, 1060) (535,) (535,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.37s/epoch, Train Loss=0.152, Test Loss A=0.183]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.149, Test Loss A=0.172]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.39s/epoch, Train Loss=0.148, Test Loss A=0.181]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.38s/epoch, Train Loss=0.148, Test Loss A=0.162]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33<00:00,  3.37s/epoch, Train Loss=0.149, Test Loss A=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.166), (0.3, 0.159), (0.5, 0.17), (0.7, 0.154), (0.9, 0.153)]\n",
      "(689, 500, 1060) (689,) (689,)\n",
      "(154, 500, 1060) (154,) (154,)\n",
      "(154, 500, 1060) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.25s/epoch, Train Loss=0.150, Test Loss A=0.168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.159)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_bge_30\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.159\n",
      "----------------------------------------\n",
      "(535, 500, 804) (535,) (535,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.476, Test Loss A=0.548]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.466, Test Loss A=0.506]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.465, Test Loss A=0.524]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.17s/epoch, Train Loss=0.463, Test Loss A=0.589]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.17s/epoch, Train Loss=0.466, Test Loss A=0.604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.531), (0.3, 0.506), (0.5, 0.524), (0.7, 0.512), (0.9, 0.514)]\n",
      "(689, 500, 804) (689,) (689,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.75s/epoch, Train Loss=0.489, Test Loss A=0.508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.503)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_bge_base_3\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.503\n",
      "----------------------------------------\n",
      "(535, 500, 804) (535,) (535,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.226, Test Loss A=0.329]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.222, Test Loss A=0.361]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.219, Test Loss A=0.293]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.219, Test Loss A=0.355]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.221, Test Loss A=0.333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.308), (0.3, 0.294), (0.5, 0.293), (0.7, 0.307), (0.9, 0.286)]\n",
      "(689, 500, 804) (689,) (689,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.76s/epoch, Train Loss=0.236, Test Loss A=0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.263)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_bge_base_7\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.263\n",
      "----------------------------------------\n",
      "(535, 500, 804) (535,) (535,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.19s/epoch, Train Loss=0.191, Test Loss A=0.220]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.187, Test Loss A=0.210]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.17s/epoch, Train Loss=0.186, Test Loss A=0.252]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.184, Test Loss A=0.267]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.17s/epoch, Train Loss=0.185, Test Loss A=0.233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.214), (0.3, 0.195), (0.5, 0.206), (0.7, 0.203), (0.9, 0.199)]\n",
      "(689, 500, 804) (689,) (689,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.76s/epoch, Train Loss=0.192, Test Loss A=0.196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.193)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_bge_base_15\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.193\n",
      "----------------------------------------\n",
      "(535, 500, 804) (535,) (535,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.152, Test Loss A=0.162]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.18s/epoch, Train Loss=0.151, Test Loss A=0.172]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.149, Test Loss A=0.161]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.149, Test Loss A=0.183]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/epoch, Train Loss=0.150, Test Loss A=0.191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.162), (0.3, 0.164), (0.5, 0.161), (0.7, 0.158), (0.9, 0.163)]\n",
      "(689, 500, 804) (689,) (689,)\n",
      "(154, 500, 804) (154,) (154,)\n",
      "(154, 500, 804) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.74s/epoch, Train Loss=0.152, Test Loss A=0.182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.15)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_bge_base_30\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.15\n",
      "----------------------------------------\n",
      "(535, 500, 336) (535,) (535,)\n",
      "(154, 500, 336) (154,) (154,)\n",
      "(154, 500, 336) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.17epoch/s, Train Loss=0.468, Test Loss A=0.596]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.20epoch/s, Train Loss=0.472, Test Loss A=0.537]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.17epoch/s, Train Loss=0.472, Test Loss A=0.535]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.08epoch/s, Train Loss=0.468, Test Loss A=0.580]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.18epoch/s, Train Loss=0.468, Test Loss A=0.536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.582), (0.3, 0.536), (0.5, 0.529), (0.7, 0.53), (0.9, 0.533)]\n",
      "(689, 500, 336) (689,) (689,)\n",
      "(154, 500, 336) (154,) (154,)\n",
      "(154, 500, 336) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.03s/epoch, Train Loss=0.481, Test Loss A=0.583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.53)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_glove_3\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.53\n",
      "----------------------------------------\n",
      "(535, 500, 336) (535,) (535,)\n",
      "(154, 500, 336) (154,) (154,)\n",
      "(154, 500, 336) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.22epoch/s, Train Loss=0.225, Test Loss A=0.319]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.19epoch/s, Train Loss=0.224, Test Loss A=0.312]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.16epoch/s, Train Loss=0.224, Test Loss A=0.309]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.16epoch/s, Train Loss=0.224, Test Loss A=0.299]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.17epoch/s, Train Loss=0.224, Test Loss A=0.303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.319), (0.3, 0.291), (0.5, 0.3), (0.7, 0.291), (0.9, 0.291)]\n",
      "(689, 500, 336) (689,) (689,)\n",
      "(154, 500, 336) (154,) (154,)\n",
      "(154, 500, 336) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.08s/epoch, Train Loss=0.243, Test Loss A=0.292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.283)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_glove_7\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.283\n",
      "----------------------------------------\n",
      "(535, 500, 336) (535,) (535,)\n",
      "(154, 500, 336) (154,) (154,)\n",
      "(154, 500, 336) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.17epoch/s, Train Loss=0.192, Test Loss A=0.230]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14epoch/s, Train Loss=0.190, Test Loss A=0.218]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.18epoch/s, Train Loss=0.192, Test Loss A=0.219]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.17epoch/s, Train Loss=0.190, Test Loss A=0.213]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.22epoch/s, Train Loss=0.190, Test Loss A=0.215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.23), (0.3, 0.218), (0.5, 0.208), (0.7, 0.204), (0.9, 0.209)]\n",
      "(689, 500, 336) (689,) (689,)\n",
      "(154, 500, 336) (154,) (154,)\n",
      "(154, 500, 336) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:11<00:00,  1.11s/epoch, Train Loss=0.195, Test Loss A=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.19)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_glove_15\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.19\n",
      "----------------------------------------\n",
      "(535, 500, 336) (535,) (535,)\n",
      "(154, 500, 336) (154,) (154,)\n",
      "(154, 500, 336) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.18epoch/s, Train Loss=0.152, Test Loss A=0.175]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.15epoch/s, Train Loss=0.152, Test Loss A=0.172]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14epoch/s, Train Loss=0.152, Test Loss A=0.170]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.19epoch/s, Train Loss=0.152, Test Loss A=0.179]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.18epoch/s, Train Loss=0.151, Test Loss A=0.178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.172), (0.3, 0.169), (0.5, 0.167), (0.7, 0.177), (0.9, 0.162)]\n",
      "(689, 500, 336) (689,) (689,)\n",
      "(154, 500, 336) (154,) (154,)\n",
      "(154, 500, 336) (154,) (154,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.09s/epoch, Train Loss=0.156, Test Loss A=0.174]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.162)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC15_glove_30\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.162\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directories = ['KeFVP_emotion2vec_MAEC15_Roberta', 'KeFVP_emotion2vec_MAEC15_Roberta2', 'KeFVP_emotion2vec_MAEC15_investopedia', 'KeFVP_emotion2vec_MAEC15_bge', 'KeFVP_emotion2vec_MAEC15_bge_base', 'KeFVP_emotion2vec_MAEC15_glove']#\n",
    "#years = ['_2015', '_2016', '_2017']\n",
    "\n",
    "KeFVP_MAEC15_final_results = []\n",
    "for data_directory in directories: # different feature engineering features\n",
    "    for n_days in all_n_days: \n",
    "        #for year in years:\n",
    "        year = ''\n",
    "        best_alpha, MSE_testset = train_val_test(data_directory, n_days, year)\n",
    "        KeFVP_MAEC15_final_results.append([data_directory, n_days, year, best_alpha, MSE_testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding Variant</th>\n",
       "      <th>n_days</th>\n",
       "      <th>year</th>\n",
       "      <th>best_alpha</th>\n",
       "      <th>MSE_testset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_Roberta</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_Roberta</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_Roberta</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_Roberta</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_Roberta2</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_Roberta2</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_Roberta2</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_Roberta2</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_investopedia</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_investopedia</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_investopedia</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_investopedia</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_bge</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_bge</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_bge</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_bge</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_bge_base</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_bge_base</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_bge_base</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_bge_base</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_glove</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_glove</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_glove</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC15_glove</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Embedding Variant  n_days year  best_alpha  \\\n",
       "0        KeFVP_emotion2vec_MAEC15_Roberta       3              0.9   \n",
       "1        KeFVP_emotion2vec_MAEC15_Roberta       7              0.3   \n",
       "2        KeFVP_emotion2vec_MAEC15_Roberta      15              0.5   \n",
       "3        KeFVP_emotion2vec_MAEC15_Roberta      30              0.5   \n",
       "4       KeFVP_emotion2vec_MAEC15_Roberta2       3              0.7   \n",
       "5       KeFVP_emotion2vec_MAEC15_Roberta2       7              0.3   \n",
       "6       KeFVP_emotion2vec_MAEC15_Roberta2      15              0.3   \n",
       "7       KeFVP_emotion2vec_MAEC15_Roberta2      30              0.5   \n",
       "8   KeFVP_emotion2vec_MAEC15_investopedia       3              0.7   \n",
       "9   KeFVP_emotion2vec_MAEC15_investopedia       7              0.9   \n",
       "10  KeFVP_emotion2vec_MAEC15_investopedia      15              0.9   \n",
       "11  KeFVP_emotion2vec_MAEC15_investopedia      30              0.7   \n",
       "12           KeFVP_emotion2vec_MAEC15_bge       3              0.7   \n",
       "13           KeFVP_emotion2vec_MAEC15_bge       7              0.9   \n",
       "14           KeFVP_emotion2vec_MAEC15_bge      15              0.7   \n",
       "15           KeFVP_emotion2vec_MAEC15_bge      30              0.9   \n",
       "16      KeFVP_emotion2vec_MAEC15_bge_base       3              0.3   \n",
       "17      KeFVP_emotion2vec_MAEC15_bge_base       7              0.9   \n",
       "18      KeFVP_emotion2vec_MAEC15_bge_base      15              0.3   \n",
       "19      KeFVP_emotion2vec_MAEC15_bge_base      30              0.7   \n",
       "20         KeFVP_emotion2vec_MAEC15_glove       3              0.5   \n",
       "21         KeFVP_emotion2vec_MAEC15_glove       7              0.3   \n",
       "22         KeFVP_emotion2vec_MAEC15_glove      15              0.7   \n",
       "23         KeFVP_emotion2vec_MAEC15_glove      30              0.9   \n",
       "\n",
       "    MSE_testset  \n",
       "0         0.509  \n",
       "1         0.281  \n",
       "2         0.186  \n",
       "3         0.154  \n",
       "4         0.514  \n",
       "5         0.272  \n",
       "6         0.183  \n",
       "7         0.153  \n",
       "8         0.508  \n",
       "9         0.267  \n",
       "10        0.184  \n",
       "11        0.153  \n",
       "12        0.497  \n",
       "13        0.263  \n",
       "14        0.179  \n",
       "15        0.159  \n",
       "16        0.503  \n",
       "17        0.263  \n",
       "18        0.193  \n",
       "19        0.150  \n",
       "20        0.530  \n",
       "21        0.283  \n",
       "22        0.190  \n",
       "23        0.162  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KeFVP_MAEC15_final_results = pd.DataFrame(KeFVP_MAEC15_final_results, columns=['Embedding Variant', 'n_days', 'year', 'best_alpha', 'MSE_testset'])\n",
    "KeFVP_MAEC15_final_results.to_csv('data/KeFVP_emotion2vec_MAEC15_final_results.csv', index=False)\n",
    "KeFVP_MAEC15_final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n_days</th>\n",
       "      <th>15</th>\n",
       "      <th>3</th>\n",
       "      <th>30</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding Variant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC15_Roberta</th>\n",
       "      <td>0.186</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC15_Roberta2</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC15_bge</th>\n",
       "      <td>0.179</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC15_bge_base</th>\n",
       "      <td>0.193</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC15_glove</th>\n",
       "      <td>0.190</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC15_investopedia</th>\n",
       "      <td>0.184</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "n_days                                    15      3     30      7\n",
       "Embedding Variant                                                \n",
       "KeFVP_emotion2vec_MAEC15_Roberta       0.186  0.509  0.154  0.281\n",
       "KeFVP_emotion2vec_MAEC15_Roberta2      0.183  0.514  0.153  0.272\n",
       "KeFVP_emotion2vec_MAEC15_bge           0.179  0.497  0.159  0.263\n",
       "KeFVP_emotion2vec_MAEC15_bge_base      0.193  0.503  0.150  0.263\n",
       "KeFVP_emotion2vec_MAEC15_glove         0.190  0.530  0.162  0.283\n",
       "KeFVP_emotion2vec_MAEC15_investopedia  0.184  0.508  0.153  0.267"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "KeFVP_MAEC15_final_results = KeFVP_MAEC15_final_results.drop(columns=['best_alpha', 'year'])\n",
    "KeFVP_MAEC15_final_results = KeFVP_MAEC15_final_results.pivot(index='Embedding Variant', columns='n_days', values='MSE_testset')\n",
    "KeFVP_MAEC15_final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.18s/epoch, Train Loss=0.510, Test Loss A=0.362]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.16s/epoch, Train Loss=0.513, Test Loss A=0.380]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.513, Test Loss A=0.386]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.505, Test Loss A=0.500]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.500, Test Loss A=0.657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.362), (0.3, 0.37), (0.5, 0.368), (0.7, 0.364), (0.9, 0.365)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:17<00:00,  7.77s/epoch, Train Loss=0.483, Test Loss A=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.363)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_Roberta_3\n",
      "best_alpha---------0.1\n",
      "MSE_testset--------0.363\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.18s/epoch, Train Loss=0.325, Test Loss A=0.232]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.17s/epoch, Train Loss=0.326, Test Loss A=0.228]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.16s/epoch, Train Loss=0.323, Test Loss A=0.248]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.16s/epoch, Train Loss=0.319, Test Loss A=0.264]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.320, Test Loss A=0.226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.22), (0.3, 0.223), (0.5, 0.223), (0.7, 0.218), (0.9, 0.217)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:17<00:00,  7.74s/epoch, Train Loss=0.298, Test Loss A=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.211)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_Roberta_7\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.211\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.16s/epoch, Train Loss=0.248, Test Loss A=0.181]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.245, Test Loss A=0.201]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.17s/epoch, Train Loss=0.245, Test Loss A=0.171]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.19s/epoch, Train Loss=0.244, Test Loss A=0.168]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.18s/epoch, Train Loss=0.239, Test Loss A=0.240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.17), (0.3, 0.168), (0.5, 0.164), (0.7, 0.167), (0.9, 0.166)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:17<00:00,  7.76s/epoch, Train Loss=0.225, Test Loss A=0.167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.157)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_Roberta_15\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.157\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.16s/epoch, Train Loss=0.189, Test Loss A=0.145]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/epoch, Train Loss=0.190, Test Loss A=0.140]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.189, Test Loss A=0.178]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.186, Test Loss A=0.189]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.13s/epoch, Train Loss=0.185, Test Loss A=0.254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.138), (0.3, 0.137), (0.5, 0.134), (0.7, 0.137), (0.9, 0.138)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:16<00:00,  7.69s/epoch, Train Loss=0.175, Test Loss A=0.209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.135)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_Roberta_30\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.135\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.16s/epoch, Train Loss=0.510, Test Loss A=0.367]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/epoch, Train Loss=0.502, Test Loss A=0.383]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.481, Test Loss A=0.681]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/epoch, Train Loss=0.481, Test Loss A=0.887]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.487, Test Loss A=0.521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.364), (0.3, 0.371), (0.5, 0.364), (0.7, 0.368), (0.9, 0.379)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:17<00:00,  7.73s/epoch, Train Loss=0.478, Test Loss A=0.379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.347)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_Roberta2_3\n",
      "best_alpha---------0.1\n",
      "MSE_testset--------0.347\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:02<00:00,  6.20s/epoch, Train Loss=0.324, Test Loss A=0.217]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.18s/epoch, Train Loss=0.320, Test Loss A=0.217]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.17s/epoch, Train Loss=0.310, Test Loss A=0.217]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.18s/epoch, Train Loss=0.309, Test Loss A=0.239]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.13s/epoch, Train Loss=0.307, Test Loss A=0.586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.217), (0.3, 0.214), (0.5, 0.21), (0.7, 0.211), (0.9, 0.21)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:17<00:00,  7.76s/epoch, Train Loss=0.287, Test Loss A=0.479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.2)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_Roberta2_7\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.2\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.16s/epoch, Train Loss=0.243, Test Loss A=0.186]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.238, Test Loss A=0.261]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/epoch, Train Loss=0.230, Test Loss A=0.303]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/epoch, Train Loss=0.225, Test Loss A=0.438]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.230, Test Loss A=0.297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.163), (0.3, 0.161), (0.5, 0.165), (0.7, 0.174), (0.9, 0.169)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:17<00:00,  7.72s/epoch, Train Loss=0.218, Test Loss A=0.271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.16)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_Roberta2_15\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.16\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.17s/epoch, Train Loss=0.189, Test Loss A=0.136]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.182, Test Loss A=0.225]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/epoch, Train Loss=0.176, Test Loss A=0.233]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/epoch, Train Loss=0.174, Test Loss A=0.239]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/epoch, Train Loss=0.176, Test Loss A=0.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.136), (0.3, 0.131), (0.5, 0.135), (0.7, 0.136), (0.9, 0.133)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:17<00:00,  7.73s/epoch, Train Loss=0.169, Test Loss A=0.212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.129)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_Roberta2_30\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.129\n",
      "----------------------------------------\n",
      "(980, 500, 804) (980,) (980,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.07s/epoch, Train Loss=0.513, Test Loss A=0.380]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.05s/epoch, Train Loss=0.505, Test Loss A=0.413]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.05s/epoch, Train Loss=0.504, Test Loss A=0.389]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.499, Test Loss A=0.393]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.494, Test Loss A=0.430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.372), (0.3, 0.369), (0.5, 0.375), (0.7, 0.372), (0.9, 0.37)]\n",
      "(1260, 500, 804) (1260,) (1260,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.06s/epoch, Train Loss=0.483, Test Loss A=0.352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.352)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_investopedia_3\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.352\n",
      "----------------------------------------\n",
      "(980, 500, 804) (980,) (980,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.325, Test Loss A=0.229]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.01s/epoch, Train Loss=0.317, Test Loss A=0.218]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.00s/epoch, Train Loss=0.318, Test Loss A=0.219]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:39<00:00,  4.00s/epoch, Train Loss=0.317, Test Loss A=0.215]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:39<00:00,  4.00s/epoch, Train Loss=0.315, Test Loss A=0.217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.22), (0.3, 0.218), (0.5, 0.219), (0.7, 0.215), (0.9, 0.217)]\n",
      "(1260, 500, 804) (1260,) (1260,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.05s/epoch, Train Loss=0.294, Test Loss A=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.195)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_investopedia_7\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.195\n",
      "----------------------------------------\n",
      "(980, 500, 804) (980,) (980,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.05s/epoch, Train Loss=0.245, Test Loss A=0.165]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.03s/epoch, Train Loss=0.243, Test Loss A=0.176]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.242, Test Loss A=0.177]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.239, Test Loss A=0.183]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.01s/epoch, Train Loss=0.236, Test Loss A=0.256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.165), (0.3, 0.165), (0.5, 0.168), (0.7, 0.164), (0.9, 0.167)]\n",
      "(1260, 500, 804) (1260,) (1260,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.08s/epoch, Train Loss=0.218, Test Loss A=0.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.145)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_investopedia_15\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.145\n",
      "----------------------------------------\n",
      "(980, 500, 804) (980,) (980,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.03s/epoch, Train Loss=0.190, Test Loss A=0.137]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.03s/epoch, Train Loss=0.188, Test Loss A=0.133]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.03s/epoch, Train Loss=0.186, Test Loss A=0.135]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.185, Test Loss A=0.143]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.04s/epoch, Train Loss=0.185, Test Loss A=0.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.137), (0.3, 0.133), (0.5, 0.135), (0.7, 0.135), (0.9, 0.138)]\n",
      "(1260, 500, 804) (1260,) (1260,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  5.11s/epoch, Train Loss=0.175, Test Loss A=0.130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.13)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_investopedia_30\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.13\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.10s/epoch, Train Loss=0.506, Test Loss A=0.437]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.11s/epoch, Train Loss=0.497, Test Loss A=0.571]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.06s/epoch, Train Loss=0.490, Test Loss A=0.415]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.06s/epoch, Train Loss=0.496, Test Loss A=0.434]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.06s/epoch, Train Loss=0.488, Test Loss A=0.418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.377), (0.3, 0.375), (0.5, 0.37), (0.7, 0.384), (0.9, 0.378)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:16<00:00,  7.67s/epoch, Train Loss=0.462, Test Loss A=0.361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.35)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_bge_3\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.35\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.07s/epoch, Train Loss=0.322, Test Loss A=0.252]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.07s/epoch, Train Loss=0.316, Test Loss A=0.230]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.06s/epoch, Train Loss=0.313, Test Loss A=0.215]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.07s/epoch, Train Loss=0.311, Test Loss A=0.223]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.06s/epoch, Train Loss=0.305, Test Loss A=0.232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.229), (0.3, 0.219), (0.5, 0.215), (0.7, 0.218), (0.9, 0.221)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:16<00:00,  7.65s/epoch, Train Loss=0.290, Test Loss A=0.207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.2)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_bge_7\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.2\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.17s/epoch, Train Loss=0.242, Test Loss A=0.181]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/epoch, Train Loss=0.239, Test Loss A=0.167]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.16s/epoch, Train Loss=0.234, Test Loss A=0.180]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.19s/epoch, Train Loss=0.231, Test Loss A=0.196]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.18s/epoch, Train Loss=0.229, Test Loss A=0.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.164), (0.3, 0.167), (0.5, 0.165), (0.7, 0.163), (0.9, 0.165)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:17<00:00,  7.79s/epoch, Train Loss=0.212, Test Loss A=0.189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.146)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_bge_15\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.146\n",
      "----------------------------------------\n",
      "(980, 500, 1060) (980,) (980,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/epoch, Train Loss=0.188, Test Loss A=0.138]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.12s/epoch, Train Loss=0.183, Test Loss A=0.142]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.11s/epoch, Train Loss=0.182, Test Loss A=0.141]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.13s/epoch, Train Loss=0.178, Test Loss A=0.147]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.11s/epoch, Train Loss=0.178, Test Loss A=0.135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.136), (0.3, 0.135), (0.5, 0.134), (0.7, 0.132), (0.9, 0.134)]\n",
      "(1260, 500, 1060) (1260,) (1260,)\n",
      "(280, 500, 1060) (280,) (280,)\n",
      "(280, 500, 1060) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:17<00:00,  7.73s/epoch, Train Loss=0.164, Test Loss A=0.154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.122)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_bge_30\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.122\n",
      "----------------------------------------\n",
      "(980, 500, 804) (980,) (980,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.07s/epoch, Train Loss=0.515, Test Loss A=0.373]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.03s/epoch, Train Loss=0.504, Test Loss A=0.402]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:39<00:00,  3.97s/epoch, Train Loss=0.501, Test Loss A=0.388]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:39<00:00,  3.96s/epoch, Train Loss=0.498, Test Loss A=0.414]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.01s/epoch, Train Loss=0.498, Test Loss A=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.373), (0.3, 0.374), (0.5, 0.388), (0.7, 0.373), (0.9, 0.385)]\n",
      "(1260, 500, 804) (1260,) (1260,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.09s/epoch, Train Loss=0.485, Test Loss A=0.371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.366)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_bge_base_3\n",
      "best_alpha---------0.1\n",
      "MSE_testset--------0.366\n",
      "----------------------------------------\n",
      "(980, 500, 804) (980,) (980,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.323, Test Loss A=0.222]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:39<00:00,  3.99s/epoch, Train Loss=0.322, Test Loss A=0.230]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.06s/epoch, Train Loss=0.316, Test Loss A=0.221]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.04s/epoch, Train Loss=0.313, Test Loss A=0.220]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.313, Test Loss A=0.224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.221), (0.3, 0.223), (0.5, 0.219), (0.7, 0.215), (0.9, 0.22)]\n",
      "(1260, 500, 804) (1260,) (1260,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.05s/epoch, Train Loss=0.294, Test Loss A=0.205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.205)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_bge_base_7\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.205\n",
      "----------------------------------------\n",
      "(980, 500, 804) (980,) (980,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.245, Test Loss A=0.169]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.00s/epoch, Train Loss=0.243, Test Loss A=0.164]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.00s/epoch, Train Loss=0.239, Test Loss A=0.167]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.237, Test Loss A=0.197]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.235, Test Loss A=0.180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.168), (0.3, 0.164), (0.5, 0.167), (0.7, 0.167), (0.9, 0.164)]\n",
      "(1260, 500, 804) (1260,) (1260,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.08s/epoch, Train Loss=0.224, Test Loss A=0.158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3, 0.157)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_bge_base_15\n",
      "best_alpha---------0.3\n",
      "MSE_testset--------0.157\n",
      "----------------------------------------\n",
      "(980, 500, 804) (980,) (980,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.04s/epoch, Train Loss=0.190, Test Loss A=0.137]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.02s/epoch, Train Loss=0.186, Test Loss A=0.141]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.00s/epoch, Train Loss=0.184, Test Loss A=0.134]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.00s/epoch, Train Loss=0.183, Test Loss A=0.133]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:39<00:00,  4.00s/epoch, Train Loss=0.184, Test Loss A=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.137), (0.3, 0.134), (0.5, 0.134), (0.7, 0.133), (0.9, 0.133)]\n",
      "(1260, 500, 804) (1260,) (1260,)\n",
      "(280, 500, 804) (280,) (280,)\n",
      "(280, 500, 804) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.07s/epoch, Train Loss=0.171, Test Loss A=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.127)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_bge_base_30\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.127\n",
      "----------------------------------------\n",
      "(980, 500, 336) (980,) (980,)\n",
      "(280, 500, 336) (280,) (280,)\n",
      "(280, 500, 336) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.59s/epoch, Train Loss=0.513, Test Loss A=0.376]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.59s/epoch, Train Loss=0.514, Test Loss A=0.392]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.49s/epoch, Train Loss=0.510, Test Loss A=0.366]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.50s/epoch, Train Loss=0.516, Test Loss A=0.374]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.55s/epoch, Train Loss=0.511, Test Loss A=0.377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.376), (0.3, 0.38), (0.5, 0.366), (0.7, 0.372), (0.9, 0.37)]\n",
      "(1260, 500, 336) (1260,) (1260,)\n",
      "(280, 500, 336) (280,) (280,)\n",
      "(280, 500, 336) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:20<00:00,  2.04s/epoch, Train Loss=0.485, Test Loss A=0.369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, 0.363)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_glove_3\n",
      "best_alpha---------0.5\n",
      "MSE_testset--------0.363\n",
      "----------------------------------------\n",
      "(980, 500, 336) (980,) (980,)\n",
      "(280, 500, 336) (280,) (280,)\n",
      "(280, 500, 336) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.63s/epoch, Train Loss=0.325, Test Loss A=0.226]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.46s/epoch, Train Loss=0.325, Test Loss A=0.241]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.48s/epoch, Train Loss=0.325, Test Loss A=0.240]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.53s/epoch, Train Loss=0.325, Test Loss A=0.235]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.66s/epoch, Train Loss=0.325, Test Loss A=0.232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.226), (0.3, 0.229), (0.5, 0.229), (0.7, 0.232), (0.9, 0.224)]\n",
      "(1260, 500, 336) (1260,) (1260,)\n",
      "(280, 500, 336) (280,) (280,)\n",
      "(280, 500, 336) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.95s/epoch, Train Loss=0.302, Test Loss A=0.227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9, 0.223)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_glove_7\n",
      "best_alpha---------0.9\n",
      "MSE_testset--------0.223\n",
      "----------------------------------------\n",
      "(980, 500, 336) (980,) (980,)\n",
      "(280, 500, 336) (280,) (280,)\n",
      "(280, 500, 336) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.54s/epoch, Train Loss=0.246, Test Loss A=0.183]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.62s/epoch, Train Loss=0.247, Test Loss A=0.175]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.51s/epoch, Train Loss=0.245, Test Loss A=0.168]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.49s/epoch, Train Loss=0.246, Test Loss A=0.168]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/epoch, Train Loss=0.244, Test Loss A=0.173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.18), (0.3, 0.169), (0.5, 0.168), (0.7, 0.166), (0.9, 0.168)]\n",
      "(1260, 500, 336) (1260,) (1260,)\n",
      "(280, 500, 336) (280,) (280,)\n",
      "(280, 500, 336) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.90s/epoch, Train Loss=0.229, Test Loss A=0.163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.163)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_glove_15\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.163\n",
      "----------------------------------------\n",
      "(980, 500, 336) (980,) (980,)\n",
      "(280, 500, 336) (280,) (280,)\n",
      "(280, 500, 336) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.57s/epoch, Train Loss=0.191, Test Loss A=0.139]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.61s/epoch, Train Loss=0.190, Test Loss A=0.138]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.61s/epoch, Train Loss=0.190, Test Loss A=0.138]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.56s/epoch, Train Loss=0.190, Test Loss A=0.138]\n",
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.62s/epoch, Train Loss=0.190, Test Loss A=0.142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1, 0.139), (0.3, 0.138), (0.5, 0.138), (0.7, 0.137), (0.9, 0.137)]\n",
      "(1260, 500, 336) (1260,) (1260,)\n",
      "(280, 500, 336) (280,) (280,)\n",
      "(280, 500, 336) (280,) (280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.93s/epoch, Train Loss=0.179, Test Loss A=0.139]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7, 0.138)]\n",
      "----------------------------------------\n",
      "run_name-----------KeFVP_emotion2vec_MAEC16_glove_30\n",
      "best_alpha---------0.7\n",
      "MSE_testset--------0.138\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directories = ['KeFVP_emotion2vec_MAEC16_Roberta', 'KeFVP_emotion2vec_MAEC16_Roberta2', 'KeFVP_emotion2vec_MAEC16_investopedia', 'KeFVP_emotion2vec_MAEC16_bge', 'KeFVP_emotion2vec_MAEC16_bge_base', 'KeFVP_emotion2vec_MAEC16_glove']#\n",
    "#years = ['_2015', '_2016', '_2017']\n",
    "\n",
    "KeFVP_MAEC16_final_results = []\n",
    "for data_directory in directories: # different feature engineering features\n",
    "    for n_days in all_n_days: \n",
    "        #for year in years:\n",
    "        year = ''\n",
    "        best_alpha, MSE_testset = train_val_test(data_directory, n_days, year)\n",
    "        KeFVP_MAEC16_final_results.append([data_directory, n_days, year, best_alpha, MSE_testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding Variant</th>\n",
       "      <th>n_days</th>\n",
       "      <th>year</th>\n",
       "      <th>best_alpha</th>\n",
       "      <th>MSE_testset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_Roberta</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_Roberta</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_Roberta</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_Roberta</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_Roberta2</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_Roberta2</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_Roberta2</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_Roberta2</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_investopedia</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_investopedia</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_investopedia</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_investopedia</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_bge</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_bge</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_bge</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_bge</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_bge_base</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_bge_base</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_bge_base</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_bge_base</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_glove</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_glove</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_glove</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KeFVP_emotion2vec_MAEC16_glove</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Embedding Variant n_days year  best_alpha  MSE_testset\n",
       "0        KeFVP_emotion2vec_MAEC16_Roberta      3              0.1        0.363\n",
       "1        KeFVP_emotion2vec_MAEC16_Roberta      7              0.9        0.211\n",
       "2        KeFVP_emotion2vec_MAEC16_Roberta     15              0.5        0.157\n",
       "3        KeFVP_emotion2vec_MAEC16_Roberta     30              0.5        0.135\n",
       "4       KeFVP_emotion2vec_MAEC16_Roberta2      3              0.1        0.347\n",
       "5       KeFVP_emotion2vec_MAEC16_Roberta2      7              0.5        0.200\n",
       "6       KeFVP_emotion2vec_MAEC16_Roberta2     15              0.3        0.160\n",
       "7       KeFVP_emotion2vec_MAEC16_Roberta2     30              0.3        0.129\n",
       "8   KeFVP_emotion2vec_MAEC16_investopedia      3              0.3        0.352\n",
       "9   KeFVP_emotion2vec_MAEC16_investopedia      7              0.7        0.195\n",
       "10  KeFVP_emotion2vec_MAEC16_investopedia     15              0.7        0.145\n",
       "11  KeFVP_emotion2vec_MAEC16_investopedia     30              0.3        0.130\n",
       "12           KeFVP_emotion2vec_MAEC16_bge      3              0.5        0.350\n",
       "13           KeFVP_emotion2vec_MAEC16_bge      7              0.5        0.200\n",
       "14           KeFVP_emotion2vec_MAEC16_bge     15              0.7        0.146\n",
       "15           KeFVP_emotion2vec_MAEC16_bge     30              0.7        0.122\n",
       "16      KeFVP_emotion2vec_MAEC16_bge_base      3              0.1        0.366\n",
       "17      KeFVP_emotion2vec_MAEC16_bge_base      7              0.7        0.205\n",
       "18      KeFVP_emotion2vec_MAEC16_bge_base     15              0.3        0.157\n",
       "19      KeFVP_emotion2vec_MAEC16_bge_base     30              0.7        0.127\n",
       "20         KeFVP_emotion2vec_MAEC16_glove      3              0.5        0.363\n",
       "21         KeFVP_emotion2vec_MAEC16_glove      7              0.9        0.223\n",
       "22         KeFVP_emotion2vec_MAEC16_glove     15              0.7        0.163\n",
       "23         KeFVP_emotion2vec_MAEC16_glove     30              0.7        0.138"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KeFVP_MAEC16_final_results = pd.DataFrame(KeFVP_MAEC16_final_results, columns=['Embedding Variant', 'n_days', 'year', 'best_alpha', 'MSE_testset'])\n",
    "KeFVP_MAEC16_final_results.to_csv('data/KeFVP_emotion2vec_MAEC16_final_results.csv', index=False)\n",
    "KeFVP_MAEC16_final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n_days</th>\n",
       "      <th>15</th>\n",
       "      <th>3</th>\n",
       "      <th>30</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding Variant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC16_Roberta</th>\n",
       "      <td>0.157</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC16_Roberta2</th>\n",
       "      <td>0.160</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC16_bge</th>\n",
       "      <td>0.146</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC16_bge_base</th>\n",
       "      <td>0.157</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC16_glove</th>\n",
       "      <td>0.163</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KeFVP_emotion2vec_MAEC16_investopedia</th>\n",
       "      <td>0.145</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "n_days                                    15      3     30      7\n",
       "Embedding Variant                                                \n",
       "KeFVP_emotion2vec_MAEC16_Roberta       0.157  0.363  0.135  0.211\n",
       "KeFVP_emotion2vec_MAEC16_Roberta2      0.160  0.347  0.129  0.200\n",
       "KeFVP_emotion2vec_MAEC16_bge           0.146  0.350  0.122  0.200\n",
       "KeFVP_emotion2vec_MAEC16_bge_base      0.157  0.366  0.127  0.205\n",
       "KeFVP_emotion2vec_MAEC16_glove         0.163  0.363  0.138  0.223\n",
       "KeFVP_emotion2vec_MAEC16_investopedia  0.145  0.352  0.130  0.195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "KeFVP_MAEC16_final_results = KeFVP_MAEC16_final_results.drop(columns=['best_alpha', 'year'])\n",
    "KeFVP_MAEC16_final_results = KeFVP_MAEC16_final_results.pivot(index='Embedding Variant', columns='n_days', values='MSE_testset')\n",
    "KeFVP_MAEC16_final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3dbe179ae4b6e61a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3dbe179ae4b6e61a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir KeFVP_runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (1896645534.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    :)\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/mpeg;base64,//PkZAAgGgkCAW8MLpyj4hVuGMsdCfywmqQRpgwYsLJItEkKqgEAjutRmDkMwCExjLtsTXemIXALiMkhiHMHQXQy934bZ2ztnbX3Ld9+IYfxyIcdhYRYjLHfcuH3zM/OyWrYJAkGEUpBAA4BMCYHwbiOZmZmJYNAaA0Eg8r5wYCWIYliWJauWzMSAaA0JhgJANCwsP7lcSzMSxLEs/iSCRF7BIJiz9O37r373cpRhZ0zh2SxLJ5LEMSzMzJjkzNJxYf/y+PV915MixYSCZXOYq/clk/215geLFixYsMFFNvdtfbrrFiyjCzfmpm/N/pVesWa+wsWVfbXmbxg5OUnzhRdgwPKLzt/J47P7rNfm8tvgZ4eHj8oJIBL6JYAIEEWmTxEABGHF9MIIQ0Jz0J+m7uHMkTd3/AxZolcDF/u7vBB+hOLOfehxcTeJE/rwAEU0UAI/m7k7wn6buBi4nwWehPq4QAinE3Ezr/9CEbIQhCaEnD5xM/6EY5Cf6nO/////qdyEDgABwAVBEdDIQpj4CPGISJ2YS4QZgHgIGBOAiDQUjAPAmKgKhkHgORglOTpAS9RVDK6i5d0EkFZjIkSsgVBwIIgaWQJElURWxFpUQQCLqpzrJjKXggDJjhgrZUI//PkZFcnsgz+YHtPLp4zGhikOk74IBy8aAcu/VVeA74AdBOwHR8BmejPIObB8AzgtR+BQzbNUb5OtQXpE4I0UhiFYRJUFfCERrWtRW8O/itDWFPfb4GciHxUVImoau1iNCEEQRojYakr9EeRnQq4NRBhmb0BjfV/4Gf7wIMBnFPtYo3z4MMiyNkSRNRDNEcR9XxFFHGHsWew1dckNKCKHcKwVnsKoVG+KwNbddQWFWxaxdZEFta1rZFXWtpVayxdCszWwoBErPnzELurnr0QUUyusCsgigtkDM9r+IfWCV498lfyrtWxGsWfFYPapVlXvj3I8iSoe2CgoKCoAG1EEOiHEGDYjCWJwfxNgpxV+ePnOdOCv87vBAPDn4f/sfiMB8XGFHOT73OT504KBVxUdP86dOHP0bnmTySJNASNkaSf8B00OChohh3iHDAcIMBmFIhiAN8QCA0KN/g0Fc0DDv//DEQea2cGAu+IP8QnfJEf//LFVQAxQNG5EWDBMg00wZcCtMBoAzzArQEYwEcCKMAEAJzAiwCYrAaSsAEMAFABSsAmMAmAaDAJgCcwCYAnMAaAUjAGgFIwFIAbMBHABSwAjGATgApgAgBMVgAhgAgCOYAIACmATAE5gAoAKBix//PkZGsrwgj6tK/QACVLRfwBTWgAcLhAMULC4cBQsBhAgRCAacKBpgoGECwiEhhgbB4YcMNC6wApYLrg2DINg4IlgwwYcGwaGGAy5cGwcGHDDg2DQwwXWDDBdYLrhhoXWC64YeES+DYNC60GwZwMIF+EQvAwgQGBQYECITAwoX4MCQiEAwoSDAmDAuDYMhdcMNDDg2D4YcLrBhoNg3C6+DYMwwwXXBsHBhwbB4YcGwdBsGwuuGGC68GwfC68LrhdeF1wusF1gbBoXWDDBhuEQkGBPBgX4MC/CIQGBYRC/hEIEQsGBPwiE//4RC+EQnDDQbB0GweF1guuF1gbBkLrYXWhh/hdf4XXBrBqBrwawa8NIaA0QJiGgCZhqDV+DWALgNIjhICREiJAFoDWBMQ1hrDQBMwJhw1YEzw1BpDSGqGoNQaQBc4NXg0w0+BMQJhDWGvDWJCC0CO4jxHCOBagWoR4ArRIcGn+DUDQALmDVwasGiDTg0/g0+DVDRDRDVw0hqDXhow04avwavBqBpwa8GsGj/Br8Gjg0/wa+DWqLFgyFoulqutrkckkaDM5gp5DCQaMWAkzuYDmVeMKg9fYsZzKYbOOHw/HKzC4XGAahMaYY/LhmANM6QXjQQWBUXCo//PkZEIn0hc3L85sASd7rkEVg0ABEcBAHAMAGWEknzZ3GiIrMOAisCTfMUOCwZmmkJzjg6b5xlfsbjMbdJ0HXAwY0xeCKDyM5dWMur9Ezt043GGcukYQBIKL8TjVsSQjcbjUZoGduq6FE+VHGqKjV2ztxy4CKDTFd08Quxe7SyW5FJPfp6alk96k/6N1lcUToM4dR86X7t+lk1PJJNdpae9ficnity5TX6aTX1bExAwDjcbfNnDqUf0TpxqMfQ0X0H0UaoKKi+jofoKH6Kg/6Ogo6D//6ONxiMUVB/xih9MRnDqPnGP////////v////////////////////uoztncbZxGIxRxiioIxGKOioo3QRgSFgwJDnihSRSvVILguqrNnEi5AiPE6JSUzDRQaDzu0MwlKLEcSsQzK3QhmwHgNxGEERjUFRiS7HZ5SB6WHYjmOZRxIhtFokYoPEA8Gx6ocY1jC6oRTZVFiJZ6HRA8se76ujwi/KzA5Fee9Et2kqtH5jlB7QtM+OlpuLi1qmW6074u4S4qar9OJHDLm75/RfyVMqRaPkK/VcsFCJ1/dVgFUJEUu+/21ut1t1p0OlQswxlkDAWAgysCMt6DASMaREMLSQBwOmJoaA4CTCkNjC//PkZDAmUhFQ387oASWj6hwLh1AAQZwIAwWEOBB4BzzrAIFFhgOBqQiSeV2mDbpsEoEC0ykYtTXlEHyoKIhExkLgAsPSRZ0zpNpJJ0I1GlbAQBfG4q2SqpPIoYraQAExqFW1fsao/+Ns5X+v1XUbQVV06VyKxaIxKS/J78Xu3rl58V4RJu6mkQcOIXKV/aS7evXqa7Jbt2lpYlTU1144lTRFulLfpYrEorFbty7SuLe/79Ldvxmg+jjdB9D9F/xr4zGvjMaoaKgjUZfCNPjRXaX/uf//9+7TXaa5ru9b1+vx3vmeWoNg9yoPcuDHKcuDvcuDoNcqDnK+D4P//pbl+7c+JUt7/vf9y/S3v////+5fu3P+///90gggFPBQFIMgrBng0P4eg3CMIweh74fcPg9gUoFKHvh5joF0ciiDaKRGEaH3jgvEQOx0PsPYegUA+h58cHR2DMUCiDYI4jRTwbcRsRgKIfB+HofB5D0PIfeHgeh4HmHgfQ/h78Ph0dHBFCIF4uEX/D7w9D0P8PcUwbuI8R8RxHEfD6H4eB6HgFCHvh/Dzh/w+//////gUyQCbvqcZ3MM7mSQNUY1aKxkKguGEmjyYuycRh0jnGFGEmduwJhntnTmeUC4YSQbJipg//PkZDImAgsQCe9QACDT2eQB05gA3GLIGyZyg7xhRiPmFEBSZWAjxhsjvGUeEAFgBjAXBvMEwBYwKAtTApBNMCkE0D37wGFoGHDAYcuBhroDA0DdlgGBgDA4SoMVBEOJoJUJqJWJoGKgxQJrF2F4C7F2MSMUQUEFgvIG6AguMUQVF0LsQViCguhFRcwuYhRcwuYXOPwucRUXIP4/j8P2PxCELj+P5C8hCWjmSUJSSvibxzyXkoOeJwktkrHOJSSxLEsSxL5L5LEvkrJQcyOaSxKDmDmDmxzSW8lJKZK//4gvxi/F0LoQXxdC68hCEIQhCEIQf4/kJkIQkfvIQf/+QnkIQhCR/i5CEH4fyE5Cx/j//IQGb/hHYRIDCBEkD3vA9agx4RdBj8GahHXwjqDNgzQR18De8GPwY8Dc7COwjsI6Bm4R3+Ed8I6/CO/COsIuCLwN7oRfgx4Mfwi/8Ga4M0Edf/8Gb4M3/gzQHvQR2Ed///gzXBm/4MdCLgY/CLv+EXYRd4McEX4Md/Bm/+DN////Bj/wY9UUDVzRlsyn4SlMO1BrzBIyGIxb0FfMN5A0jC7BBkxKQPcMInHNzEkQG8x68UwME3BwzG7jTZqJjes+zrFNjZu7DQ9wjpyOAn4j//PkZEkn1gcGFH+tPiIEAegAnOMcok0jB8CjOdmjAsHzFo0jL8CzB8HzTcMggtzDIHzEYM1GzAsHisHlGisCggFTAoHkVwgFFOAoBfoqIrKcGBQFhUClOQoBYQC5WBSKiK4QCqjYQCoAQoqCsKsVBWxXBOBXBOBXFQVQTgVYqwToE7FcVhXFYVcE7FUE4FQE5ipBOgjBEYRgiYRABvBEBHhG+ETwjBHCMEYI0I4BugG6AboR8A3QiMI4R4qirBORXFSKgJ18VBXxU8VhWFYI0I3CMAbvwiQiQjBGhEYRP4RIBugG6EYVYJ1FQE7/BOuKwrCrxXBORWFQVIqRW4rcVP4JzgnIq+K8VOK/hFwMfBj/wYTCJYRcEX/BmgPWvgb3hF4MeEXYMdwZqEdgzQM1/gzf/4R14M3wjvgzfgzWEdwZoGagzcIkgwgMJgZCAZShEkIkBhQYTgwn//wZv/CNgyBGQZQjMIz8IwIzBk//////4MuDKDJCNwZeDLCN4Mn/4YcLrBhvC63C60LrQuv+F1wuukBM0nR6jEpjE4we0LGMBlMeDGsQewwvIRPMFrBljEpxE4xCI4tM8zGsDDdQZcw3QETMNIDzDBEwcIw8wA6ORJxLEiHDIHmMpInjxInO//PkZE0qqgb+BX+tTiC7jfQAhBtcAdGtSJmtRImB4dmXh0GBwHmiS1mSIHFgDzA8ZDA8OjDsOjDoZTDoDjA4OisDjA4DisDzA8DysDjCcBCsBDAUBSsBCwAhgIAhgKAhgIApactIWm9NktMWAXTYAwWlpS06bKBSbBaQsAsWmQKLTFp4RARAROEQEcIwRwiADfCOCdgnIriuK0VAEEVwTkVBXioAEYIiAb0IgI4RIRPAN+EYI8I4RIRoFmAB4C3gWIFsADwAHgLcC3wAOeEYA38A3wDcCMEYI+AbwRoRuESEcI4RMIkI0AD3At//+BY8CzAtfgW/AsfAtgWALAFj/Atf4FsC2BbgAcAsAWsCyBbAtgWYFvAA5AtfAtgWv+BhhiiJr4MAiYRPhEgw8GMIoMQiBFhE+EQGEDUIsIgGARIMQiwihEwYQ84eeHmDyw88PKFkGFkMIuDCEXhE4RPAx+DEGHBjCJCJA0CJ/BiDEIv/hZFDzwsj//DyQshh5YeT/wYfgw/4MfwaAagaYNGDUDUDUDVg14NANPg1QaYNGDVVWAJo7tgn/TaqVo7GJ8J8aqon5n8CfmU0J8Ynx/JififGjsRYVtg+YWYwJkojAFgLIwsgszCzGBLAwBWU0Yn5//PkZD8mvgUACXttbB7TtgQAaBokTZWU157K8WF4sL5WvmvbBXIGdsnmHHZWdeBRcrFiwLAYt8rF02U2SwLFpU2E2UCi06bCKoUCkVQqFKNorBQLRXUaRXKwpRpFcrCkVFG1G/CBQIF0Cy0xaX02UCi0haRNgtMgWWlTZgW8CxgWcCxAA7AsgAcioK4rCsCdioKoJ0KsVBUgnWCdAnArgnAJ2KuCcAnYqCrFQE64rQTkVQTgVhWFQVRXFQVxUirFQVBXFbFYE7FYVhUioCcCqKwJxBOBXisK2KoqRUFYVBV/wTsVxVgnXFb////gWgLPwLYBuBGCMEQAb/ANwI4RuEYIkA3gDcwDdwjwjisK0VRXxUFUVRWFcVxViqK/ivBOYqirFcVhXFYVMVxW4ritFYVhU/iuK8VhXBOBU4r+KwJyKv/FeK4rYrfF4XMXwtYui4FrFwLTwtULQLv4q8VuKv4qYqgnEVor4rfirFWKorAnOKn8VP/xXFT/iv4q+K8VfFYV///+K6oB+gIE4dKA/3bwyhEExSFI01BorBoz/EEsCCVlCZQK8Z/iCYgCAYNkaVkYYpEaWDFMUwbKwaMUyNKwbKxSLANhAeFYFFYPIqorKcBAKlgClOUVlOPVKqRq//PkZFggBgEQKnXnniEjthRSao/o7V1TeWgCkWgI8shNeArCbFqWhagKImha/nyfJOScn3z7JyfZO+GuTg+D55OD5J0fJ9E75OOvNPXl5D/+vNC+vde/af0O/7Svr6/+0IavtCGdo6Gf9fX2le7R+0ftHQ1faUPX2hpaXbS0oav9D0NaUM6H9pQxo7ShqGn3D8PgOEHw/h4fgNw/iH8QiABgfgNh4hw4QQ/Dg7h8PDhBEEG/AA/BTBQGwU4KgRKVMdRmGeOmM8Z4zCN/+OuOuI1BOorRXFfx0jOM0VhUBO/ivjOM4jQzxnGbHUZo6iMxGRmEYGcZxm4z8dcZojcZ+CcCpBORXivFSK8E7FXFbBjw6DH/gFYcBmHkPIew/D2H/D3w/w+D8PvgxwYgx/8Av4cDoBTgpBn/BT+DODAb+DfwbRQO+LBPM7ANbzEMxSNM/SMMjAbMUj8MjD9MGxTMxD8M/SMMjSNNNBSMUzEM/QbKyMMGwbMGiNMUyMMjRT8sA0ViFiYxZjFEMUVFVFZFZTlFdFUrBMABU6pVSNUKwPar7VvLACplSvmXLZy+bOfZ2+LOxdF3i6FqC1BaBci4LsXhdF8XgtIui9i4I0GkNYjIjYOoRsdYaIjYzxnEZFYV//PkZJ4hKgUGFHctaB8DpgRIbhsAhWFYV4rxUxW4qYqR0EZGYdRnHUdBnHUZh0EaEYEZHQRkRmM46xnF0XovC6Lovi5xfC0wtfF3i5F0XcXIvhaheF/i9F4LTi7F2L8X8XYWgXcE6xX/iripxV/4qfi+Fo/FyLmLwWjC1i5i5xeAxARHCI4ROER/wjwiYRoR/oqhRSnKnKjaKyKgrioKwrCpFaFqi5F+Fpi7hEBG8I4RMLQL8LXC1C5xcF7BOxUFXFcVvFXFUVor4q4qir/wTmKuK+K/xXioK0VwToVBWFQVorCr+KwrcV/FSKvhG//hE//CNhG//CJ///8VlUxBTUUzLjEwMFVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVUhB5V+Zw7lZmcE5gIRZhONBgIApmcRZWIxjQE5suqhkWAhYAQwmGksGcWBpMnJisFNpRzBIsycFNHJiwCigMKA5ckFHoIE0VCwFIrIr+pwHAKp2rqmVIqZqrV1TKmVO1dqzVfVN6plTKk//9nDO2cM59JFIx8GdJHM6GYRgZhmEbEYHQRkdI6jPEZGYZ8RmI2I0Ogzx1jNjOIyIyDoEYHQRkRkRsZxGRGhGcdR1HQXBcFwLR//PkZLQgHgcIFXdtTh+rUgQqa9sAxfha4ui/F6Fq+LsE4gnUVYrRUwTjFTFYVcVfFf/iuK/xX/Fb8Xov/xfi+L/i8LnwtUXIvRfF/HXHXGYdR0GcdIzDpjOOuOg6CMRG4jQ/QwLGEaKwqRVFfAsxUhH4qCrFYVxVFcVYr+NsHMNvjaBzRUFXFUVhWwLP4FoC0BZAt/8IwRgjcIwRoRgjRUgnYrgnIJ2K2CcCoCcRV+CdxX4qfiriqK2KwJ34qgnfFbBOOEeEcI+Ef/8I/+KsVv4qfir4q4qxXiv4q4rxU8V1Eb4BcxnpqhGDSBMWARzAnCKMEcK0wRgaTBoBoMh0RAwrBVDBHCLMK0Gk4toNHBDRs8sAptLQYJnliLMnJiwTmCExYRisENHBSwTmCAoGYgMXlpy0xaZNktMWlTYQLQKLSFpSsBVKHEapWrlYAqVUgVCwqFKNFYUpwpyiuisFQoA3AiAjBEBEhEhEBHCMESAb4BuhGCOAb4BuhHCJAN6ESEQESAbgBuhEwiIRMIjCMERAN4A3QjhHhEBEQjBEBGwiQiAjBEQDcAN4A3IrRWBOgTsE5FbFcE4FUVQToAIcE5FYVIJwK4rwLEC0BaAt8CyBaAs4FuBbgWwLOBb8A3oR//PkZP8l5fb+EHttPidjneAAnKfEwj8ImEcIiETCIwjQjQDe/hG//+BbgWvAtgWMC3wLMC1CJ+EaEbCMAbsI4RwiAjBE/gzXhHQR1hF4G92EdAe9QMpQiQDKQIkhHXge9+BucEXgb3AzQR2EdeDNwjoI6hHfgx0IvhF4ReEXgbnAb3BF8GbhHfCOuB71hHfCO4M3Bm/8I/gf8DPgzoR/gzgP/A+/CPAfdgffCPBH4M8D/sGdgzgPvA/6DOCPwZ3//4R1/BmwPW//4M3+DNf8IvBj/A3OCLoRf//CLvwN74RcEXJMQU1FMy4xMDCqqqqqqqqqqqpaDTOHT48JzXQzzf0BDCYaTAUijK0BTAQaDIsrDO5EDEcJiwIxp056Y56NJ6dB6Qhxox6U56I5YTlacsOyt2VjjHjzHD0VTFi1GgqKRVLAotN5YL+WlLTFpkVkVjFClOQgqFRanKnCnCKnlgV6K6jSjSnIFkCwBYAtAAdAtgWQLYFoC0AB2Ab0A3gDeCJCICJCOEYA3giQjBGCOAboRoBuhEgG7CICOAb4BvhGCMEYA3IRMA3uEYI4RARARoROAboRAJwK4JwCdAnMVxUFUVwAhgnAqiqCdAnIJwCdRVFUVRUAtgWoFkCx+BYw//PkZOsk3gj+FHdNPiPbxfQog2FkLPAsfgWALMC1wLeBZgWgLcCzwLXgWcCyBbwLUC0Bb8Cz/gW8Cx4FjgWQLfwLfwjBG8InCIANzhHwjeEQOXhEwsjDzhFwiAwCJwYfwYhE4RYRAigwBjgaYRQNAYhECJhFhFgYBFBiBqGvDWGkNPDUGuDSDRg1g1A0g1A0g1g1A0gahFgwCLBgDEIgRANAYwNIRcIoRQNAY4MPBhCIETwYBEA1Bj/4MOESEUGHCJ4MAicGMGPgx/4RcGHgxCL/+DAGP/8GH//gw/CJ/hFqPIdFY2wh6TGABLMOQOQwZAfgMEsYZoC5gYgYlYMpgyhZGH+AuYGAC5glgYGAuAuYJQGBgLglgQBYwSwMTAxBlAwZAEAXAwFgGBiLSAUBdNkCgLAYiDBFYAcEDEAE0IsAqgi4MoBVguGAVcLhQFUEXA7vC4QLhAuFhGguEiLxFQwwYeGGwuuGGDDBhwwwXChcOIrC4YReIoIsFwwXDhcOIqFwgioioi2Fwoi8RQRQRURWIvEUC4SIsItC4WFwoXCiKwuFEWhcLiLxFeFwsRURURbEUEWEVEWEW/EUEUC4QRYRbEWEUEUhcLEXEXC4fEWEWiKiKiLCKiKww/4Yf4Yc//PkZP8mVgr+AK9IACkjneQBVJgALrQw34XXDD4Yf8LrQw3hhv4YYLrf8LreGHxFuIsIqIpEUwuEEUiKiLCLCLCKCKxFOIsIsDEXhFGERAREwYihFEDAIMAhEDwiVwiUwiihFEBgABhBCIIRDBlAjSEaBGkGUhGmDKhGgRoDOhEAGAEIgCIYMCBhABoSEUcGICKQNKODEBFARRBieDE4RQDEQZT+DKAygRpCNYRqEaQjSEahGkGVCNYMpCNIRr4GhEGIhFMGJ4GlARRwimDE4RTwjSDK8I1/8GU///////BiIRTCKf//gxEGJ+EUVRMYDSRJhMAoAs3Ky6zGBBjMS5pQwJhdDA1B1MFkEcwdABjBrA+MloZAzMBrjAHAiAQNZWCMYCIDZh5j2mN+G2YdAkYMA8YPASYPg4LB+LAccan+ZEDgYmjKPA0YGA0IgNBgDEQMIBl2KJGS4ZmDwjBAeFYPSQeBhpBakwGAxpK7ACBqAUcAdpoOA9Ai0hdrZV3qMtISpaciQzB+30YG5a7IZEYDrtf5pLSEqGzP8/6HNQ5q4gAJqj9qmT1ch9YOdB9k9mCKgjTlOS5D8NUg1+aJ/F3QwX4UYUk05s1H8mbi//tmbdpa7H9aUlWu9pK7X8ae//PkZPIxNhcGFM90ADNT9jBdglgA05szTmlrTg5yHIg5yXKcuD1rwfB3//vk+L4vk+D4s69AitRyINgxTy1nJWrBqnblOU5Hwf/+tZafrXctylPLR9a7luS5bOnyfB83xZwzv2cPkzl8XwfJnLO2rf/tW9qntXar7V/9Uv+1T//2qf/tX9qzVPVM1Zq3tU9qjVmqqk//VM1f2qKnau1dq6pGre1dq/tU9q7VFSIKyxFlJOoIAcaADjggYw4OMCBAQGBD4Hpf1B3lpUsaGpubmpqPKhsPBsPJsobmhsampuoarqqm4PgPQbNjc1I+aDwarfmxooHgejUPRoaj+bNVamSaX1QPj4quHo2IpuaD+bZHIpuHrUNFR/Htcew8mhuB3H0SjtMTMdxgY+O/zFQjKmxqPA8j2Hk1I5sRiMP5qPw+mpuPhoqPOqbm6uuvqea/myqyn6mv6mbKDsMx3mRn+O0xMcyMh2ma6+uur/qf////+uqv////+ouqAAghaJRKskpqUqUmlSlSct7lhmTjSHdgBEZsxEpovlcmqEVwYUbVZr1gxmTMlSZ04chiSCyGSINIYp5wxhupXGBGJIZc5EhqjnDmP+GSAANDF8JfMSAWUw8grjBjDkMKMCIwYgIz//PkZGYtrgsoLs94AB5DYjALhVAACSDWMLoGosiYLgGhi1AnmC6CcYBYIAiALKwVDAJAI/zAyAC8dADMAsBMOAHEgF2yF9S/K7YHg5OWncpkD+goAdMlRF/E3I26nq2fQpiurQug6ElkipE2kzFTpmUDOlbvfCNxp8/+goKChZRB0CrvpoGXZStmdZW2ijb5UNFQRn6P6GNUUZ/2duu6lDG4x/0VFRxj3QfL40vyioqONUdF9HQUNBGaL6D6D38+TSX5O/kmfyTe/klf9kb/fQUH/GaKgooxGqGhdGgov/7lz79N///3bnqkf6TP/Jn8kz+SZ/5K//yR/JK/j/yf//43Q/QxiNfR0f0FBR0dHQRr//6D6H6H/o//6ONEkgQ6AXAMKgFD4cw/DwuHBdETi8XRFCI44IqLx2IsX+LsX5YvHpWVKlI7F4i8sWLFy8RUcF+PyhUfl+PR+UKD4uVLD8uU+O8cjovFwvHBcL4ig7l+VHuP+Of+WHkuPJWVLx8Wyg8y8ryuXL/y/8sPyg/K/lo9K//F9VBNCsrCzcvDesyXYS9MIdHGDCpQ2wwoIRYM1kNATJEBakxnAd+M/DC5jCHxDYxvgKDMIcAizCpAf0wEcEzMXKHfjD0xeoxi8TeM//PkZEormgsIBe/UAB4T+fwBzWgAZyIBTCHhWQwZYOPMFUBlzAiwREwGgCsMBoCgjAiwAUwO4DPA1buQMjEcDNCsA0WaANWM8Dd5oA3cBAMjiYDRYmAwIRwMCAQDNJHBgEAwIJwMCCYGAUDAoECIFhECgwCwBhYF1wbBwXXDDgwLg2DguthhgbBgNg0Lr4XXBsGhdcVkVQqxWIrAqhWRVisirishhgbB4XXwusGGC64YZHBsGBdbxVCsCr+Gr+Groqw1cKoVcNXxWOKzCIBDVorGKwGrOGrhWYq4rEVkVgVcNXCsBq+KwKrDV4q/xVCqxWRVRVxWBVis8VUVWKr/xVCsiq/EXxF8Rb//xFRFRFOKwKxFUKvxWQ1cKzw1bis4rGKoVkViGr/+BY4FsCzAN6EQEbAseBa+BZ8CwBbhEQiYRgjBGgWgLPAsgWfhHCIhEQjcIgIjhGCJwjhEQiIRvhGhEhEQj/gW///+BYwLf+Bb///gWPAt//4Fv//8C1FTivBOhWFbFSK0Vor4qxWFWKgreKuKwrCrFcVxU8VP/FU4aWvTBNJ6MhYK4wX0qDFRCQMKkHwzfzWDBHFcCyZhwrHOmr0IOYm4O5oAmBwKg5oa0Bv+PxleUZnlX5sevh4S//PkZEAo4gUQAHusPh67gfwAaBqAbRtmE5hyHJnYcBgSMpj6DRk4FoYlpqWOBgeGZg2ExgQKYJDgw/AkwJAAwtA4uQQAAQACgnTFTcU+zlfr5qfUQdN0HTV0v5fMZX7GKNDGwfI0SMOTETJGxmiMDIzMTEwE0TDMwQkKTIOTEwQzIxRI0YdB2iQjEwGwmGKGYmQcmBmhokNGhyYow+MTNCRyZCahyiRDeRMMg5RGRmhShIhuHImSYojIxlDlCQjJGHKEjQzFFJkiMjOUaNEZISGhASQ5RIZiYo5MUcoYcI0aEhoYdIaKZRog+MzEzMUZkhB0BNFJgjlCMEcozBHKEjkyM5QjFDQ0SJEjQ5QjNFMo0SNGiQkKZRmBjKPBoBpg1QaYa4Ewhqw1w0waoNMGsGrgC8DR/DRhpAmIEyDSBMA0gTCGnAmYEwDQGrAmYaw14ag1QagaQawaINX/g0cGsGn+DRwaYNGDXwacAXYNQNANX+DSDXg0A1YNfBp8Gvg0f8Gv/gC9/+DX//g0A0/4NPAF/g1/4NJgTk3ayNEhmMyBA7TFkYqMxcQQybyNDEkAzMa0yYy7hRDgUTpHAxDDUCjMY0gwwigGjBDIdMaQQ0wxRlTG8E1MZUaQxRAojIVD//PkZEko8gcKBXtvZiFDvgAAa9oAMMRUGIytbNrazMnsyICNL7Tm4I1MKMCIzExo1sTMKWg53MKEjEhoQhapgSBgolDgVUr+joFJZMme1boaSYkoZIa5ZklJMmhSzRFLFI6ZTKbTBoEnJASdpXl8kKGNAaxaoYvdf6GNJIuvNC+voYh7QhyGHwcTU1nG7azhVjW1O2tWftTW6X0MaOhqGIc0tC9+0tPaEMQ5DehqGFp+hiGIY0r3XmhfX/+h68vIehyHdDV/8ki8voc0ryHof19DkNQ1f/Q3tP6Gr///6Hr6+v9D+vL6+0If//0MQz//r36+09Dmhp6HdeaOmE100m0z/00m02mzRTBofpvprplMGmmoREbQOfwicI+EeKoqwiIR+FowjBGwicIjhHCN4RH4qQTnFcVxVgnAriqK/FWK4JzFfFUVME5FaERCP8I+EfiuKniqK2CdCtFeKgqCrxVFQVBVFQVsVMVxX+CcCoK8I0In/hHCNwjf8VcVYrip4qivFaK2K4qRXFWKkV8In///4Rwjf/8IijLjh6E0doS8MWpB/DCHRBQw9MQVMNtCpDAigmEwM4MrMOPCpDGkwysw/IR6MCLARzDTAsUw2wAnMMrDbCwBFmBFAZxgRYZW//PkZEcqLgb+AH+NbB67GgAAatvAYDQEfmEOioZgmQKoYGcBWmR9waLEx1RFmzqobuVhzJFGz0WYnExotFmrBOZGI5idFGBRMYmIxgUjGBAKWAKYnEybCBRafy03gULlpC0xaQtMmwmz6BRWFy0pYBaKqnKKiKynKK5WClGvU5UaU5U59RpRpFZFdTlThTlRtFYC1AtgWALHAsAWgLHgWAToVQAgisKkE5BOxXACBFWKwJ0CdirFYIwBvBHCJgG7CMAbsI4Bu4RPCIAN8A3wjhEQiAiAiAiYRIRwjQDdCJwjBEwiAj+EbCIhGhH4R/4RwiYRARwiIRARHCOERgWQLXAt/wLECz+Ba4FjgWsC0BbhEBGCJhGwjwj8Ij/hHhEfBqg1fgIQacR0R4LVg1/Bpg1cAn4ag1hphrDXAmUNAaAJhw1QJkGmGoNWGmBMsNAExw0Bqhrw1hr/g0f4PYAfhYLg9g+FwfAB8Lg+FsCYBoDWGnhpDRgTCGqGmGsNIaw0w14aMNWGjw0w1BqDRAmMNeGgNX//gE3//BrqM5N0IrR/LAZxg3g3FYw5g3A3mBuJgVgbmESEQYN5UJjDB9mH0DcYG4RBiYgbGG6BuZtEnumxm5sV7pm5uVmxWbGjCpig//PkZEUgWf8OAHttSCB7PgAAatuAqWEYxUUMVRjHAEsDhYHSwAGAgJYAIPU4g6DFVHIg8RoRoZxmGYFJHWJSPYXCwtHoPYewvFuWlUsEoLB7j0yoslRbKyotlRUVj0HqL49C0epYPcsLZUWj1HtHsVlhVj2HqWyvK5WVFUeo9iyPYslhUWFcsLY9sqlhYJWPbLB78rlUrLJUVFZWWlkrLCse5UWx6FQ9C0qKpVyoslpaW49eWeIzGbx1HQZ//8Z/xmjMVSsqyyWSyPcs49yotKisq4FvhHCPgWfwiQjhEeBZwLUC1AtBEfwjhG/FwXwtIWsB5C1C4LsVQTmKwrgnQrgnGKw4Kw7hwBABIOhwVYCAqCt4qipFeK+Kv4qYr4rCvBOBVFYE7iqKkVRUBOfFfFSCcCr4qirBOxXxXwTvFfFcVBXxVBO8E78I/+Ef/wiP8I//AtUJAEPU/EPBa5MCB7M7zINOxVMLgJNFCjMejJMe0UM7lhMyAvMozJMCTIMCDvLAXGURkGZIqGBCKGig9mF49mPQqmFwEmvXGJEmuqla4xIgxC81wnzECDEiSwIVgGgiqqqisMHQdB8HOQ5cGIqoqfGcdRmhGiMBHCJGcA3AjjoI0CkgpYRhnGcdRGhm//PkZIsgugcIGXdNZiBTpggIaptsBSB0jNjOIwOg6DqOo6iMjMIyM3HQZ4jIzjrEeJEFqxHCPgtMSHiOBahHDpjOM0dRmEZx0HUZxGRnHQZuMw6xmEYEbHXGeM+IxHWOuMwjERsRqOgkIEyhrw0w0/4aOGkNP//BauI/4kPEd8SER/xmx0iMf8Z8ZxnxG8RmAqYr4J2KsVorAnfirFYV/BOBXxV4uC5C0BavFUVRXxXFcVQTqK8E5gneAXw4DHDgMgxALhwGQYDodDoc+BSD8PcCiHgFOHgfAUQ/gF/w4DMAvDgdBkOB0AuK/FYVoJyK/8VhUFb/iuK+KgqfFfxVxVirFf//FfxW//FT/+K///xXTEFNRTMuMTAwVVVVVVVVVVVVNl9MMrdMMaQFMiiLMJyLMrBGNdRGMJwmMBSKNdIdMJwmMaBHNEBHMJzvMRyLNGiiwjHWEx58WZOjGTo5gpMYICFgFKwQycnMmRywLFpwMWFpC0ibAcBiAAasqVUypGqpIPkzl8fSOfNnC13Kg6DFpwfBjlwY+LOWdM6fBnPvm+b5vkOg6CMiMg6YzDOOgjQjUdIqCtFf4qirFYVBWHUdIOgHSI0IyI2I2DpGcRqIwMw6iNDqOg6DoIyIxGcR//PkZL0gegEGAHdtTiE7nfgABFpYkRgRsdcRvHQdYzxGvxehaMX8XYWuFphaovC4LmLkVIqioK3xVxVFbip/ivipxW4Jx8Vv8VhV/FTxc4u8Xxe4ui/Fzi/F0XRF/CNC64XXBsH+DIEZww2DYPhhgjP4RoRgjBEwDcBOoJ0KkE6BOATsVuEeETAN4A3QDeCIgWYAHf4FiK0VATkVwTsVATkVBUipBOeEcIkIiAboREI4RgjcI4RPCNhHwDcwj/CI4RARgiP/////////ivipFaKwqirFX+KkVRXFb8VhXgnaTEFNRTMuMTAwqqqqMuf1w9h2UTH8FUMAQO8wigRjDOCKMREO4wrAzjF1KlM00dsxdQrTAECLMTMAQwigrDDPFVMRACcwzwRzBGDuMVUTMwJgzjDPBGLANJhFBFGAICMYAgNJgTgTGCMFaYRYE5gjAjmAKCMYEwApYAmLAApzimLP5iTlgQ5hCwIYopiT+ViFgQsCFgQxRTFFKxDEELApWKWBCwIViGKIWBfMQT/MQTzFFMUUrn9Fb/CFEVkVAoWZZSnKjaKvoqJsoFFpP8tMmymx/+gWmz6BSbEIwDkA5QZAjQO2DIB2gdoMn4HKDJCNCN+B24RoMsIwDtwOwGTB//PkZPMmegr4AHsxiiLLHegAnGdQkhGQZQjfCNgywZYRoRmDL8GTwjOEZwjeEbCMA7eDKEbCNgy4HYByeEZ/BlwZfCNwjfCM/+DJCMwjYMoRgMv/wjP4Rf/8I6wjvxFBFAErCKhFxFfg2DQbB4qgHhDVwRCDAhq4NXAYY4RoHZgyBGgyAcnA7AO0GUGWEZBkhGAyAcoMgMgMkDlgcoRgRoMsDtwjcGXBkCNBkBk/A7AjQjQZeEbBkCMgy+EXhF2EX8Iv8IuCL8GP4M3///4R1hEvCJPgwv+DCBEsIk/CJIM1TBVCaJhRBnRiaGH6GKeIpmpKRjSmakNGpRh4qkeLilgbNSUjGxosKRYjSxGFhTMaUzFhcDmIEMDFhYycFMFJiwClYIYKChUeMKCkVTCgoKBanACqxFQuEAVQBFhcKDYPC64Ng4LrhdcGwaGHBsHBhoXWwusF1wbBgYeIpC4XhcIItBlCKgyguFBlCLBcOIvC4aIuIpFVDVgrIqxVRWRVhqwVQqg1cKuGrRFwuHBlxFAuEEXiLhcPC4eIqIsIoFwoXCQ1eGrw1bFZFYisCqFXFZFZhqwVUVnFVw1cKwGrBVCrFYxWfFZFZDVoqxWBWRWcVYrGIp4ivEWEVC4cRbxF//PkZP4mKgsCFXtyDiYrIfBAlSSioisRX8RTEXiLYisRb+IqIt4imItEW4iuIvxFBF4XCCLiLhcLEWiLxFOIvEVhcOIpiLxFYA4GihFAYgRWDECP4XWg2DgYkDRQZeCN7CKAxAYkGIGrw1aGrBVgPENXBGwjQioigigioi8IpCKeDYNhdfg2DwuuF18Lrg2D8LrBdeF1oigXCCLiKBcIDLEUhcNEUEWEUwusDYMDDQbB4YeGHC6/hdfhFcIp/wYnwYgMTgxPBiYMUIr/8Ir/gxQYsIqDF/CPf/wZ//+Ef8I+NljCMyRDdDE+JEMLwJEwvBEjAOETMewA8wZQvTDoBlMOgWsxEhEisLwwvQDiwAcYHYMpgyh0mB2DIYXgnxgdBemIkDIYHYSBgHgdmAcB0YB4MhgHAd+WAZCwcfZ59neZx5nHlYnlYpzif5YEQLNZctIWkPBdNnwKsVieYghYEMUQsC+VilgQxBSwKYohzimKKYovlYpYE8xBS0ibHlpQNaWnLTf/psIFJshFIRUGKDECKwYgMUIqEVwYgMUDVQYkIpBiBFIMUIoEUBieEVwivwioGqwYkGJwNUhFAikIqBqvgzwZ+DP4R8I/4R7wZ8I9Bngzgj/Bn4H/gzgP+CPc//PkZP8mqgD2AHsyeiZEEewijKKgGeDO4R+DOA/8GfhHwjwR/8GdwP/BngzsGdwZ3Bnf/4RUIqEUhFMGIBosDRQYoMT4MUGKDEhFYBgyQjAOQGXCMwZeDKDKDJBnQZwMsGWEZ4HYEaIrEVC4cRULhQuFgyQZIMv/CM/CMBl4HaDJhG8IwDk/BkCMwZQZOEZA7QZYMkIzBlBkCMgywjQOUI3gyAy4RvwjQjAjcIzBlCNgyhGAyBGcIzCNBk+EaEaEZwO3//gygyfCNhGcDt/4Rv/wjPwjAjP//CNwZf/8GXBkgywjajhjHPMlEBcxZg/zMoXMYko2aMTWQxMLH8xiMTGFNMLBcsGQ1mZDC4WMYhcz+ME2AIMAKZSsYFpysYAQLmFgsVhZAowsF02SsLgULJsoFlpgOqEWAVYLhMGUIsB3QXDhGguHC4WFwgavAcAqwiMNXishq0VQioXChcKFwkRYLh4iwMoRYRYRcRfEVC4YRQLhxFBFwuEhhww0MOF14YeF1oXXBsGBdYLrQuuFwwXCAyhFYXCCKCKwuFhcKIpEVEUEVC4URSEbEVhcOFwoXCCKYMsRb4i4isRSIsIuFwgigioimIvC4QRQReIrEVxFQuEEUhcMIqIoIsF1/wuv//PkZPsl0fz8AHuSDibTuewAnCXohhgutDDwwwYeF1vC634XXC6wXXDDhdeGGDD//DD4YfDDhhuF1sMN4XX/4YeGG4YfDDhdYGJwingYQwjEPIHkBgMIpwiEGB4MRhFPBiQYnA0ohFMGJ/BicIgCIAYEDCAGBCIcIgCyOHm4eUPMHlDy4efCyELIQsgCyCHmCyIPPBgPhEIMADAAwAMAEQBEARDhFEGJgxP4MT4MRgwgYQYBFhF/BjwiQYAaQMAigYgx8GHwigYQMANMGGDCDGEThF/wYgxBjwYf///////wZARmcmBthkBmd0CUYTITBg/gYmBiAuWAFzALAeLABSjYFAXLAGAEAxMAoAssAFBUAorAXLSJspSAYGBAtNgOABDgAg4ANUqpwZYi4HVhcIAmoiwi4XCCKiKgKuFwgasDVwatAcIrAatDV8VgVkVQauisBq2A0EGCGrhWRVgOEVkVQqhWRWA1YKwKxDV4qw1fiscVgVYavFZxVxWA1cKoNXBq0VkNWCqFZFWKwGrw1eKzFUKwGrorAauisRWYasDVsNWCqhqwVmGrxVcVQasBgCrDVgrMVUVQ3hvQ4YoCN0b43xuigMbsbo3BvCgo3Rv434rIrEVXFV/hq7FZFYis//PkZPwkwgkEFa9IACnL7ewBUpAAiqisxWBWPFVis/8NXhq+KyKxDVmKxw1dFY8ViKz4q4rP/hq3FYFYFVirBkwZGDI4MADAYMkGTCIgYABiIGAhEAYMGRBkBGIRGEQBgAYDwYARAIiEQhEYRADEYREGABgIMn8GQDI4REDAYRHgwMIiBiIMAGDAwGBiIGI4Rn4Mjgyf+ERwiIREIhBgQYPwiIGAcGD+DAhEYRAGDBgBEf/Bk//+DJ4RngyP//wZGEZw8weT4eTDyh5oefw82HkCyEPOHmw8uHnh5Q80GDBgfwYH8GBVACAwFYYBAYQAMCAAPFZTBJw7Ax3whWNoVJmjGpQf8OAFwUANmNSBohkK4kSYkQIOmpLlORYAAg4AUMEUDUjCRgHoxPUJqMakLtxICwv/50DP1GnoTUVgnGJO/WcKy5plsGiFm12NmL8GRmPaY1IspiQhBmJAGMYp4kBhXCQGHmGMYVweYkAugQXeWSL8mDUBUmYCgJBCAWCgBzCuCDBgCINAnKwVDAnAQdBJKifJ1V/umkev9f7oK4EIBYcAOWAEiwAGyNDd0vo43R/GGXwP9xdisCANsjZi/QCAVXaIgCy/Vykk1y98UuXWTyVU7J3/f9U7J1SCEAJk//PkZPkxOhUePs/4ACnkBiwziVgAyplSMjZE1R/H//70kpKa/JPuX5MyT2QP5JGTv4/jJ/kr/qmTIarJ2RP7JZKyKSySS/9FRf9B/0VHG///////f+Tyb/k7+SZ/5O2Vs3/67WzNm9sjZ2y+2VdxZL//////////////5PJH8ZIXLVO/7JJLJ/k3//v4/km//AIBRfVdq7WyNkbL7ZGz/7Z//2yNkAmECEAQPci6aN7kKNyXe5EDS2urq/m5ooPyi+aKm+aB7H1Rb/UUNDZY2UNwHI5NzcPqii2bKraxqrmo9B6Hojmw/rLLLq65qvmi6+ZmNlEuLSggFNY1U1lF9RY3VVU1FDbH4fh5WWNR8UV9ZU3WV/W1TdRX1NRZfUzQeTRXUzdVRZdc0W///11TXzb83W1PU1NdbVzf1v/9b//NvW9fX1P/1v/1PXU1lT0/MfMy50U+MPVCUTDhgtEyP0bcMQjDHjSFwekwwQnMM0jT6jO2g6Ex18HOMPVHrTDoAc8wMoQJMI2DhzAFkCs0F4sdMpOPDzNPQYEwMsB+MUkASTEIgh0wRkFMMCYA/zASgjcwjYFMMFnEigOkinwNaCAwMphMwMjAfgMmQZAMTA/gMZpMgMf4ZAMGI5AMJQFg//PkZJIxJgcKAO/YABsbeewB0pAABhlADGaAxZhKBgZQMMoMABQyAYFwLAYFgLA2DwBgWgYFgLgwCwNg+AMC8LrA2DYAoFwBgXAYMQLAYFwLBhwutDDg2DQbBoXWg2DQbBoNg4GwbBsHBdcMOF1gw4YYGwaDYNDDBhguuGG4XWhdYNYDYNC6wNg2DYOC64Ng4MMGHBsGg2DYNg0LrBhguuDYO8GwbhdeIuIvC4URQRcLhguGiKiLBcLEUiKCLBcN/EWfEXEWiK4iwXDxFMRWIuFwwioi3hdbDDQw3+F14YbDD+F18MPhcNiKCKCL4iwioXC+Fw3EX/EW/EXFV8VfisfxWQ1cKwKsViKsVf4R6DOhFANFA0WEUgzgZ4H3Az/wPuhh4Ng/8I9wZ8I/+DP/gxYRWBqmEU8GfwZ8I9gf/hH/4R6DOhHwj2BomDFBiQiuEVwNVhFfBi/wYvCKQYvwYvwj////+DF4MXhFOBqn/8Ipwj3//wZ2DOWJwq9aHVShgYCYSRjinXmceI4ZTxQ5nbEGGIIF6IC/jz6g9Mt8z4zJyhgUPwZSwKRhFgJmkwE2Zf4DZiyF7GYMSaY1p05nzCWmGICGdtDZpsBmUuqYLJRhJmmgnaYjJZgNFmUwmY7Z//PkZGctIgsQAXuPaBvDwgS0bFvkhgNBGmzEYDGZiIJmGwUIQmPAQwmAg4amCg2yYOAg8BGTP4/jJn8VMm3JWTlgBqlaoGUSIskNJGWjQWhI/0M68hwY7T2gs18TZD0N/XmlDyyQxeaEPaSyJAhqHdoX14kgmhJEPE3Q9D0PJP+vLxJV/800wmDRTYniZE/TRpdNieGmaHNA0E0mE0aSGLzQvEkQ5oaevocvIYvIc0NC+h7SvL6+hjSv9D0OJAv9DF79eJI0Ly90MaCQEhJGh5J0O/6+vIYvoeWSHoZ+hiGNC80dDGhoLJoaehxarzQhjQ0Ie0rzSh/7Sh6+m03xPDQTP/TSZNBMmmNtNJg0OmTQTSY/Tf6aBJDgYJwK4qRUitCICIwjwieEYInCPCOESEeEThGCP+ET+ETCJ/+AB8CwBZgWwLX/gWvxUxUFbFWKsVYBuhG//hEeDLgyYRvwjIRsGUGSEaDLBsHfBsH8MN/ww8MPwZP//hH/CN/////ip/+KsVhVQfEYg5uroaGPAHOYIJ8JnGjRGMyNGYJYEBj2lJmKKx6Y+6H5jCEVmK0SqYjZEJinFOmOEOaZCojRgqC3mCCRUY+wZAyVkYsgwpg1glHZFmYMKpiAVGVSoYr6//PkZFordg8OBHuPahyr+ggAa1Vc5r0gmFxAYMBhlQqhUbmIT+EFYxCDDBogMLAMwEDRkQmDQEiuqso2qqqsqoo0qqpw5asDlIrqqeqorAPAeTP7JX/f5kjJX8f9/jiamtXK8nPPt0fatdq5DyQlo0fryHIav9pQ1DF79NmgmAcwpSbE9G1+m/0wmzRNE0emf+aRpClGmaKbTBpGkaSbNJNpk0010zzRTXTKb/6aTSa/TPNI0v010waJpJkT1NJs0fzR//NE0U1+mjSNJMpo0RPUwmk30ymE2aIpPTSa6ZTSZTBpGkaPTSaTJpGkm02mUwaX/TXTXTP//XkOQ39Du0/r7SvoahrQvIcvLyHL680tDR0NQztIrxVFUE6irgnXFTivxWFeCditivFXiqK4qioK4rwTjFeKnxXFXxUFfxVFbF6L4ui5i5F+LguRV4r/gneCc8VxV/FbFbBOYqf/ivFSK4rcVP/FXxX//iqKnirxV/4q4rfwZ+DIc+DIc/BjwZ/Bngz4c/+HVQCbZRzM3S2N4t8Ex4xUTI+GJMvcTUxtRrTFjBGMbQn80ZFATXJCaMuMP8wow0DJaA/MZEZsxrRdDDGERMb4PUxfgvjDbAjMCIPUySQkTCGB1PHrTYi0//PkZFYpZgsKKnttah3TBfQAk+GA6yaN1IzIpo5F1MtPwEjlkjRkYzUiLB8ZoDmWmg0jDQcWRDA0y8ADgMsABgACHABgAAIRArIXwLAmkgzh8vZz4JBisBVMIQBUnmAgKp1Sqmau1QAIIqiviuCcAEwqCuKgqxfi4FqFwLUFo8XBfF8XoJ0CcAnYripFYVxUBOwTmCc4qirxei4FrF7F0XIuBaReFwXYvRf4ui+LwuxcC1i+Lgv8XcXwtIuC6FoF0XBfi7GYRiMwzDoOgzjqI18dYjYzcZ4zjqM+Oo6i5F6LwvRcC1C+LgueLvhasXsXRfi4L4u4q4rxUioKorioK2Korip+KkVoqCt/BkcIx4eTBg4RGDBCIYeYPMHlh5/Bk4MAGD8Ih+DACIAwQZPhGPhqSP/DUhqSPI8jh7j34anhECKDEGPgwwiYeX8PNDyB5A8sPL8IoMeEUGP4GPhFCLh5+HkDzB5A8gecPKHnCyOHnh5cPJ//BjCLgx/gY8IvCKoJrfyJ35fhjuCpjsbZgoIxiOOxWbRlShhYNo0+pkx2EYwVBQwVBUrQwxHNsxGBUxGNox3HYyoBUypQw0NHYrBU4xQypUsFTKRjjxisCVujAADAASwBMABU7DBgYOMM//PkZF4hVg0SAXdPZB7qmgQAABoEHTFTETGN50O03T6V5xq4nKt7W7a2vnwvyzSoYqXilVD/z+eZ6pZ5UMfKh91f3X7tXtXa2trdNTvumo++rGvq906av2tXtXd+ed5NNO/lnklfyPZHk0sj6bzdrVjW6/av3Su///au1d0rP/3asdO1c7av+6/dNTp33XdNatdtX7t11c6a3Tpqaur3f/7prdtf/////dfq3+aWZ+98080nfTeR/NJNNI+f+bzyyz4RME4iv/CICPCJCPhEwjhEhHwDf+EaEfBOYq8VRXwToVhVFXisK4rC4LguQtWFqC0i4FpF+KuKwJ1FQVhVFYV4rivFXxXFWK0VhWFeK2KoqRdi4Loui8L8X8X4ui6LkLVhaRcC18XhfF8XYuC7xeF+Foi5C1i+L4ui/CIqGyyTLq2SvsDE4TjCNZTOQIzCIIytTywTHmySTmk4nGXYnGJ4nlguysujJlTysmDJkmTE9JysTjLsTvMIhj8xiCMwjCPywHgNCcHBEoygGBwRjIBjQCKcqNweiv7khQA3Kcj3J9y0waXTKZTYnqZTIZCHLy8hq9y0QxeQ1NdNGjzQFJTRpGl0x02aH5p9MJhMc0emkwmzRaevoc0ry+hyHr68//PkZKIfHfsOGXXnrCCLrgQQa1rcvf/tKGof/17tC915Duh3aWlfX17r//a1cb7r9r6ua3XVvVjW1/tbtq58OumMOiHAZ/DohAeA4PgODsB3iHxDiDiAQh+IfDw4PxBh4hh2DPwZwUgA8GQYIUV4q4q4J3itFQVoripFQVcVhUxXBOBUiv4rCuKkVYqirxXxUitFQVOCdxV4qYqCt4rirFYV+Koqip4rCoK8V8CzwLUCyBZ4FqBb4AH+K3xWFYVxU/+FpFwLUL0X4uhaoWoXuL3xd/FSK4qivxXirFTFX8VRW8VxWirxV4rf///8VjUubzOO6801Ly+DKJBSMW4acwGgUjHeGmMMUW4xNRbzE0MzMsEFMxpiUTKIAbMIwacxbiFzCMGnMFIFMx3g/TUvwxqMPEGjUowrjTGxs1PEMajDjFM2Q7MPDzDg4sHRnZ0VnZnbKYcdlgPMOD/LAcYcHgQXLSFpkCi06BRaX0Cy0ybJaX02UCkCkCysAau1dUrVFSKnauqb1TgwA1cKrCIBq4ViKsVkVjwutDDww/C64Ng4LrhdcGwaFw8LhIXCwuEEWC4YRYLh8RQLhAuHiKCKRFRFxFQuHC4cLhBFMRaIqIrAVcRXiKCL4YaF1gbB//C6//PkZPIlmfj+AHtyXCRr5fQAg2FM0GwZ4XW4XWDDhhoXWwutwbB3DD4XXDD4XXC63hh4XW4Ybww+F1v/4XX8Lr+DYNiLiLiKCKiK//iKRFw80PMHmh5eHn8IuEQDHgxhF4Mf4MAigwBhAxwYQYwBfg1A0A0wa4NANINANcGkGsGjg0ATINENENOGoNYag1QagaQaga8GiDSDUDVBqg1g1BEgxgxgx4RAiQYfw8wWQYeSHk4ecPMFkOFkAecPIHm8GP8GH//Bh4RcIoMf//+DH8Iv8InAx///DyB5g83/h5A81UxBTUVVVVUyd3nTecZ2M1ACwydgLDEGAtMQYQcxUAdTB0B0MVAVAyvxUDHjB0LAOhixfmLPGZ0X5wcWGvxYa+g51ComvhYa+Opiw6lg6lYsMWCwxYLSsWGxA0WA2WA2VhosBssBswUCggLIrhQFGHwUo0o0iupwEBZThTlFRTnxXBORVAJgEAAQYJwK4rAnAJ2CcirFQVhWBOxVFYE6BOBWFeKorgnEVgTnCIAN4IkInCICIAN2EYI0I0VIAA4qAnQrCqKwqxVBO4qwTsVBUFQInCMERAN8IgIgI4RMImAbwR4RARIRsIwREIiEcA34R8IwRPCI/gG78Cz8Cz/A//PkZPclrgcAAHuNPCVTWegAlGWotQAPcC3+BYwiAicIjANz8I0A3QiAiOEcI/COAbwRPivioKoJ0K4rCrisKoqQTkVhUFUVPiuKnCP4R4I+DPBnhHuEegxQigM4Gfgzgj4H/4M/wjwH/YR+DOhHwjwM7Bn4RXCKgxPBiBFYRQGJA1UGLwZ3gzgZ0I/hHgjwRgMgMoHLhGgckDlBkCMwZAZAZMI0DlCNCNCNCMBkgywZYHKDKDLwZQZAjQjQZYMoRsIz4RvCMCM/wZ//hHgjwR6Ee//hHvhH//8Gd/+EewZyNqRPU1zB/zNEJrMawFUwogLzAuAvME8E4sAnGMkCcYXQJ5jJhdGF0CeYRIRBgbgbGBuESYXYXZgnhdlYJxhdCTlYyXlgE440c48YrKnHKGVKg0iacgowDkBkCKAcrIFZFRkHIFE/UTQDlZFRNRJRhRMsEPTFKw6YgYMU+mMp9TynSnananSYinvU+mKp9Tr1OlPqeU7TGTGU/6nan1PKeTEUZUTQD+owgH9RL/BhFRP0AijHwaQBdg0A0waga4NQAvgC/BpBowasNIaQJgGoNYEyw1hrhpDXAmGBMsNcGoGmDXg0waMGkAXwaQawaQBcBqg1A1wawaAa+ATeAAN///PkZP8mkgb+AHtNbiWLmegAnKMYAAG8Am/AQ/wagaINEGqDUDV8Gjg0g0QaAaYNYNUGnhohohrAmQaQ0w0hrDXDQGqGnDT8NIaP+BlKDChEkIvwi+EdeEdAzXBm/+DFA0QD/uDOBn4XXDDhdcGwaDYMhhoYcLrBdcLrQbBgXWC64YYMPC68GLBiAaKEVhFQioRSEVwj/CP/hHoR8GfgzoR/wj+EfCPgz/BlA7MGTBkCNCNgycGQI0GUDkA5AjfgyBG/wZYRvCNwjAZQjAZAZf/////CM8I0IyB2/wZP/4MlTEFNRTMuMTAwCfNageETueooMYYiUgWYLjIZfhYWAtMvx0MoChK1fMoSgLApmKYNGKYNFigLCAdCgmWuhXfGWFpupaVspYDvKw8w4OMnJzJyYrBTJybywTFY8o2o0o0VhaKynKK/hAqiuiuFQtThRtTlFT0V/UaRU9RotMgWgUWlTY9ApApNlNhAsA34RABuAG8Ef4RwiQiYRwiQjAG+EQAbgRgDfCIgG4ESEcIgA3oRARARARARHCJhHCMERCPCOAbsIjCMESEcA3oRIRoBuBEgG+AbsIiERhE4BugG+AbwRGEThHwj+Ab4RsIkI8IiAboRgiOET4BvgG/4RwjQ//PkZPYlagr+EHdtTiWjBeQApOR8jwiAiYRwiIRGEYIkIwBvYREI/CJ4REI4ROEbhEYBufCNhGCJhE4RwieEYIgIgI8IkI3CJhH/gyDga1aDFoMdCLsIuhHUGa4M1/BhQMpQYUDIQGFAyECJAMhOBlIESAZSgZS/Bm8I64R/hH8GfBnQjwM7hHgP+CPcI/gz/wZ/CPBFQYgRUGIDFBiBFAigMQDVMIpgaIBokIqDEBiAaLBieDFgaKEUCK4MXgaoEV8GfCPAzsI+Ee4R7CPfgz4H/cI/hHwj/8I/4M7hH4R5TEFNRTMuMTAwVVVVVRrAf1zYbqeIZ3BeYAh2Ydh0YAgAY9gQYEBcViqY9lGViqYXj0YEheVgQYXioYXheYXBeY9D35j0KphcKhYAkwOjBcMEAwQDBBDLwuOp5MUxxlOkAyjKAVRPywggFU+GXBhoWHCw6YqngsMomDolGVEkAyiZWiokgHU69TpMf0xysZMRMRTyY/piJiJieVjqd+Fh0xywMp9MaGmBMg1w1gTMNMNGGqBMg0BoDWGgNIaoaoEww1Bq4ExDUGkCYYEyAmeGmGiGsNeGngTCGiGnAmQaw1eGgNIacNQaQ1hpw0BohrgC4DRBoBrg0A0g0cGiDQDQ//PkZPIkhgsAGHctbCZrKegAliTADT4NGAL4NQNMGj8GiDTBr4NP8GqDTBp4NHg1w0/DSGrDXhqDTDSBM/DSGkNIaw1hoDXBnYH3/4R+DPgzwjwR8Gf9NhAtNgsWBncI8DPCKwYuDFwivA1UIqEV4M6EewP+BigxQYsDVAigGqwYsDVMIqEVBiQikDVANUBigxOEe//BnQNEBi4MUDRAYsDVIRUIoBosIoBqgGqhFcDRIGq4MQGLCKAxANVCKQYkDVAigMTBiBHsI//wZ/gz8Gdwj3gz/gzwZ3//wZ4R74M5QA1gDXRdDoOYTKxdSwB5YJAw7DoxGEYwFCcxHAUxHGgyLCYxpCYwmEYxoEcxHGgwFEYwFCYwECcwmAQxoAQrCYwmAVRsI8KywhY3ywhRFcKFBUosF+WOz7OM/srOKzywcZ5xYEK5isUsCFYhWIYgpiCIF+gWWkQKLSemwWnLTpsJslpy0oGsLTAawtOWkTZ//UbU49FRFVRpRv1GlG1OFGlGghRRtTj1OFOFOVG1OFOVGvUbCIhGCNCOEQESEQAb4R8IgA3AjhEBE4RoRGESEeERwiIRGEQEYI/wLMC0BY/8C2BbAt+BYwjhGCMEfAN6EQEaAbkA3wjBEAG9CJCJ//PkZP8lfgj+eHctbiei9fAgjiL0AN0IgImEYI2ET8ADngW4FjAswLP8C38CzgWQLUA3PhG8I4BuYR+EeEfwDdCML8DlwjIMnhhww0LrhhvBkoFps+myWmQLLCkVQiyjajSKyjSjSnKnHorKceo36bCbPps+gWWmQKQK9Nn///TZLSlp/UaRURVCKorKNoqKc+iso0iuF1ww0LrBdaF18MPC6/gycI2DJgygdoMkDtwZQZfDDA2DAw0MNwuuF1oYeDYOwbB8MMF1//wjfwZeDJ8LrfDDcLrww8MOF1ww/DDKNIqWQyniuTEzGaN+sywynZZpzBiaULgWyLAsbKYnmCxpYsYuyGlixWygQWAzEYu/AbIK0ozEXAxeBRYDFybIGlQO8CWQLQKAtwJc1+9ThRpTlFRRpTlFcIupwo2o2FVIr+mwgWmwgUB3lpSxZAv02ECi0ybCbKBRaRApNhNhNlNktOWk9NlApApNlAvy0voFJspsIFemwgV6bPlp02U2C06bKbKBZaUtOmz6bKbP+mz/psoF+gUmx6bCjaK6K6nCK6jaKqK3qNIq+pypwVqRVUa9TlFZRtTlTj/LSFp//0C02U2f//LS/6bP+gX/psIFoFoFegV6bHps/6bJaX02//PkZP8odgD6AHt4DCXrafQAk+GEfQK9Ar0Cv/0C0Ck2S03+mx/+Wm//8tN6BSbPpspsemz/+gV////6bH//+mz/pspsf/+mx6BSBfoF/6Bfpsf6bHps/6bH/CM//wiAGA+HkCyDE0hisMU4mgMn/AxGDA4RH4eeHlh5A84eQVv/DuAzis4rA7g7hWCtHuGqI8ew9yPHsR49g1QanhqA1IagewMYRMGP4MYRQYYROBhCJwYf/BiEUPNCyMPPCyMLIQ84ecLIQ8sPIHkh5IWRB5A8sPOFkEPOHnBj/+EUIv/wicGPh5oWRB5g8/w8+Hl4eSo10sfjwgsENRQ/cwoAQDFeCgLA3pjeB/mK+FAYII3pjeDeGK+H8YUIIJXQGg/xWgmg/5/9AaB/mq4h/mKamNf5oKCWP80GhNBQPLBaVuvmWFpWWFgtK3Q3Ut83UtK3UywtN0dCwWeWC0rLPO+LTLS0xpS8sDZWNmNDRWNlgbMbGjG1IGLMDWrQitCKwIrQYsBiwDWrQNasA1iyDFkDWrQitA1q0DWLIR6gaxYEVkDgwQZBA4MADgQQZACMEGQOEYEGQIMgAcCADFoRWAaxYBrVgH1WcIrIRWgxaBrFgMWQithFYBrVoGsWhFaDFgMW//PkZO4vggDoAHt0PiQzhegAjiboAxZCKwDWLANYtBi0IrYRWQisBizhFaBrVuEVkDWLYMWwNYtCK0IrIMW4RWgxbwYt4RWYRWgxZwYt+DFgRWQYswNYthFbBiwGLQNatgxbBi3Bi2EVgRh/BkHBkHhGDgyBCMAGQcIweDIEIwQZBCMAIwIMgYMWQYsCK0IrIGsWQYswYsBiwGLeBrFgRW8GLf/gcmB2QjYHLCMhGQjYRqK6nJWrwqoIuo2pyo2iqFFBFUVPCKeo0isioVrU4hEn4RLCJQiT4MIESAwgMLBhAiSDCQiQDIXCJAYXwZvCO/8Il4RKESwYUGEwYWESgwoRLgwn///BmvgZC4MLCJAYXCJAiXwMhIRLCJP////COuEd+ESBEv8IlBhf8IkhEsIlBhINDNkKwOIo1ExDwbjBvAyMG4FowCwqz3HzFiiwKCRpnzxWKCosKxzFsiwKMULKzxiowQXCMxWLRWCjMKiis+iu1QOgGQAFYD1TlakVkVAosIqa1oqlpy0oEsWkLTFi6bKbJ/UWFhVanKKgRUrUo2isFV+iupwiqFVqNqNor+ir6bP+WlQKLSIFJsFp0Ck2E2UV1OVGlOUVlOVOFOFOUVEVPU5/1G/U5U4Ciwoo//PkZKwsEgj6FHtYHCSjNghUAtpgIuiupx6KyKiKinCjXorKNqNKcqcKcKNorf6K/qNKNepwpwir/qchVaK6jfqNqcepyo0isispx6nKnKnKKynCnCnCnPqNKNIq//qN+o2o16jfqN+o16nH+iqpx6jfqcIqf/+o16jSjajfqc+px6nCjX/6jSjf+o0isir6nKjaK6jSnCjajQUX6nPqNf6janHqNqc+px6jbVFS/7Vmr/7VWqtWLAWqeqVU//7VPasqZq3tWao1YI5UkDFYCfi6FphG8A3wjBEBHgG7FTxUAN4A3QDfCJCOEThGgG+EaEYA3AifgnWKwqCoK8V+KoripFX+ETCJCP4RwjhHxmHURsRodR1EaGcRiIwOvEaEaHWCcCuK4qCuCdCoCc4qCvFYVcVBU4r/iqKorwToE5FUVYrCrxV+L2LuLni5haxeF/F3i9F7F0Xxc/hHMOg7w0hAmzBfFUNeXxCnnNCBl5+Z9NmfgBl4gVkJp68aefqlEIgWBExABMQAQ5cDl0wEhEAiWAEwAQEAAYAAiAQUQFAcVBjHgYuUzotRNgFYtQFQBXLItAAGAoAAEswRxZibAP4CiWhZgAAsyyAU+AqFmWpaCaAKID8A/CagKJZCbAjh//PkZIQrHgz6AHtvDiVrcgBKa9skNRNC1E1AVwFEtQFD8tBNxNCyAUOJuWpaiaCacteJqCPLIsyzE2BHloWQmgI/8sxNCzE1LIBRLITXloJry1LQtCy5ZflkJuWhaloJqWYCuJpyyLMsxNy0E05a8tC0E2E05ZCbFmJsWRZlpxNC1E04m4CqWhactCy5ZFp+Ao8suA/iaiaFoJsJsJoWYD8JoWZZfgKwmhZgjuJuWhZlly15Ziaflry1LIsv/y1E05aln+WhaFl+WhZlqWvLItC15Zcsi1LMsvy1LIsizLItSy/LTlqWpZFoI2Ef4FoIgImKorioKmLwvwtYR8ImFqF4XhcF+ERCOETCJjYByjbByDaG0NoHMWhaFqJsJqWgmwCtwjAG7hGCJCN8I+EQEcImERCMERhG/wj+ETCJhE4R+Ab2ERwjeERCJ4RwiIR+ETCNCJCICIAN4I8IwBvBEAG4EQEfCIAN3COEYIjCJwjYFr///hGhEf/hG4RH/4R6MyEw68lDOC5FlgCRWKBMWK5gYPFgbioeBQ+FgaYTA5ckrA5YCZckwmB0kEjS5ZchJFnL4FgDPkmJBiYi11qOQ+aRjOmcem0kctGDYMLmOWp0tH+fRO+Ts+OAsnwfPPs+//PkZGAncgsAAHHrriiDWfwgbhrCg7T5PsnROz6JyTknJOidBKidE4J2fZ8k6DtPknISc+T6J0fR9n0fR9n0Tk+vz7AWOfZ8H2TgnR8hrHyfROQkxOj6CVH2fPJwff5OufZ98nIax9n0fJOD7Ps+efR8n0fROOTo+D4Po+efZ9n0Tg+j7PgnR9E65OPydH0Tvk4J2fR8H3z4Pk+CcHwTonfPs+idk6PonBOidnyHZycc+D659H2AmAkKxWKwEQ6Kw6Kw7isOAIhzFYc8OgICoBH8OfhwVBwVCoVgJB0OhwVBzATw5hzDnhzw6HRWKsOB1HgG6ET4RgDdFWCdRUBOoFoCxK1KchRajSnAqRVFeKoROEQEcI+CKFoC0C4LwD2FqwToVBUFQV4qRVFeCdCoKwqCqCcAnQRgifhHhH4q4rgnQqxXgnArioCdgnAJ2KgJyKmK0E7ACAKoqgneKkVRVir8I8I+ESEcA3fCJCJgG9wDcwiOER/CJCICPCPwicI+ERwj/8I8IiEcI/+EfhEeEf8Imjd8PjuQmzE8jTE8ADC4TjCAPjE4EA4AzBAERAAJjaCJgCCAeCqcQ/KIptJJFiAsAtVauXKFBiscUGSSasqUsAmii1dUqY61YPWkXOWq//PkZE0jagj8AHctPitLogggao+w5HptpIs4fJnYKOZyqYsAFYCpWrNVVKqVq4qiqCdAnQqitFYAI4rAnUAIEE4BOwTjBO4J0KkE4BORUFYVYJ3FeCcxUBOcVsVYrQTsVATsVBVBOgCcVATkVBUwTkVgTrFcVwTkE5BOhVFcE48VxVFcE4isCc4qCoKoqCpFbFbFQE7FTxVFcE5gnYriuKkVhXgnQqCoKgrirFTiuK0VxUFcE6itFUE7BOxWFaKuKsE68VME6FfiuKkVhUFYE4iqKmCccVIqRX8V4reKgJ34rxX9F6L2FoxfF2LkXhcF2KorxWxUBORWhagHeLgWoXhGR0GcdBmEbHWOsZh1jMM4ui/F+LwvhaMXsLQLovC7F0XBnjrGcdBGxGRGB1B24MQCodh0OgzALgyAWDodgzDuAVgxDodDgBUGIMAF+AVgFocAKgyHODAMB0Av+HPAK4MwYDkGA58O8GQZh2AVBiDGHIM/gz4M/4cBnBvBkFAZBWADgoDAbgpBXg3BoAEFAZUEVoHHdqGdIfmH5VGCAnmLwfGJwfmCAImCIQmCIAGgAaKAggEAAf+1bytAwARAA1YOBK0EViwUELBC4UKKwfDgg4IOiLACjSKiK6jaKynK//PkZE8g5gr+dHctLid0Dgjoa9r0KwVKCF1GkVQqV5lFqNgBAFaCcCuCcwTgBACdgnME4BOBXFYVBUiqL4vC+FpF+FqC0i4Lgui+LwqRWBOhVFeK4J3BOYJ0KkVIqCoKgqRW4J0K3iuKgq8VoqiqKnivFYVBXFUVYqipitxUioKviqKsVOKorgncVxWgnMVRUFf+KuK4qfioKorYrYqcV8VRVitioCdivFaK0VcE5FfFaK/haRexcF4XxcFyFqF0XxcF2Lgvi9i9F2L2LwMOo/8VouhaBeFSKgJyCcCuKuLsXzQGOaHTHE3E0LQsgFUTUtUwaXTRpJk0k2aCZTf/NA00wJt+WvLUTYTXlmJoaX6bTBpjFTJomhzTTIuxeF8XhchaYvxeF/4WsLWLsX8XxfF4LR8Xxdi/4ui+L8LSLgWvC1YWsXxc/wTjip/FQVhW4rf+Kviv/iqKkVP//8VOKv/8V8X8XPi7//i6MsSTP6ySMOhYMEBUMmQmUYMOhZMHBZMdhZMHAAMAQdMAAAMHA6MHRZMHAdMEARBoIIBywDhYAArAErB0sB2VgCYAAD5g4DphAYQFgJhCVhPoCsJWEscMISsJWArCgGUYQCg8IMgokoz5Y6VgKwGABgAWAmAJ//PkZHUhSgT0AHcQfC8b+fzAa9rUYD6iajCjKiSiX/6if/6iSjKiaiaAVRNRn1EgeNAL6AYrj6jCjCjCjKjCiSARAOgEUT9RNALwYBEBgETgwgYwYYRQYhEgwhE4RPBiDDAxBgBpwYYMYMeBrgwgaQiQihEBiEUIgRANIMeESET/8GHwiQigYgxwYQigYwYeETwYwi8GPwYwiYMODD/CKETCJhE8IgRQigxFtwiMIjAA+BZAswiQiQiYRoFrPonHPgnPG2DkG0NnjY4OcbfGwDkE0LMTUsy1LMsuWvE2LUtC1LQTUsxNi15ZFmJsWnE3LQTYVBWiuCcgnAJ2KuK4qiqAbn4R4Rgj4RgjAG6KwrRXFSKorCsKgqiuKsVQTjFSK0VuK3ioK/xU8VBWirxXBOBVFXiqKnisKwrCvisK0VoJxwTsVIr4J2Kwr/ipFYE5FYE78ImET4RP/wjcI3hH8VcVv/+Kwq05JIM6ND0yDFQxUD0w8FUwRBAwnBEwQCZRJRgHBGDAmBwmlgJzBEEQuY73DGNmbIWRL8qdhYyYpWdMf1GEAiAX0Ayn0xisyngudMdT6AVAMokgEUSUSUYQDoBVGEAqjKjKiX//qdep0VnU9/qdqdJigTCGkCZ4aA1h//PkZHkfYfz4AHcNTjHTbfgAa9qcrDXAmAEy4EzhpDQGsNENAag0w1ATMNIaw04ag0BpDUGsNfDXAmOGgCY8CZgTICZATENMNMNeGgNYaPwagBdBp4NH8GgGrBq8GoGkGuDV+DQDTgC7/BpwaQagBdg14aoaYag1w1hrhrhq4aeGjDQGjhohohoDQGkGsGoGr/BpBq/waf/hEhagHYFqGyNsHOTk+efZ8H0HafASQ+Scc+D5PkJVydn2To+yck5Ps+ick4PknROwkx9Brn0HafR8nyAsHwTgnROj4JyTo+Cd8ncXhcFwXgHYCKFqFwLTFwXoR4RoR4BugG+EYIkA3QjQjBHCPCOETgG/wDcgG74RoRgiIRARABvgG/CPwj/CICICJhHhHwiMI0I0IkIkA3vhEwjBHCJhH8IwRwjhGCJCJCPhEAG/4R4RHwjwjYRIRIRwiIRGEQERhGhH/CIVFlAxMxzjSLB/AwzZacwSgSwKAuYGICxaRAowSgSgMBeBAFzXwLSmssYsxWIYsybCbBWsBVy0wFWTZAixaQrKChRWUFCvRWChQUKRXUbRWMspRr/TYQLTYQLTZQKQKLTFpEC0CkCy0iBSbOFwgi+IsIsIuIsFw4XCiLAJoRWFw4iw//PkZIEdnfz2ZHsyPjUz9fwga9sGigigigi/C6wXXwusF1+GG8GwcFw8LhoXDiLCKYivC4TiL+F1gw3/8LrQw2F18LrBh/+GHC634YYMNxF4i8RfxFRFOFwoi4inhcPxFRFcRYRQMP4XWDD/4Ng74XWDDQw4YfC68MN/hdb//wusEV4risKmKmK4qCsCcioKsVxUxWBDi4FpFwLSK+K2WRZFqWQmxZiaAjxNAR4mhaCblkJoKwqwTsE7gncVovhaQQwWji6L8VhVxXwTkVorRUC1C+L4WgLQL8EMLovxdxfC0xUFWCcQTsE6BOhVxVFWCcCqCdirFQVQTgVIripFeK4qYqCtFYE7FTBOuK0VwTvFeK0VsVoqRXioKoJwKorCsKoqiriuKgrip8VwTv+KgrCtFWCdYJ2K+CcRUFYVgTgV+KmKwr8VxU4rCv4Jx8V8VOKvisKiMTcPo0QQqjBbBbCCwVFhBcxQsz7IsCixGRXMUeRUCh8Kig5AVgCsCYECYEgqZqyKijaKoVForNWVIqZUqpPFQVorRUFUB4haQtcLRC0QiYRMI8A3AiAjhEhEBEBEYREA3oqAnQrCrFQE7iuCdYrwjhG+EYIiEYIkI8IgIwBvQjwjQjhHCIhGgG94//PkZIoYvgL4AHtNDjVj9fwga9rcRPhEwiQDcCNCPhEfCN8IiEf4RHhEAG8EbhEf/hHhEcI34RMIgIjhEhEBEBEf///CI+ERCP//wif/CICOQV4rgnOCdioK4qCtisKwqCqKgDzhaScHyfZOj6JwEq4a5OA1j7Pk+w7D4/JwfR9E6Ps+OfASg+Sdk7J1z7Pk+ydcnJOCck4PonB8k6CUHzw7D4PonB9BKOfHJxxNS1E15alkWhZCbcTUsyzE0LL8VBWBOcVoJ2KwrCvFQVhWBOoq8VsVQTqKorRXwToE6FbisCdAnAJyK4qRUFYV8VxVBORWFTFTBO+KwJyCdCqKorRVipwToVeKwrxVxWxXFeKgq4qeKgrYrcVvFfir4rRX/ip//ioKlSIGPk2H54xcEQ4AGIQiYQEIRXwiphgqUwAKwlgHlgIgAqVNt8Wcly022cpHf6pVStXVK1X3KgxaynblrRg+LguRcF4LUL4risCdAnIJyK8VMLWLkLV8Xovxci8LwWrF/i4LsX4uha4uQtXF8ZhGRGxGI6DoMwzjOOgz4jQzjOI0Mwufi/wtUXovYuRfFwXYWni6L2LwWoX8XvF0Xhci9F0VRUiqK8V8VoqgnWKn/////xUitisKn//F//PkZLkXtfz8VHMNHjub+fAAxJuMf/ir4rFpU2PQKLSIFemz6nCK5YWgV6BSnKnCjXoFf6pmrqlDgFYHzSTSNURSNfJnPpHs5Z2XLSQasIANVKwqkVK1X0VvUb9ThFYsLU4RX9qocBUzVGrqlEIPaq1YRcRfEVC4QRcRULh4XDxFhFhFBF/iLxFhFoXCiLRFIi8ReIqIqIriLhcIFwsRYRcRbgywuEhcKIqIuIuIvEXiKfC4XgWOBaAsf/At8CwBbAsAWAAPwLUC3gWQLAAHALUCwBYwLXgWIFjwLcC2AB74FoC1gWQLXgWfwLYFgC3gWMC0BawLQFjwiAiQjfCICMERCMEYInCJTEFNPsFk+yWDDpYMdhww4WTLABMAD5wwAPvPPgSsJ8CWAmEJWEwA8whLATCBAKWIAyAPGomokgHUZQDKJqJKfU+FzqfKzf+ATAIQEHgC8ALgNYAvQagaAagaQauDXAFwGqDRBrwaMGsGvg0A0g0wa+DQDXg1QBdBr4kILWI6C1gtAjoLSJERwLWI8SAkQWiDXwaf/8Gr8BD/gE3//g0eDV8GrwBd/waINPAQ///4CD/gE8Gv+DV4NQNINQeoALUTUtBNvy1E2/LItQR5ZCbDZByg5ODlByDb//PkZNUXBfLyAHMNHjoj+fzQfBtAE1E0E14mxalkJuJvy0AUuAoFmJuWomp8k6Po+CdHwfQSuEUBpBjCKKyKzF0LSL4vBawtQugO0XYWgLWCGC1C4A7ouC9C0Rc4rCtFUVxVFQE4FSCcCsKwqhaBcBFFwB6FwXwtEXRfF8XYvBaAtPFYV4qwTgVhUisKgq8VcV/BO8E4itFcE6FeKoJz4rCr4qCqKwriqKoqivFUVBXiqKoqQTjFUV8E6FXFTiuCdioKkVPFYVcE7FX4qfFeK8VYrip4J2Kwr+KvFfFXioK6NFrERD438BoyKYinOKdEQqRTnoQiKWIpiwiKWERTRFimOKdEUrREBkRQZEWDGiBHUgG0XUoRaIE2iAbRWigxosGNEwi0UGNEA2itEgxooMaKDGiBFPwRT+EU/QNP6fgNP6fgin/A2iNFwi0XBjRQi0XBjRQY0UGNFeEU/BFP+DE/4MT8DE/wNP6f//wi0ThFouEWieDGifgw8oRPIDDygw8gRPKDDyAw8mBnlPJwieX/4VEThOIvCMRP/7f/gxP/CKfm/wi0T+EWi4RaJ/CLRcGNFgxovhFon8ItEBjRYMaKEWif///+DGihiKkhAL6jHoBFGCwVK43+oyokgHQD//PkZP8dLea8AH/WBEKb5fGg09tMIB/UYUSKxBiRBiRJWIOOUMoVK4xlSplCqjKjCAdRj/TFDB4YOTFTHTEU7THU+GDkxkxAwcp349w1X4asjyOI7h3h3cVv4d3DuFaKwDKKwVodwdwGUVod4d4GcO8O8O7h3AZQ7uK0VnAyh3B3AZg7uKwO8GjBpAF7Bqg1g0A0A0A0A0g0A0waAagaQaMAXwagagaQaQaQaAagBeBog0g0cAXAaININeDVg0QaAaga8GvAF/Bo4NANOALgAuQaAaoNANINcGkGsGjBpBr/BpBqBqBqg0Qa+DXBp+DQDSDRg1g1A1A0QBeBowaf/BoBoBp4NXBrwaJMQU1FMy4xMDARjNpnwmmZbBYQFjDxHMZgtTkrWa1BVQUUE+CqwipX9FVRr1OVG1GgivCMEYA3QicIgIkC0BYAA6BawLARMIgA3IRARwjhH8I4RARuERhEhGhG/wjBEQj4Rgj8IgIj4RsIkI/wiYREIgIwRIRgjcI+EbCOEcIwRIRABuAG/+AbnhGipFcVIJ2CdAnEVorcVIrYqxV4RHCNwjQj8I3/wiQjeEf4RIRIBvhE/hEBEcIiESEYIgIj/+Ef/CNwjQiIRvCOdEVBVBOIripipxXB//PkZM0YHgrwEHMNGDYD9fwoa9qwOQTvLQsy1LRNGgMY0zTJ2AtnyAtHyTsNc+QkwC2Tk+j5E2E0LPgP5aibCaC+LsX8LSA7cVRXACOKwqAIYqCuCdxWFaKuKwJyKgqCuK4J1BO4rCuCdiuKgJ3FTFXxXivFQV4rivgncVRXFcVRVFUVYrivFSKgrcVfFUVxVitxVFcVhViqK+K0VhXiqCd+K0VuKuK/4qgnOCcCsK8VwTkE4FUVOK0X4vC5FyFpC1i+FowtMXIuBaIWoXYvhaYWiLoWoXQtfxUir8V/FTipNrUmXz5ng703qyKGMO8DvDHlQ7wx5UO8K+9K+8K+88+870+97wGO9hF3mDHeWBi28IraA1tra/hF3gGi1FmDEWwiiz4RRaDEW/4MNOBmnNNCJpoMNPhE0+ETThE00IotwYiz+EUWf/+EVtQYiyDEWwiizwii3/4MRbCKLAiiwIotBiLQiizCKLYRRZ4RRZwii34RRZgxFsGIt/8IotCKLYMRb4RW0EVtf4RW3/hFbX///Bi2/8GLb8IrbgxbcGLahFbf/4GttbVIAz8GdwZ8GKEVBihFYMWBqgRQrbK2its2mzOOM44sdlfZWcYgpWJ5WIYs5iihCwQoisFSlG/C//PkZP8Y/ei6AH+2EkJMAeRAlmS8FkCvLCyBSbCBRaUtKo0o2EKqcoqoqlh5RpFUtN/+gWmwWmTY8tIBr02U2E2C0qbKBRaRNktL/laxabCKhFAioGqAaqBqgRUDRAigMWDFBiAaLgxIMQIoDFwNUA1SDFhFeDFwZ0I/CPgzwjwR4GdBn8I9gzoM/BiQivA1SDFA1QIp8IoDECKQisGLBihFODE8IpwYgMXCK/CKAaJBigxQNE/gzuDOBncI8DO/hHsI9CPfBngzgusGHDD4NgyDYNC60LrhdYGwcF1guuGGC6/hhoXXBrOdcnmZLpkgUJC0se95b9dhtSkeliNjm2V7Xt/1ox54AUASYePwUk8z/zwApgTR4YpGE4nf+eeQa9//Qg3ISiXjw7YmUCaz+PiJVjP5Aj1k7Mx+fzPikqKcMvzOPXR7P7/3RR/FOgDtiGyXBnPlgHDKP4ghcI8A8olDtea/9Dt0eL9+johBjteHbo2jWvf5PYz7oHB4x74gH6hTIdt7opXo2/odsceqhsnigTWHpPGJqHHNRBU16HaZhsnts2TUPV+/O7Z8mYesTVKIIcLw+zxfnsPTzaJ2UkQhQ/kqe0eAjqoSr0bs0crqOXJNJtJGUtGgadEgmYaG//PkZPkc2gruAG1PXj/sHgAAe9d8FyLiW7ml0ymjS6aTaYLlff6YTRpJlMP0UmVKXFLHoI6W5AGmlTRoX1+aCWTaaSJ2GmlkimuaSRSplLJcaUXNEgl4Yyj6/5pfKSPNaypkUaZcSNHfHS5fU1AVSRNA00gW4uKbSr9Uvy+pRU36VMpPHLAVV4apNFSiLHOaWBHo6W0mkzc0EmaKqie5o0p6JFMbSyQTPpHNFKJZMHmhiDTCVv6UTaYTJo3SSDSuFVTRpe6aS1OaN7pdDJ0cpS4phBppdP7pJM01/7ltumktTSZS1HiqWk0lkB5PvEYXj6PTxDHEIDyB7e8gj9f/vEY5SkxBTUUzLjEwMKqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqoYDIhMQASaQdeKXjWIKCoKqxo1WNV121JtdSacUnoZoUtj5e///7cRFnoYIk2Vp///7cVYbH1NkiLIyVZoq4VLtRjSI6OgkCpGOtfxrf5KsExVhFe9NyIqgJgqdPBo6JREPgZB4wTSVZWehhnis2SljRDNDCUpkpEjf7QnDQVQBpImVQpGiFATLbH1uSvUJZGZIk3IsRTJVm2cksnB6FZdh6y5kVFzKK6SehUNIVHxmhIi46Fk//PkZLUXwgriIGRpHjCj8eQASZKRYpGmEUlXIk3SIl2HkpZuLIhGB4KkAmBTF1/LXOAwpNFq84dh1z6RJmRCQA0CJQnPIirwqQCYhg17krBqNahLJTg2hOGhSozKU0NbJXULJEfCpAGgVRkvWehSehVSXdtayslNkiXMopoZoWBUMmBMQnGBUXEoiPgiQBoibZl5KuRLTciKsEyroxlfjW5K4wRJuRT2SbkScGkKbJE2hgiXDIyYFSbNSVSg0qwiVhL3T0KTbpKpsrNkqzbPkrBpWCJNyqT0KTSrlgL+NoZaTEFNRTMuMTAwqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    ":)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
