## The HTML model can be simply divided into two parts:
**Token-Level Transformer and Sentence-Level Transformer.**

For the token-level transformer, there are several ways to load the pre-trained transformers and then encode your input texts: 1) [Bert-as-a-service](https://github.com/hanxiao/bert-as-service) 2)[Hugging Face Transformers](https://github.com/huggingface/transformers).

For the sentence-level transformer, we provide a customized lightweight transformer that can be easily adapt to either classification or regression problem.

Also, we provide the lightweight single-task regression code.

