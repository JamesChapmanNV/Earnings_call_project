{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256c016d-3a52-4525-b92f-d9eafcb7899f",
   "metadata": {},
   "source": [
    "# Earnings Call Project: emotion2vec\n",
    "<br>\n",
    "CIS 831 Deep Learning – Term Project<br>\n",
    "Kansas State University\n",
    "<br><br>\n",
    "James Chapman<br>\n",
    "John Woods<br>\n",
    "Nathan Diehl<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afe45e-603e-4403-b191-ecd36af94ef7",
   "metadata": {},
   "source": [
    "### This notebook featurizes the AUDIO data from the earnings calls with emotion2vec.\n",
    "\n",
    "emotion2vec documentation can be found at https://github.com/ddlBoJack/emotion2vec\n",
    "and\n",
    "https://huggingface.co/emotion2vec\n",
    "\n",
    "The data from this notebook is stored in the \"data/data_prep\" directory as the following CSVs.\n",
    "\n",
    "* emotion2vec\n",
    "* MAEC_emotion2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88d0789-36df-4250-90e7-1485c0dc9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5822f8a-897e-4fd5-b77b-1c38e8d7ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAEC_dir = 'data/MAEC/MAEC_Dataset' # https://github.com/Earnings-Call-Dataset/MAEC-A-Multimodal-Aligned-Earnings-Conference-Call-Dataset-for-Financial-Risk-Prediction\n",
    "\n",
    "############# too big for GitHub ########################\n",
    "############# stored on local disk ######################\n",
    "original_data_dir = r\"D:\\original_dataset\" # https://github.com/GeminiLn/EarningsCall_Dataset \n",
    "MAEC_audio_dir = r\"D:\\MAEC_audio\" \n",
    "# there is a link for the audio data in the MAEC GitHub, but it does not work\n",
    "# I emailed the authors, and they send another link.\n",
    "# There is like a half-million files, but only 19 GB\n",
    "# https://drive.google.com/file/d/1m1GRCHgKn9Vz9IFMC_SpCog6uP3-gFgY/view?usp=drive_link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7908bf-5a46-4a22-b959-acc40ce09ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the directory, each folder represents an earnings conference call; the folders are named as \"CompanyName_Date\".\n",
    "filename_data = []\n",
    "for filename in os.listdir(original_data_dir):\n",
    "    company_name, date_str = filename.rsplit('_', 1)\n",
    "    date_str = date_str.split('.')[0] \n",
    "    date = datetime.strptime(date_str, \"%Y%m%d\").strftime(\"%Y-%m-%d\")\n",
    "    filename_data.append([company_name, date])\n",
    "filename_data = pd.DataFrame(filename_data, columns=[\"Company\", \"Date\"])\n",
    "company_ticker = pd.read_csv('data/data_prep/company_ticker.csv')\n",
    "filename_data = filename_data.merge(company_ticker, on=\"Company\", how=\"left\")\n",
    "\n",
    "# Loop through the directory, each folder represents an earnings conference call; the folders are named as \"Date_CompanyName\".\n",
    "MAEC_filename_data = []\n",
    "for filename in os.listdir(MAEC_dir):\n",
    "    date_str, ticker = filename.rsplit('_', 1)\n",
    "    date_str = date_str.split('.')[0] \n",
    "    date = datetime.strptime(date_str, \"%Y%m%d\").strftime(\"%Y-%m-%d\")\n",
    "    MAEC_filename_data.append([ticker, date])\n",
    "MAEC_filename_data = pd.DataFrame(MAEC_filename_data, columns=[\"Ticker\", \"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537ab9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: C:\\Users\\James\\.cache\\modelscope\\hub\\iic/emotion2vec_plus_large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 20:31:37,750 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect model requirements, begin to install it: C:\\Users\\James\\.cache\\modelscope\\hub\\iic\\emotion2vec_plus_large\\requirements.txt\n",
      "install model requirements successfully\n",
      "ckpt: C:\\Users\\James\\.cache\\modelscope\\hub\\iic\\emotion2vec_plus_large\\model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\James\\anaconda3\\envs\\transformers\\lib\\site-packages\\funasr\\train_utils\\load_pretrained_model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  src_state = torch.load(path, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init param, map: modality_encoders.AUDIO.extra_tokens from d2v_model.modality_encoders.AUDIO.extra_tokens in ckpt\n",
      "init param, map: modality_encoders.AUDIO.alibi_scale from d2v_model.modality_encoders.AUDIO.alibi_scale in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.1.weight from d2v_model.modality_encoders.AUDIO.project_features.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.1.bias from d2v_model.modality_encoders.AUDIO.project_features.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.2.weight from d2v_model.modality_encoders.AUDIO.project_features.2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.2.bias from d2v_model.modality_encoders.AUDIO.project_features.2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.1.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.1.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.2.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.2.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.3.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.3.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.4.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.4.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.5.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.5.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.norm.weight from d2v_model.modality_encoders.AUDIO.context_encoder.norm.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.norm.bias from d2v_model.modality_encoders.AUDIO.context_encoder.norm.bias in ckpt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.0.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.0.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.1.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.1.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.2.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.2.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.3.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.3.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.weight, mapped: modality_encoders.AUDIO.decoder.proj.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.bias, mapped: modality_encoders.AUDIO.decoder.proj.bias\n",
      "init param, map: blocks.0.norm1.weight from d2v_model.blocks.0.norm1.weight in ckpt\n",
      "init param, map: blocks.0.norm1.bias from d2v_model.blocks.0.norm1.bias in ckpt\n",
      "init param, map: blocks.0.attn.qkv.weight from d2v_model.blocks.0.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.0.attn.qkv.bias from d2v_model.blocks.0.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.0.attn.proj.weight from d2v_model.blocks.0.attn.proj.weight in ckpt\n",
      "init param, map: blocks.0.attn.proj.bias from d2v_model.blocks.0.attn.proj.bias in ckpt\n",
      "init param, map: blocks.0.norm2.weight from d2v_model.blocks.0.norm2.weight in ckpt\n",
      "init param, map: blocks.0.norm2.bias from d2v_model.blocks.0.norm2.bias in ckpt\n",
      "init param, map: blocks.0.mlp.fc1.weight from d2v_model.blocks.0.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.0.mlp.fc1.bias from d2v_model.blocks.0.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.0.mlp.fc2.weight from d2v_model.blocks.0.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.0.mlp.fc2.bias from d2v_model.blocks.0.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.1.norm1.weight from d2v_model.blocks.1.norm1.weight in ckpt\n",
      "init param, map: blocks.1.norm1.bias from d2v_model.blocks.1.norm1.bias in ckpt\n",
      "init param, map: blocks.1.attn.qkv.weight from d2v_model.blocks.1.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.1.attn.qkv.bias from d2v_model.blocks.1.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.1.attn.proj.weight from d2v_model.blocks.1.attn.proj.weight in ckpt\n",
      "init param, map: blocks.1.attn.proj.bias from d2v_model.blocks.1.attn.proj.bias in ckpt\n",
      "init param, map: blocks.1.norm2.weight from d2v_model.blocks.1.norm2.weight in ckpt\n",
      "init param, map: blocks.1.norm2.bias from d2v_model.blocks.1.norm2.bias in ckpt\n",
      "init param, map: blocks.1.mlp.fc1.weight from d2v_model.blocks.1.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.1.mlp.fc1.bias from d2v_model.blocks.1.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.1.mlp.fc2.weight from d2v_model.blocks.1.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.1.mlp.fc2.bias from d2v_model.blocks.1.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.2.norm1.weight from d2v_model.blocks.2.norm1.weight in ckpt\n",
      "init param, map: blocks.2.norm1.bias from d2v_model.blocks.2.norm1.bias in ckpt\n",
      "init param, map: blocks.2.attn.qkv.weight from d2v_model.blocks.2.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.2.attn.qkv.bias from d2v_model.blocks.2.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.2.attn.proj.weight from d2v_model.blocks.2.attn.proj.weight in ckpt\n",
      "init param, map: blocks.2.attn.proj.bias from d2v_model.blocks.2.attn.proj.bias in ckpt\n",
      "init param, map: blocks.2.norm2.weight from d2v_model.blocks.2.norm2.weight in ckpt\n",
      "init param, map: blocks.2.norm2.bias from d2v_model.blocks.2.norm2.bias in ckpt\n",
      "init param, map: blocks.2.mlp.fc1.weight from d2v_model.blocks.2.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.2.mlp.fc1.bias from d2v_model.blocks.2.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.2.mlp.fc2.weight from d2v_model.blocks.2.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.2.mlp.fc2.bias from d2v_model.blocks.2.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.3.norm1.weight from d2v_model.blocks.3.norm1.weight in ckpt\n",
      "init param, map: blocks.3.norm1.bias from d2v_model.blocks.3.norm1.bias in ckpt\n",
      "init param, map: blocks.3.attn.qkv.weight from d2v_model.blocks.3.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.3.attn.qkv.bias from d2v_model.blocks.3.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.3.attn.proj.weight from d2v_model.blocks.3.attn.proj.weight in ckpt\n",
      "init param, map: blocks.3.attn.proj.bias from d2v_model.blocks.3.attn.proj.bias in ckpt\n",
      "init param, map: blocks.3.norm2.weight from d2v_model.blocks.3.norm2.weight in ckpt\n",
      "init param, map: blocks.3.norm2.bias from d2v_model.blocks.3.norm2.bias in ckpt\n",
      "init param, map: blocks.3.mlp.fc1.weight from d2v_model.blocks.3.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.3.mlp.fc1.bias from d2v_model.blocks.3.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.3.mlp.fc2.weight from d2v_model.blocks.3.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.3.mlp.fc2.bias from d2v_model.blocks.3.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.4.norm1.weight from d2v_model.blocks.4.norm1.weight in ckpt\n",
      "init param, map: blocks.4.norm1.bias from d2v_model.blocks.4.norm1.bias in ckpt\n",
      "init param, map: blocks.4.attn.qkv.weight from d2v_model.blocks.4.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.4.attn.qkv.bias from d2v_model.blocks.4.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.4.attn.proj.weight from d2v_model.blocks.4.attn.proj.weight in ckpt\n",
      "init param, map: blocks.4.attn.proj.bias from d2v_model.blocks.4.attn.proj.bias in ckpt\n",
      "init param, map: blocks.4.norm2.weight from d2v_model.blocks.4.norm2.weight in ckpt\n",
      "init param, map: blocks.4.norm2.bias from d2v_model.blocks.4.norm2.bias in ckpt\n",
      "init param, map: blocks.4.mlp.fc1.weight from d2v_model.blocks.4.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.4.mlp.fc1.bias from d2v_model.blocks.4.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.4.mlp.fc2.weight from d2v_model.blocks.4.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.4.mlp.fc2.bias from d2v_model.blocks.4.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.5.norm1.weight from d2v_model.blocks.5.norm1.weight in ckpt\n",
      "init param, map: blocks.5.norm1.bias from d2v_model.blocks.5.norm1.bias in ckpt\n",
      "init param, map: blocks.5.attn.qkv.weight from d2v_model.blocks.5.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.5.attn.qkv.bias from d2v_model.blocks.5.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.5.attn.proj.weight from d2v_model.blocks.5.attn.proj.weight in ckpt\n",
      "init param, map: blocks.5.attn.proj.bias from d2v_model.blocks.5.attn.proj.bias in ckpt\n",
      "init param, map: blocks.5.norm2.weight from d2v_model.blocks.5.norm2.weight in ckpt\n",
      "init param, map: blocks.5.norm2.bias from d2v_model.blocks.5.norm2.bias in ckpt\n",
      "init param, map: blocks.5.mlp.fc1.weight from d2v_model.blocks.5.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.5.mlp.fc1.bias from d2v_model.blocks.5.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.5.mlp.fc2.weight from d2v_model.blocks.5.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.5.mlp.fc2.bias from d2v_model.blocks.5.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.6.norm1.weight from d2v_model.blocks.6.norm1.weight in ckpt\n",
      "init param, map: blocks.6.norm1.bias from d2v_model.blocks.6.norm1.bias in ckpt\n",
      "init param, map: blocks.6.attn.qkv.weight from d2v_model.blocks.6.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.6.attn.qkv.bias from d2v_model.blocks.6.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.6.attn.proj.weight from d2v_model.blocks.6.attn.proj.weight in ckpt\n",
      "init param, map: blocks.6.attn.proj.bias from d2v_model.blocks.6.attn.proj.bias in ckpt\n",
      "init param, map: blocks.6.norm2.weight from d2v_model.blocks.6.norm2.weight in ckpt\n",
      "init param, map: blocks.6.norm2.bias from d2v_model.blocks.6.norm2.bias in ckpt\n",
      "init param, map: blocks.6.mlp.fc1.weight from d2v_model.blocks.6.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.6.mlp.fc1.bias from d2v_model.blocks.6.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.6.mlp.fc2.weight from d2v_model.blocks.6.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.6.mlp.fc2.bias from d2v_model.blocks.6.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.7.norm1.weight from d2v_model.blocks.7.norm1.weight in ckpt\n",
      "init param, map: blocks.7.norm1.bias from d2v_model.blocks.7.norm1.bias in ckpt\n",
      "init param, map: blocks.7.attn.qkv.weight from d2v_model.blocks.7.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.7.attn.qkv.bias from d2v_model.blocks.7.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.7.attn.proj.weight from d2v_model.blocks.7.attn.proj.weight in ckpt\n",
      "init param, map: blocks.7.attn.proj.bias from d2v_model.blocks.7.attn.proj.bias in ckpt\n",
      "init param, map: blocks.7.norm2.weight from d2v_model.blocks.7.norm2.weight in ckpt\n",
      "init param, map: blocks.7.norm2.bias from d2v_model.blocks.7.norm2.bias in ckpt\n",
      "init param, map: blocks.7.mlp.fc1.weight from d2v_model.blocks.7.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.7.mlp.fc1.bias from d2v_model.blocks.7.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.7.mlp.fc2.weight from d2v_model.blocks.7.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.7.mlp.fc2.bias from d2v_model.blocks.7.mlp.fc2.bias in ckpt\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "\n",
    "model = AutoModel(model=\"iic/emotion2vec_plus_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b69b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.039: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.12it/s]                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'Nicholas C. Gangestad_1_1', 'labels': ['生气/angry', '厌恶/disgusted', '恐惧/fearful', '开心/happy', '中立/neutral', '其他/other', '难过/sad', '吃惊/surprised', '<unk>'], 'scores': [0.0008483638521283865, 0.003417916828766465, 0.011887827888131142, 0.37373086810112, 0.11250405758619308, 0.008385236375033855, 0.005126012023538351, 0.0004774830595124513, 0.4836222529411316], 'feats': array([-0.04042191, -0.20115899, -0.25954983, ..., -0.46292517,\n",
      "        0.8943518 ,  0.65777045], dtype=float32)}]\n",
      "['生气/angry', '厌恶/disgusted', '恐惧/fearful', '开心/happy', '中立/neutral', '其他/other', '难过/sad', '吃惊/surprised', '<unk>']\n",
      "[0.0008483638521283865, 0.003417916828766465, 0.011887827888131142, 0.37373086810112, 0.11250405758619308, 0.008385236375033855, 0.005126012023538351, 0.0004774830595124513, 0.4836222529411316]\n",
      "1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# example of using the model, and the output\n",
    "# I included the features in this one\n",
    "MP3_file = \"D:/original_dataset/3M Company_20170425/CEO/Nicholas C. Gangestad_1_1.mp3\"\n",
    "results = model.generate(MP3_file, output_dir=\"./outputs\", granularity=\"utterance\", extract_embedding=True)\n",
    "labels = results[0]['labels']\n",
    "scores = results[0]['scores']\n",
    "feats = results[0]['feats']\n",
    "\n",
    "print(results)\n",
    "print(labels)\n",
    "print(scores)\n",
    "print(len(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0843632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# the output of the model kept freezing my computer\n",
    "# each audio file seems to print out a progress bar\n",
    "\n",
    "# Suppress output temporarily\n",
    "class SuppressOutput:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        self._original_stderr = sys.stderr\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stderr.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        sys.stderr = self._original_stderr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e78692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:01<00:00,  1.31s/it]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0031992837321013212, 0.12995511293411255, 0.023297548294067383, 0.18970733880996704, 0.06439411640167236, 0.0025770298670977354, 0.23691841959953308, 0.03711989149451256, 0.3128312826156616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.005: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.64it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0016599190421402454, 0.05526705086231232, 0.012034779414534569, 0.6429855823516846, 0.04890550300478935, 0.0012000900460407138, 0.08021904528141022, 0.024633927270770073, 0.13309405744075775]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.005: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.65it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0009355830843560398, 0.05223856493830681, 0.01718318834900856, 0.6403264999389648, 0.03516412898898125, 0.0018440389540046453, 0.11748670786619186, 0.015552787110209465, 0.11926846951246262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.004: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 40.70it/s]                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0016990875592455268, 0.0038299134466797113, 0.008568341843783855, 0.12420917302370071, 0.24684593081474304, 0.002062635961920023, 0.016790788620710373, 0.0017812704900279641, 0.5942128896713257]\n",
      "[0.0018734683544607833, 0.060322660545352846, 0.015270964475348592, 0.3993071485310793, 0.0988274198025465, 0.0019209487072657794, 0.11285374034196138, 0.019771969091380015, 0.2898516748100519]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# I kept having a memory error\n",
    "# this splits up each audio file into sections at most 2 minutes\n",
    "# then averages the output factors\n",
    "from pydub import AudioSegment\n",
    "segment_length = 120000 # 2 minutes\n",
    "\n",
    "MP3_file = \"D:/MAEC_audio/20160802_CORT/CORT_20160802_f000023106.mp3\"\n",
    "audio = AudioSegment.from_file(MP3_file, format=\"mp3\")\n",
    "segments = [audio[i:i + segment_length] for i in range(0, len(audio), segment_length)]\n",
    "print(len(segments))\n",
    "\n",
    "all_scores = []\n",
    "for i, segment in enumerate(segments):\n",
    "    temp_file = f\"temp_segment_{i}.mp3\"\n",
    "    segment.export(temp_file, format=\"mp3\")  \n",
    "    results = model.generate(temp_file, output_dir=\"./outputs\", granularity=\"utterance\", extract_embedding=False)\n",
    "    print(results[0]['scores'])\n",
    "    all_scores.append(results[0]['scores'])\n",
    "\n",
    "scores = [sum(x) / len(all_scores) for x in zip(*all_scores)]\n",
    "print(scores)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af26f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns 9 floating-point values \n",
    "def get_emotion2vec(audio_dir,audio_file):\n",
    "    MP3_file = os.path.join(audio_dir,audio_file)\n",
    "    audio = AudioSegment.from_file(MP3_file, format=\"mp3\")\n",
    "    # split MP3 files into sections of 2 minutes\n",
    "    segments = [audio[i:i + segment_length] for i in range(0, len(audio), segment_length)]\n",
    "\n",
    "    all_scores = []\n",
    "    for i, segment in enumerate(segments):\n",
    "        temp_file = f\"temp_segment_{i}.mp3\"\n",
    "        segment.export(temp_file, format=\"mp3\")  \n",
    "        with SuppressOutput():\n",
    "            results = model.generate(temp_file, output_dir=\"./outputs\", granularity=\"utterance\", extract_embedding=False)\n",
    "        labels = results[0]['labels']\n",
    "        all_scores.append(results[0]['scores'])\n",
    "        torch.cuda.empty_cache() # I don't know if this helps\n",
    "    # average all of the sections into one factor of 9\n",
    "    scores = [sum(x) / len(all_scores) for x in zip(*all_scores)]\n",
    "    return labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11003cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89722 entries, 0 to 89721\n",
      "Data columns (total 22 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       89722 non-null  object\n",
      " 1   1       89722 non-null  object\n",
      " 2   2       89722 non-null  object\n",
      " 3   3       89722 non-null  object\n",
      " 4   4       89722 non-null  object\n",
      " 5   5       89722 non-null  object\n",
      " 6   6       89722 non-null  object\n",
      " 7   7       89722 non-null  object\n",
      " 8   8       89722 non-null  object\n",
      " 9   9       89722 non-null  object\n",
      " 10  10      89722 non-null  object\n",
      " 11  11      89722 non-null  object\n",
      " 12  12      89722 non-null  object\n",
      " 13  13      89722 non-null  object\n",
      " 14  14      89722 non-null  object\n",
      " 15  15      89722 non-null  object\n",
      " 16  16      89722 non-null  object\n",
      " 17  17      89722 non-null  object\n",
      " 18  18      89722 non-null  object\n",
      " 19  19      89722 non-null  object\n",
      " 20  20      89722 non-null  object\n",
      " 21  21      89722 non-null  object\n",
      "dtypes: object(22)\n",
      "memory usage: 15.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>...</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89701</td>\n",
       "      <td>...</td>\n",
       "      <td>86671</td>\n",
       "      <td>73635</td>\n",
       "      <td>89682</td>\n",
       "      <td>89693</td>\n",
       "      <td>89691</td>\n",
       "      <td>89684</td>\n",
       "      <td>280</td>\n",
       "      <td>127</td>\n",
       "      <td>522</td>\n",
       "      <td>70765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>生气/angry</td>\n",
       "      <td>厌恶/disgusted</td>\n",
       "      <td>恐惧/fearful</td>\n",
       "      <td>开心/happy</td>\n",
       "      <td>中立/neutral</td>\n",
       "      <td>其他/other</td>\n",
       "      <td>难过/sad</td>\n",
       "      <td>吃惊/surprised</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0.00011693405394908041</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4592916386391153e-06</td>\n",
       "      <td>0.04475519061088562</td>\n",
       "      <td>0.0005968250916339457</td>\n",
       "      <td>0.5674771070480347</td>\n",
       "      <td>Martin Marietta Materials</td>\n",
       "      <td>20170727</td>\n",
       "      <td>2</td>\n",
       "      <td>Craig W. Safian_1_50.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>839</td>\n",
       "      <td>2824</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1736</td>\n",
       "      <td>4123</td>\n",
       "      <td>571</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1           2         3           4         5   \\\n",
       "count      89722         89722       89722     89722       89722     89722   \n",
       "unique         1             1           1         1           1         1   \n",
       "top     生气/angry  厌恶/disgusted  恐惧/fearful  开心/happy  中立/neutral  其他/other   \n",
       "freq       89722         89722       89722     89722       89722     89722   \n",
       "\n",
       "            6             7      8                       9   ...     12  \\\n",
       "count    89722         89722  89722                   89722  ...  89722   \n",
       "unique       1             1      1                   89701  ...  86671   \n",
       "top     难过/sad  吃惊/surprised  <unk>  0.00011693405394908041  ...    1.0   \n",
       "freq     89722         89722  89722                       2  ...    839   \n",
       "\n",
       "           13                      14                   15  \\\n",
       "count   89722                   89722                89722   \n",
       "unique  73635                   89682                89693   \n",
       "top       1.0  1.4592916386391153e-06  0.04475519061088562   \n",
       "freq     2824                       2                    2   \n",
       "\n",
       "                           16                  17                         18  \\\n",
       "count                   89722               89722                      89722   \n",
       "unique                  89691               89684                        280   \n",
       "top     0.0005968250916339457  0.5674771070480347  Martin Marietta Materials   \n",
       "freq                        2                   2                       1736   \n",
       "\n",
       "              19     20                        21  \n",
       "count      89722  89722                     89722  \n",
       "unique       127    522                     70765  \n",
       "top     20170727      2  Craig W. Safian_1_50.mp3  \n",
       "freq        4123    571                         4  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bad_emotion2vec = [] # Company ,Date, i, audio_dir, audio_file, labels, scores, e\n",
    "\n",
    "emotion2vec = []\n",
    "for Company,Date in filename_data[['Company','Date']].values: # each audio file of the original data set\n",
    "    Date = Date.replace('-', '') \n",
    "    audio_dir = f\"D:/original_dataset/{Company}_{Date}/CEO\"\n",
    "    if os.path.exists(audio_dir):\n",
    "        for i, audio_file in enumerate(os.listdir(audio_dir), start= 1):\n",
    "            try:\n",
    "                # skip files that are not MP3 audio\n",
    "                if audio_file.lower().endswith('.mp3'):\n",
    "                    labels, scores = get_emotion2vec(audio_dir,audio_file)\n",
    "                    features_row = np.concatenate([labels, scores, [Company, Date, i, audio_file]])\n",
    "                    emotion2vec.append(features_row)\n",
    "            except KeyboardInterrupt: break\n",
    "            except Exception as e: \n",
    "                print(Company ,Date, i, audio_dir, audio_file, e)\n",
    "                bad_emotion2vec.append([Company ,Date, i, audio_dir, audio_file, labels, scores, e])\n",
    "                # set all features to  0.0 if there was an error\n",
    "                scores = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "                features_row = np.concatenate([labels, scores, [Company, Date, i, audio_file]])\n",
    "                emotion2vec.append(features_row)\n",
    "                   \n",
    "emotion2vec = pd.DataFrame(emotion2vec)\n",
    "emotion2vec.info(verbose=True)\n",
    "emotion2vec.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f50558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89722 entries, 0 to 89721\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   angry         89722 non-null  object\n",
      " 1   disgusted     89722 non-null  object\n",
      " 2   fearful       89722 non-null  object\n",
      " 3   happy         89722 non-null  object\n",
      " 4   neutral       89722 non-null  object\n",
      " 5   other         89722 non-null  object\n",
      " 6   sad           89722 non-null  object\n",
      " 7   surprised     89722 non-null  object\n",
      " 8   unk           89722 non-null  object\n",
      " 9   Company       89722 non-null  object\n",
      " 10  Date          89722 non-null  object\n",
      " 11  Sentence_num  89722 non-null  object\n",
      " 12  audio_file    89722 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 8.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>disgusted</th>\n",
       "      <th>fearful</th>\n",
       "      <th>happy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>other</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprised</th>\n",
       "      <th>unk</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sentence_num</th>\n",
       "      <th>audio_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "      <td>89722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>89701</td>\n",
       "      <td>89694</td>\n",
       "      <td>89683</td>\n",
       "      <td>86671</td>\n",
       "      <td>73635</td>\n",
       "      <td>89682</td>\n",
       "      <td>89693</td>\n",
       "      <td>89691</td>\n",
       "      <td>89684</td>\n",
       "      <td>280</td>\n",
       "      <td>127</td>\n",
       "      <td>522</td>\n",
       "      <td>70765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0.00011693405394908041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3212887754198164e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4592916386391153e-06</td>\n",
       "      <td>0.04475519061088562</td>\n",
       "      <td>0.0005968250916339457</td>\n",
       "      <td>0.5674771070480347</td>\n",
       "      <td>Martin Marietta Materials</td>\n",
       "      <td>20170727</td>\n",
       "      <td>2</td>\n",
       "      <td>Craig W. Safian_1_50.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>839</td>\n",
       "      <td>2824</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1736</td>\n",
       "      <td>4123</td>\n",
       "      <td>571</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         angry disgusted                 fearful  happy  \\\n",
       "count                    89722     89722                   89722  89722   \n",
       "unique                   89701     89694                   89683  86671   \n",
       "top     0.00011693405394908041       1.0  2.3212887754198164e-05    1.0   \n",
       "freq                         2         5                       2    839   \n",
       "\n",
       "       neutral                   other                  sad  \\\n",
       "count    89722                   89722                89722   \n",
       "unique   73635                   89682                89693   \n",
       "top        1.0  1.4592916386391153e-06  0.04475519061088562   \n",
       "freq      2824                       2                    2   \n",
       "\n",
       "                    surprised                 unk                    Company  \\\n",
       "count                   89722               89722                      89722   \n",
       "unique                  89691               89684                        280   \n",
       "top     0.0005968250916339457  0.5674771070480347  Martin Marietta Materials   \n",
       "freq                        2                   2                       1736   \n",
       "\n",
       "            Date Sentence_num                audio_file  \n",
       "count      89722        89722                     89722  \n",
       "unique       127          522                     70765  \n",
       "top     20170727            2  Craig W. Safian_1_50.mp3  \n",
       "freq        4123          571                         4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to make sure all the labels (the first 9 columns) are the same\n",
    "# then drop them\n",
    "for column in range(9):\n",
    "    print('Should be 1 ---', pd.unique(emotion2vec[column]).size)\n",
    "emotion2vec = emotion2vec.iloc[:, 9:]\n",
    "\n",
    "# rename columns\n",
    "emotion2vec.columns = ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'other', 'sad', 'surprised', 'unk', \n",
    "                       'Company', 'Date', 'Sentence_num', 'audio_file']\n",
    "emotion2vec = emotion2vec.drop(['audio_file'], axis=1)\n",
    "emotion2vec.info(verbose=True)\n",
    "### save ############################################\n",
    "emotion2vec.to_csv('data/data_prep/emotion2vec.csv', index=False)\n",
    "#####################################################\n",
    "emotion2vec.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8972cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ventas Inc',\n",
       "  '20171027',\n",
       "  113,\n",
       "  'D:/original_dataset/Ventas Inc_20171027/CEO',\n",
       "  'Robert Probst_1_8.mp3',\n",
       "  ['生气/angry',\n",
       "   '厌恶/disgusted',\n",
       "   '恐惧/fearful',\n",
       "   '开心/happy',\n",
       "   '中立/neutral',\n",
       "   '其他/other',\n",
       "   '难过/sad',\n",
       "   '吃惊/surprised',\n",
       "   '<unk>'],\n",
       "  [2.0749192117364146e-05,\n",
       "   0.0004140714299865067,\n",
       "   0.00028590569854713976,\n",
       "   0.0006683205137960613,\n",
       "   0.988251268863678,\n",
       "   3.425650220378884e-06,\n",
       "   0.009793120436370373,\n",
       "   0.0005107651231810451,\n",
       "   5.2451694500632584e-05],\n",
       "  RuntimeError('Failed to load audio: ffmpeg version 7.1-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\\r\\n  built with gcc 14.2.0 (Rev1, Built by MSYS2 project)\\r\\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\\r\\n  libavutil      59. 39.100 / 59. 39.100\\r\\n  libavcodec     61. 19.100 / 61. 19.100\\r\\n  libavformat    61.  7.100 / 61.  7.100\\r\\n  libavdevice    61.  3.100 / 61.  3.100\\r\\n  libavfilter    10.  4.100 / 10.  4.100\\r\\n  libswscale      8.  3.100 /  8.  3.100\\r\\n  libswresample   5.  3.100 /  5.  3.100\\r\\n  libpostproc    58.  3.100 / 58.  3.100\\r\\n[mp3 @ 0000029e5e494e40] Format mp3 detected only with low score of 1, misdetection possible!\\r\\n[mp3 @ 0000029e5e494e40] Failed to find two consecutive MPEG audio frames.\\r\\n[in#0 @ 0000029e5e494a40] Error opening input: Invalid data found when processing input\\r\\nError opening input file D:/original_dataset/Ventas Inc_20171027/CEO\\\\Robert Probst_1_8.mp3.\\r\\nError opening input files: Invalid data found when processing input\\r\\n')]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_emotion2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07cdb1d",
   "metadata": {},
   "source": [
    "# MAEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f283534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [50:48:42<00:00, 104.95s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 394204 entries, 0 to 394203\n",
      "Data columns (total 22 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   0       394204 non-null  object\n",
      " 1   1       394204 non-null  object\n",
      " 2   2       394204 non-null  object\n",
      " 3   3       394204 non-null  object\n",
      " 4   4       394204 non-null  object\n",
      " 5   5       394204 non-null  object\n",
      " 6   6       394204 non-null  object\n",
      " 7   7       394204 non-null  object\n",
      " 8   8       394204 non-null  object\n",
      " 9   9       394204 non-null  object\n",
      " 10  10      394204 non-null  object\n",
      " 11  11      394204 non-null  object\n",
      " 12  12      394204 non-null  object\n",
      " 13  13      394204 non-null  object\n",
      " 14  14      394204 non-null  object\n",
      " 15  15      394204 non-null  object\n",
      " 16  16      394204 non-null  object\n",
      " 17  17      394204 non-null  object\n",
      " 18  18      394204 non-null  object\n",
      " 19  19      394204 non-null  object\n",
      " 20  20      394204 non-null  object\n",
      " 21  21      394204 non-null  object\n",
      "dtypes: object(22)\n",
      "memory usage: 66.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>...</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204.00000</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>393785</td>\n",
       "      <td>...</td>\n",
       "      <td>386876</td>\n",
       "      <td>357989</td>\n",
       "      <td>393801</td>\n",
       "      <td>393403</td>\n",
       "      <td>393884</td>\n",
       "      <td>393601.00000</td>\n",
       "      <td>1213</td>\n",
       "      <td>488</td>\n",
       "      <td>983</td>\n",
       "      <td>394204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>生气/angry</td>\n",
       "      <td>厌恶/disgusted</td>\n",
       "      <td>恐惧/fearful</td>\n",
       "      <td>开心/happy</td>\n",
       "      <td>中立/neutral</td>\n",
       "      <td>其他/other</td>\n",
       "      <td>难过/sad</td>\n",
       "      <td>吃惊/surprised</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000192526844330132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75323</td>\n",
       "      <td>INCY</td>\n",
       "      <td>20160728</td>\n",
       "      <td>3</td>\n",
       "      <td>LMAT_20150225_f000002100.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1094</td>\n",
       "      <td>3072</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1772</td>\n",
       "      <td>8181</td>\n",
       "      <td>1738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1           2         3           4         5   \\\n",
       "count     394204        394204      394204    394204      394204    394204   \n",
       "unique         1             1           1         1           1         1   \n",
       "top     生气/angry  厌恶/disgusted  恐惧/fearful  开心/happy  中立/neutral  其他/other   \n",
       "freq      394204        394204      394204    394204      394204    394204   \n",
       "\n",
       "            6             7       8       9   ...      12      13  \\\n",
       "count   394204        394204  394204  394204  ...  394204  394204   \n",
       "unique       1             1       1  393785  ...  386876  357989   \n",
       "top     难过/sad  吃惊/surprised   <unk>     1.0  ...     1.0     1.0   \n",
       "freq    394204        394204  394204       9  ...    1094    3072   \n",
       "\n",
       "                          14      15      16            17      18        19  \\\n",
       "count                 394204  394204  394204  394204.00000  394204    394204   \n",
       "unique                393801  393403  393884  393601.00000    1213       488   \n",
       "top     0.000192526844330132     1.0     1.0       0.75323    INCY  20160728   \n",
       "freq                       2      16       8       3.00000    1772      8181   \n",
       "\n",
       "            20                            21  \n",
       "count   394204                        394204  \n",
       "unique     983                        394204  \n",
       "top          3  LMAT_20150225_f000002100.mp3  \n",
       "freq      1738                             1  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Collect whenever there is an error\n",
    "MAEC_bad_emotion2vec = [] # Ticker , Date, i, audio_dir, audio_file, labels, scores, e\n",
    "\n",
    "MAEC_emotion2vec = []\n",
    "for Ticker,Date in tqdm(MAEC_filename_data[['Ticker','Date']].values): # each audio file of the original data set\n",
    "    Date = Date.replace('-', '') \n",
    "    audio_dir = f\"D:/MAEC_audio/{Date}_{Ticker}\"\n",
    "    if os.path.exists(audio_dir):\n",
    "        for i, audio_file in enumerate(os.listdir(audio_dir), start= 1):\n",
    "            try:\n",
    "                # skip files that are not MP3 audio\n",
    "                if audio_file.lower().endswith('.mp3'):\n",
    "                    labels, scores = get_emotion2vec(audio_dir,audio_file)\n",
    "                    features_row = np.concatenate([labels, scores, [Ticker, Date, i, audio_file]])\n",
    "                    MAEC_emotion2vec.append(features_row)\n",
    "            except KeyboardInterrupt: break\n",
    "            except Exception as e: \n",
    "                print(Ticker, Date, i, e)\n",
    "                MAEC_bad_emotion2vec.append([Ticker ,Date, i, audio_dir, audio_file, labels, scores, e])\n",
    "                # set all features to  0.0 if there was an error\n",
    "                scores = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "                features_row = np.concatenate([labels, scores, [Ticker, Date, i, audio_file]])\n",
    "                MAEC_emotion2vec.append(features_row)\n",
    "\n",
    "MAEC_emotion2vec = pd.DataFrame(MAEC_emotion2vec)\n",
    "MAEC_emotion2vec.info(verbose=True)\n",
    "MAEC_emotion2vec.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf57c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "Should be 1 --- 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 394204 entries, 0 to 394203\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   angry         394204 non-null  object\n",
      " 1   disgusted     394204 non-null  object\n",
      " 2   fearful       394204 non-null  object\n",
      " 3   happy         394204 non-null  object\n",
      " 4   neutral       394204 non-null  object\n",
      " 5   other         394204 non-null  object\n",
      " 6   sad           394204 non-null  object\n",
      " 7   surprised     394204 non-null  object\n",
      " 8   unk           394204 non-null  object\n",
      " 9   Company       394204 non-null  object\n",
      " 10  Date          394204 non-null  object\n",
      " 11  Sentence_num  394204 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 36.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>disgusted</th>\n",
       "      <th>fearful</th>\n",
       "      <th>happy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>other</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprised</th>\n",
       "      <th>unk</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sentence_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204.00000</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "      <td>394204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>393785</td>\n",
       "      <td>393734</td>\n",
       "      <td>393745</td>\n",
       "      <td>386876</td>\n",
       "      <td>357989</td>\n",
       "      <td>393801</td>\n",
       "      <td>393403</td>\n",
       "      <td>393884</td>\n",
       "      <td>393601.00000</td>\n",
       "      <td>1213</td>\n",
       "      <td>488</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0031425696797668934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000192526844330132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75323</td>\n",
       "      <td>INCY</td>\n",
       "      <td>20160728</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1094</td>\n",
       "      <td>3072</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1772</td>\n",
       "      <td>8181</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         angry disgusted                fearful   happy neutral  \\\n",
       "count   394204    394204                 394204  394204  394204   \n",
       "unique  393785    393734                 393745  386876  357989   \n",
       "top        1.0       1.0  0.0031425696797668934     1.0     1.0   \n",
       "freq         9        11                      2    1094    3072   \n",
       "\n",
       "                       other     sad surprised           unk Company  \\\n",
       "count                 394204  394204    394204  394204.00000  394204   \n",
       "unique                393801  393403    393884  393601.00000    1213   \n",
       "top     0.000192526844330132     1.0       1.0       0.75323    INCY   \n",
       "freq                       2      16         8       3.00000    1772   \n",
       "\n",
       "            Date Sentence_num  \n",
       "count     394204       394204  \n",
       "unique       488          983  \n",
       "top     20160728            3  \n",
       "freq        8181         1738  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to make sure all the labels (the first 9 columns) are the same\n",
    "# then drop them\n",
    "for column in range(9):\n",
    "    print('Should be 1 ---', pd.unique(MAEC_emotion2vec[column]).size)\n",
    "MAEC_emotion2vec = MAEC_emotion2vec.iloc[:, 9:]\n",
    "\n",
    "# rename columns\n",
    "MAEC_emotion2vec.columns = ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'other', 'sad', 'surprised', 'unk', \n",
    "                       'Company', 'Date', 'Sentence_num', 'audio_file']\n",
    "MAEC_emotion2vec = MAEC_emotion2vec.drop(['audio_file'], axis=1)\n",
    "MAEC_emotion2vec.info(verbose=True)\n",
    "### save ############################################\n",
    "MAEC_emotion2vec.to_csv('data/data_prep/MAEC_emotion2vec.csv', index=False)\n",
    "#####################################################\n",
    "MAEC_emotion2vec.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce3639c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAEC_bad_emotion2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adbcf0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(MAEC_bad_emotion2vec))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
